{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import queue\n",
    "import numpy as np\n",
    "import threading\n",
    "from io import StringIO, BytesIO\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Data/AmazonFashion6ImgPartitioned.npy'\n",
    "\n",
    "dataset = np.load(dataset_name, allow_pickle=True, encoding='latin1')\n",
    "\n",
    "[user_train, user_validation, user_test, Item, usernum, itemnum] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper-prameters\n",
    "K = 100 # Latent dimensionality\n",
    "lambda1 = 0.001 # Weight decay\n",
    "lambda2 = 1.0 # Regularizer for theta_u\n",
    "learning_rate = 1e-4\n",
    "training_epoch = 20\n",
    "batch_size = 128\n",
    "dropout = 0.5 # Dropout, probability to keep units\n",
    "numldprocess=4 # multi-threading for loading images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def avgpool2d(x, k=2):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': [11, 11, 3, 64],\n",
    "    'wc2': [5, 5, 64, 256],\n",
    "    'wc3': [3, 3, 256, 256],\n",
    "    'wc4': [3, 3, 256, 256],\n",
    "    'wc5': [3, 3, 256, 256],    \n",
    "    'wd1': [7*7*256, 4096],\n",
    "    'wd2': [4096, 4096],\n",
    "    'wd3': [4096, K],\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': [64],\n",
    "    'bc2': [256],\n",
    "    'bc3': [256],\n",
    "    'bc4': [256],\n",
    "    'bc5': [256],\n",
    "    'bd1': [4096],\n",
    "    'bd2': [4096],\n",
    "    'bd3': [K],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(name):\n",
    "    return tf.get_variable(name,dtype=tf.float32,shape=weights[name],initializer=tf.compat.v1.initializers.glorot_normal())\n",
    "\n",
    "def Biases(name):\n",
    "    return tf.get_variable(name,dtype=tf.float32,initializer=tf.zeros(biases[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(x,dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 224, 224, 3])\n",
    "\n",
    "    conv1 = conv2d(x, Weights('wc1'), Biases('bc1'), strides=4)\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    conv2 = conv2d(conv1, Weights('wc2'), Biases('bc2'))\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    conv3 = conv2d(conv2, Weights('wc3'), Biases('bc3'))\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    \n",
    "    conv4 = conv2d(conv3, Weights('wc4'), Biases('bc4'))\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    \n",
    "    conv5 = conv2d(conv4, Weights('wc5'), Biases('bc5'))\n",
    "    conv5 = tf.nn.relu(conv5)\n",
    "    conv5 = maxpool2d(conv5, k=2)\n",
    "\n",
    "    fc1 = tf.reshape(conv5, [-1,weights['wd1'][0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, Weights('wd1')), Biases('bd1'))\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, Weights('wd2')), Biases('bd2'))\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    fc3 = tf.add(tf.matmul(fc2, Weights('wd3')), Biases('bd3'))\n",
    "    \n",
    "    return fc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.compat.v1.layers' has no attribute 'xavier_initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-99fbe8ffd053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#siamese networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DVBPR\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mresult1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mscope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mresult2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-0105ae0f6671>\u001b[0m in \u001b[0;36mCNN\u001b[1;34m(x, dropout)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBiases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxpool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8bb92fab13c9>\u001b[0m in \u001b[0;36mWeights\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mBiases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core.compat.v1.layers' has no attribute 'xavier_initializer'"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    #training sample\n",
    "    queueu = tf.placeholder(dtype=tf.int32,shape=[1])\n",
    "    queuei = tf.placeholder(dtype=tf.int32,shape=[1])\n",
    "    queuej = tf.placeholder(dtype=tf.int32,shape=[1])\n",
    "    queueimage1 = tf.placeholder(dtype=tf.uint8,shape=[224,224,3])\n",
    "    queueimage2 = tf.placeholder(dtype=tf.uint8,shape=[224,224,3])\n",
    "    batch_train_queue = tf.FIFOQueue(batch_size*5, dtypes=[tf.int32,tf.int32,tf.int32,tf.uint8,tf.uint8], shapes=[[1],[1],[1],[224,224,3],[224,224,3]])\n",
    "    batch_train_queue_op = batch_train_queue.enqueue([queueu,queuei,queuej,queueimage1,queueimage2]);\n",
    "    u,i,j,image1,image2 = batch_train_queue.dequeue_many(batch_size)\n",
    "\n",
    "    image_test=tf.placeholder(dtype=tf.uint8,shape=[batch_size,224,224,3])\n",
    "    \n",
    "    image1=(tf.to_float(image1)-127.5)/127.5\n",
    "    image2=(tf.to_float(image2)-127.5)/127.5\n",
    "    _image_test=(tf.to_float(image_test)-127.5)/127.5\n",
    "\n",
    "    u=tf.reshape(u,shape=[batch_size])\n",
    "    i=tf.reshape(i,shape=[batch_size])\n",
    "    j=tf.reshape(j,shape=[batch_size])\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "    #siamese networks\n",
    "    with tf.variable_scope(\"DVBPR\") as scope:\n",
    "        result1 = CNN(image1,dropout)\n",
    "        scope.reuse_variables()\n",
    "        result2 = CNN(image2,dropout)\n",
    "        result_test = CNN(_image_test,1.0)\n",
    "        nn_regularizers = sum(map(tf.nn.l2_loss,[Weights('wd1'), Weights('wd2'), Weights('wd3'), Weights('wc1'), Weights('wc2'), Weights('wc3'), Weights('wc4'), Weights('wc5')]))\n",
    "        thetau = tf.Variable(tf.random_uniform([usernum,K],minval=0,maxval=1)/100)\n",
    "   \n",
    "    cost_train = tf.reduce_sum(tf.log(tf.sigmoid(tf.reduce_sum(tf.multiply(tf.gather(thetau,u),tf.subtract(result1,result2)),1,keep_dims=True))))\n",
    "    regularizers = tf.nn.l2_loss(tf.gather(thetau,u))\n",
    "    cost_train -= lambda1 * nn_regularizers + lambda2 * regularizers\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-cost_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\robin.opdam\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(train,test,U,I):\n",
    "    ans=0\n",
    "    cc=0\n",
    "    for u in train:    \n",
    "        i=test[u][0]['productid']\n",
    "        T=np.dot(U[u,:],I.T)\n",
    "        cc+=1\n",
    "        M=set()      \n",
    "        for item in train[u]:\n",
    "            M.add(item['productid'])\n",
    "        M.add(i)\n",
    "            \n",
    "        count=0\n",
    "        tmpans=0\n",
    "        #for j in xrange(itemnum):\n",
    "        for j in random.sample(xrange(itemnum),100): #sample\n",
    "            if j in M: continue\n",
    "            if T[i]>T[j]: tmpans+=1\n",
    "            count+=1\n",
    "        tmpans/=float(count)\n",
    "        ans+=tmpans\n",
    "    ans/=float(cc)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(step):\n",
    "    print '...'\n",
    "    U=sess.run(thetau)\n",
    "    I=np.zeros([itemnum,K],dtype=np.float32)\n",
    "    idx=np.array_split(range(itemnum),(itemnum+batch_size-1)/batch_size)\n",
    "    \n",
    "    input_images=np.zeros([batch_size,224,224,3],dtype=np.int8)\n",
    "    for i in range(len(idx)):\n",
    "        cc=0\n",
    "        for j in idx[i]:\n",
    "            input_images[cc]=np.uint8(np.asarray(Image.open(StringIO(Item[j]['imgs'])).convert('RGB').resize((224,224))))\n",
    "            cc+=1\n",
    "        I[idx[i][0]:(idx[i][-1]+1)]=sess.run(result_test,feed_dict={image_test:input_images})[:(idx[i][-1]-idx[i][0]+1)]\n",
    "    print 'export finised!'\n",
    "    np.save('UI_'+str(K)+'_'+str(step)+'.npy',[U,I])\n",
    "    return AUC(user_train,user_validation,U,I), AUC(user_train,user_test,U,I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(user):\n",
    "    u = random.randrange(usernum)\n",
    "    numu = len(user[u])\n",
    "    i = user[u][random.randrange(numu)]['productid']\n",
    "    M=set()\n",
    "    for item in user[u]:\n",
    "        M.add(item['productid'])\n",
    "    while True:\n",
    "        j=random.randrange(itemnum)\n",
    "        if (not j in M): break\n",
    "    return (u,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_async():\n",
    "    while True:\n",
    "        (uuu,iii,jjj)=sample(user_train)\n",
    "        jpg1=np.uint8(np.asarray(Image.open(StringIO(Item[iii]['imgs'])).convert('RGB').resize((224,224))))\n",
    "        jpg2=np.uint8(np.asarray(Image.open(StringIO(Item[jjj]['imgs'])).convert('RGB').resize((224,224))))\n",
    "        sess.run(batch_train_queue_op,feed_dict={queueu:np.asarray([uuu]),\n",
    "                                                 queuei:np.asarray([iii]),\n",
    "                                                 queuej:np.asarray([jjj]),\n",
    "                                                 queueimage1:jpg1,queueimage2:jpg2,\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27448, 117707, 46610)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_async():\n",
    "    (uuu,iii,jjj)=sample(user_train)\n",
    "    jpg1=np.uint8(np.asarray(Image.open(StringIO(Item[iii]['imgs'])).convert('RGB').resize((224,224))))\n",
    "    jpg2=np.uint8(np.asarray(Image.open(StringIO(Item[jjj]['imgs'])).convert('RGB').resize((224,224))))\n",
    "    print(jpg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base64_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-27a92a66905a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbase64_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64_message\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmessage_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase64_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_bytes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base64_message' is not defined"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "base64_bytes = Item[0][''.encode('ascii')\n",
    "message_bytes = base64.b64decode(base64_bytes)\n",
    "message = message_bytes.decode('ascii')\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['asin', 'c', 'title', 'imUrl', 'imgs', 'salesRank', 'categories'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Item[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-2024c7e6abe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mItem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'imgs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "Image.open(BytesIO(Item[0]['imgs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('DVBPR.log','w')\n",
    "config = tf.ConfigProto(log_device_placement=False,allow_soft_placement=True)\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "t=[0]*numldprocess\n",
    "for i in range(numldprocess):\n",
    "    t[i] = threading.Thread(target=load_image_async)\n",
    "    t[i].daemon=True\n",
    "    t[i].start()\n",
    "\n",
    "oneiteration = 0\n",
    "for item in user_train: oneiteration+=len(user_train[item])\n",
    "\n",
    "step = 1\n",
    "saver = tf.train.Saver([k for k in tf.global_variables() if k.name.startswith('DVBPR')])\n",
    "\n",
    "epoch=0\n",
    "while step * batch_size <= training_epoch*oneiteration+1:\n",
    "\n",
    "    sess.run(optimizer, feed_dict={keep_prob: dropout})\n",
    "    \n",
    "    print('Step#'+str(step)+' CNN update')\n",
    "\n",
    "    if step*batch_size / oneiteration >epoch:\n",
    "        epoch+=1\n",
    "        saver.save(sess,'./DVBPR_auc_'+str(K)+'_'+str(step)+'.ckpt')\n",
    "        auc_valid,auc_test=Evaluation(step)\n",
    "        print('Epoch #'+str(epoch)+':'+str(auc_test)+' '+str(auc_valid)+'\\n')\n",
    "        f.write('Epoch #'+str(epoch)+':'+str(auc_test)+' '+str(auc_valid)+'\\n')\n",
    "        f.flush()\n",
    "    \n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
