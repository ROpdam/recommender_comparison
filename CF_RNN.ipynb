{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1586364379603,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "eWJsd_7Pc-TZ",
    "outputId": "38fa93e1-7d3a-4b3e-9cc5-ff2f5debea21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "# data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>datetime</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18590190</th>\n",
       "      <td>120461</td>\n",
       "      <td>2501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>2410</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590032</th>\n",
       "      <td>120461</td>\n",
       "      <td>252</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>249</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590159</th>\n",
       "      <td>120461</td>\n",
       "      <td>2069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1980</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590048</th>\n",
       "      <td>120461</td>\n",
       "      <td>440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>435</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590145</th>\n",
       "      <td>120461</td>\n",
       "      <td>1959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1870</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  item  rating            datetime item_id user_id\n",
       "18590190  120461  2501     5.0 2000-04-25 02:29:35    2410  120460\n",
       "18590032  120461   252     4.0 2000-04-25 02:29:35     249  120460\n",
       "18590159  120461  2069     4.0 2000-04-25 02:29:35    1980  120460\n",
       "18590048  120461   440     4.0 2000-04-25 02:29:35     435  120460\n",
       "18590145  120461  1959     4.0 2000-04-25 02:29:35    1870  120460"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df.item.astype('category').cat.codes + 1\n",
    "df['user_id'] = df.user.astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "### Leave last item out of subset of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_users_out(full_data, leave_out, seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    full_data['index'] = full_data.index\n",
    "    user_index_df = full_data.groupby('user')['index'].apply(list)\n",
    "    users = np.random.choice(list(user_index_df.index), leave_out, replace=False)\n",
    "    users_indices = []\n",
    "    \n",
    "    for user in users:\n",
    "        users_indices.extend(user_index_df.loc[user])\n",
    "    \n",
    "    sub_set = full_data.loc[users_indices]\n",
    "    remaining = full_data.drop(users_indices)\n",
    "    \n",
    "    return remaining.drop(columns=['index']), sub_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_x_out(full_data, n_users, leave_out=1, seed=1234):\n",
    "    # Input: data must contain user_id\n",
    "    # Output: full_data = without all last (time order) entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('user_id')['index'].apply(list)\n",
    "    users = full_data.user_id.unique()\n",
    "    leave_out_indices = []\n",
    "    users_picked = []\n",
    "    \n",
    "    for i in range(len(full_data.user_id.unique())):\n",
    "        random_user = np.random.choice(users)\n",
    "        item_indices = user_items_ind[random_user] # random user's items indices\n",
    "        if random_user in users_picked or len(item_indices) <= leave_out:\n",
    "            random_user = np.random.choice(users)\n",
    "            item_indices = user_items_ind[random_user] # random user's items indices\n",
    "        else:\n",
    "            users_picked.append(random_user)\n",
    "            leave_out_indices.extend(item_indices[-leave_out:])\n",
    "        \n",
    "        if len(users_picked) == n_users:\n",
    "            break\n",
    "        \n",
    "    if len(users_picked) < n_users:\n",
    "        error = 'Cannot pick ' + str(n_users) + ' users with more than ' + str(leave_out) + ' items'\n",
    "        solution = '\\nTry a smaller test and/or validation percentage of the data'\n",
    "        raise ValueError(error + solution) \n",
    "            \n",
    "    leave_out_set = full_data.loc[leave_out_indices] # the last items of n_users users with n_item > leave_out\n",
    "    full_data_leave_one_out = full_data.drop(leave_out_indices) # drops last items for n_users users\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, batch_size, val_perc, test_perc, n_items_val, n_items_test, stats=True):\n",
    "    # Input: df with user and item id, batch size for CFRNN data, val and test perc of users\n",
    "    #        number of last items to leave out for val and test set\n",
    "    # Output:full_data = total users and items of the original df, \n",
    "    #        Train, validation and test sets\n",
    "    \n",
    "    total_users = len(df.user_id.unique()) # Need all users for BPR\n",
    "    total_items = len(df.item_id.unique()) # Need all items for CFRNN\n",
    "    \n",
    "    users_to_remove = len(df.user_id.unique())%batch_size #Batch size compatible for CFRNN\n",
    "    df_new, deleted_users = leave_users_out(df, users_to_remove)\n",
    "\n",
    "    test_users = int(test_perc*total_users / 64 + 1) * 64 # Number of users to be used for testing\n",
    "    test_last_items = n_items_test # Items to be removed from test users in train set and used in test set\n",
    "\n",
    "    val_users = int(val_perc*total_users / 64 + 1) * 64\n",
    "    val_last_items = n_items_val\n",
    "    \n",
    "    train_set, test_set = leave_last_x_out(df_new, test_users, test_last_items)\n",
    "    train_set, val_set = leave_last_x_out(train_set, val_users, val_last_items)\n",
    "    \n",
    "    if stats:\n",
    "        print('Total number of items:', total_items)\n",
    "        print('Total users:', total_users)\n",
    "        print('Number of train users:', len(train_set.user_id.unique()))\n",
    "        print('Number of test users:', test_users)\n",
    "        print('Number of validation users:', val_users, '\\n')\n",
    "        print('Users deleted:', len(deleted_users.user_id.unique()))\n",
    "    \n",
    "    return total_users, total_items, train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 27387\n",
      "Total users: 16254\n",
      "Number of train users: 16192\n",
      "Number of test users: 1664\n",
      "Number of validation users: 1664 \n",
      "\n",
      "Users deleted: 62\n"
     ]
    }
   ],
   "source": [
    "total_users, total_items, train_set, val_set, test_set = train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKThZjwtc-Tx"
   },
   "source": [
    "---\n",
    "# Data Prep\n",
    "1. Each (relatively) ordered item sequence per user will be viewed as one time series\n",
    "2. **Sequences that do not have the *right* size, will be padded/truncated for now**\n",
    "3. Each batch consists out of BATCH_SIZE users sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aneydXL_c-Uc"
   },
   "source": [
    "---\n",
    "## Train and Target sequences\n",
    "Create the **sequences** from the item_ids per user (already sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m330f6Nfc-Ud"
   },
   "outputs": [],
   "source": [
    "def get_x_y_sequences(dataset, n_unknowns_in_y=1, stats=True):\n",
    "    user_sequences_x = []\n",
    "    user_sequences_y = []\n",
    "    lengths = []\n",
    "    users = dataset.user_id.unique()\n",
    "    \n",
    "    for u in users:\n",
    "        user_item_seq = np.array(dataset[dataset['user_id']==u]['item_id'])\n",
    "        user_sequences_x.append(user_item_seq[:-n_unknowns_in_y])\n",
    "        user_sequences_y.append(user_item_seq[n_unknowns_in_y:])\n",
    "        lengths.append(len(user_item_seq))\n",
    "    \n",
    "    median = np.median(lengths)\n",
    "    \n",
    "    if stats:\n",
    "        print('Number of sequences x:', len(user_sequences_x), \n",
    "              '\\nAvg sequence length x:', np.average(lengths),\n",
    "              '\\nStd_dev sequence length x:', np.round(np.std(lengths),2),\n",
    "              '\\nMedian of sequence length x:', median)\n",
    "\n",
    "    return user_sequences_x, user_sequences_y, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10230,
     "status": "ok",
     "timestamp": 1586364411289,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9Ks5DfnUc-Ui",
    "outputId": "08b88b1e-d379-4247-a33e-32667301cfaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences x: 16192 \n",
      "Avg sequence length x: 150.41637845849803 \n",
      "Std_dev sequence length x: 242.73 \n",
      "Median of sequence length x: 71.0\n"
     ]
    }
   ],
   "source": [
    "user_sequences_x, user_sequences_y, median = get_x_y_sequences(train_set, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RB9BnyCXc-Ul"
   },
   "source": [
    "---\n",
    "## Padding\n",
    "- **Using: Median, Mean or Min**\n",
    "\n",
    "- add zeros if they are too short\n",
    "- remove item ids from the beginning if they are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL-2yLvoc-Ul"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_length, stats=True):\n",
    "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=int(max_length), padding='post', truncating='pre')\n",
    "    if stats:\n",
    "        print('number of sequences:', padded_sequences.shape[0], \n",
    "              '\\navg sequence length:', np.average([i.shape[0] for i in padded_sequences]),\n",
    "              '\\nstd_dev sequence length:', np.std([i.shape[0] for i in padded_sequences]))\n",
    "        \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9048,
     "status": "ok",
     "timestamp": 1586364411291,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "vOVxaQKNc-Uo",
    "outputId": "5cc77716-fd05-4abc-8c85-70e6b930111f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 16192 \n",
      "avg sequence length: 150.0 \n",
      "std_dev sequence length: 0.0\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 150\n",
    "padded_sequences_x = pad_sequences(user_sequences_x, max_seq_length)\n",
    "padded_sequences_y = pad_sequences(user_sequences_y, max_seq_length, stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LBhWQHfc-Us"
   },
   "source": [
    "---\n",
    "## Create Dataset\n",
    "- sequences_x inputs\n",
    "- sequences_y actuals\n",
    "- batches of size BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3339,
     "status": "ok",
     "timestamp": 1586364411291,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "I-K4vjgzc-Ut",
    "outputId": "1d627352-feda-4895-f516-f0b0a05e97f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((150,), (150,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_data_x = tf.data.Dataset.from_tensor_slices(padded_sequences_x) \n",
    "sequences_data_y = tf.data.Dataset.from_tensor_slices(padded_sequences_y) \n",
    "dataset = tf.data.Dataset.zip((sequences_data_x, sequences_data_y))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2828,
     "status": "ok",
     "timestamp": 1586364411292,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "RqMlFLqwc-Uw",
    "outputId": "5b99dcf8-e467-4aeb-fae3-79cda4b66132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: tf.Tensor(\n",
      "[2154 1431 1480 1544 2581  511   13  995  985  988  975  257  991  994\n",
      "    8  886  583  597    1 1785 1965 1963 1232 1959 1976  996 1973 1956\n",
      " 2629 2897 1488 1955 3242 1958 2977 2038  992 2228  307  982  757  584\n",
      " 1033 2014 2257  357 3243 2169 1911 1961 3244 1896 1924  585  604  951\n",
      "  977  311  142 1935   60 1932 1926 2017  976 1967  973 1968  980 2272\n",
      "  981 1883 1845  567  575  154 2019 1970 1314  970 2713  993 1960  972\n",
      " 1930  850 2000 1974 1916 1931 2273 2695 1892 2302 1621 2039 1411  447\n",
      "  494 1759 2322  367 2818  236 1331  200 1269 1166 1604 1153 2580 2630\n",
      " 2498 2555 2869 2592 2727  578  449  157 1529  370  466  576  220   22\n",
      " 1527 2671 1754 1517  722  760  636  754 1011 1906 1352  361  310  108\n",
      "  472  255  581  999 3250 1149 1150 1162 1151 1241], shape=(150,), dtype=int32)\n",
      "Target data: tf.Tensor(\n",
      "[1431 1480 1544 2581  511   13  995  985  988  975  257  991  994    8\n",
      "  886  583  597    1 1785 1965 1963 1232 1959 1976  996 1973 1956 2629\n",
      " 2897 1488 1955 3242 1958 2977 2038  992 2228  307  982  757  584 1033\n",
      " 2014 2257  357 3243 2169 1911 1961 3244 1896 1924  585  604  951  977\n",
      "  311  142 1935   60 1932 1926 2017  976 1967  973 1968  980 2272  981\n",
      " 1883 1845  567  575  154 2019 1970 1314  970 2713  993 1960  972 1930\n",
      "  850 2000 1974 1916 1931 2273 2695 1892 2302 1621 2039 1411  447  494\n",
      " 1759 2322  367 2818  236 1331  200 1269 1166 1604 1153 2580 2630 2498\n",
      " 2555 2869 2592 2727  578  449  157 1529  370  466  576  220   22 1527\n",
      " 2671 1754 1517  722  760  636  754 1011 1906 1352  361  310  108  472\n",
      "  255  581  999 3250 1149 1150 1162 1151 1241  227], shape=(150,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):#.as_numpy_iterator():\n",
    "    print ('Input data:', input_example)\n",
    "    print ('Target data:', target_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2487,
     "status": "ok",
     "timestamp": 1586364411293,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "e2o_tNO2c-Uz",
    "outputId": "b3532ec8-1960-4a73-9246-8168e38c80c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (64, 150) \n",
      "\n",
      "output: (64, 150)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "for i, o in dataset.take(1):#.as_numpy_iterator():\n",
    "    print('input:', i.shape, '\\n\\noutput:', o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dfr9RyeAc-U5"
   },
   "source": [
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code:https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYbz0zq8c-U5"
   },
   "source": [
    "\n",
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huW9kTD0c-U6"
   },
   "source": [
    "### model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjqXT55ic-U8"
   },
   "outputs": [],
   "source": [
    "def build_model(total_items, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(total_items, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        \n",
    "        tf.keras.layers.LSTM(units=rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=False, #Reset cell states with each batch\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(total_items)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "---\n",
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "total_items = total_items,\n",
    "embedding_dim = embedding_dim,\n",
    "rnn_units = rnn_units,\n",
    "batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "---\n",
    "### Add Loss and Custom Metric\n",
    "**Added one hot encoding of the labels to match logits output after dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13355, shape=(64, 150), dtype=int32, numpy=\n",
       "array([[ 1431,  1480,  1544, ...,  1151,  1241,   227],\n",
       "       [ 3586,  2614,   865, ...,     0,     0,     0],\n",
       "       [ 1238,  1241,  1190, ...,  9611, 16031, 15899],\n",
       "       ...,\n",
       "       [ 1021,   348,  1349, ...,     0,     0,     0],\n",
       "       [  999,  2630,   108, ...,     0,     0,     0],\n",
       "       [  712,     2,    25, ...,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13636, shape=(150,), dtype=int32, numpy=\n",
       "array([1431, 1480, 1544, 2581,  511,   13,  995,  985,  988,  975,  257,\n",
       "        991,  994,    8,  886,  583,  597,    1, 1785, 1965, 1963, 1232,\n",
       "       1959, 1976,  996, 1973, 1956, 2629, 2897, 1488, 1955, 3242, 1958,\n",
       "       2977, 2038,  992, 2228,  307,  982,  757,  584, 1033, 2014, 2257,\n",
       "        357, 3243, 2169, 1911, 1961, 3244, 1896, 1924,  585,  604,  951,\n",
       "        977,  311,  142, 1935,   60, 1932, 1926, 2017,  976, 1967,  973,\n",
       "       1968,  980, 2272,  981, 1883, 1845,  567,  575,  154, 2019, 1970,\n",
       "       1314,  970, 2713,  993, 1960,  972, 1930,  850, 2000, 1974, 1916,\n",
       "       1931, 2273, 2695, 1892, 2302, 1621, 2039, 1411,  447,  494, 1759,\n",
       "       2322,  367, 2818,  236, 1331,  200, 1269, 1166, 1604, 1153, 2580,\n",
       "       2630, 2498, 2555, 2869, 2592, 2727,  578,  449,  157, 1529,  370,\n",
       "        466,  576,  220,   22, 1527, 2671, 1754, 1517,  722,  760,  636,\n",
       "        754, 1011, 1906, 1352,  361,  310,  108,  472,  255,  581,  999,\n",
       "       3250, 1149, 1150, 1162, 1151, 1241,  227], dtype=int32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(target_example_batch, example_batch_preds)\n",
    "# print(target_example_batch[1], '\\n', example_batch_preds[1])\n",
    "example_batch_preds.shape\n",
    "tf.keras.backend.one_hot(target_example_batch, total_items)[1]\n",
    "tf.keras.backend.argmin(target_example_batch[0])\n",
    "target_example_batch[0]\n",
    "# tf.nn.in_top_k(\n",
    "#     example_batch_preds,\n",
    "#     target_example_batch,\n",
    "#     20,\n",
    "#     name=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    K = tf.keras.backend\n",
    "    y_true = K.one_hot(tf.dtypes.cast(y_true, tf.int32), total_items)\n",
    "    y_true = K.ones_like(y_true) \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    recall = true_positives / (all_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE_UKWEgc-VF"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    oh_labels = tf.keras.backend.one_hot(tf.dtypes.cast(labels, tf.int32), total_items)\n",
    "    return tf.keras.losses.categorical_crossentropy(oh_labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='Adagrad', loss=loss, metrics=[recall]) #, metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RLAlSqfc-VJ"
   },
   "source": [
    "---\n",
    "### Try Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1586364422809,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "wKo9zst9c-VJ",
    "outputId": "65689f7c-621c-45fc-e5af-4d9b463fceed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 150), (None, 150)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1586364423399,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "LTk5zKtzc-VM",
    "outputId": "24309455-eaaa-40bc-aa30-ab49634a8db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 150, 27387) # (batch_size, sequence_length, total_items)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_preds = model(input_example_batch)\n",
    "    print(example_batch_preds.shape, \"# (batch_size, sequence_length, total_items)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dr4N1eijc-VQ"
   },
   "outputs": [],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1586364425704,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dAoSfkuDc-VS",
    "outputId": "5a05abf5-2dbe-4b58-945d-ac2f6ee7aff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 150, 27387])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1586364425706,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "PoqIE7YXc-VV",
    "outputId": "4ff7b6d0-f151-44bd-8bcf-b28b4ae28ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 150])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "---\n",
    "**model summmary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (64, None, 100)           2738700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 27387)         575127    \n",
      "=================================================================\n",
      "Total params: 3,323,507\n",
      "Trainable params: 3,323,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_val_x, user_sequences_val_y, median = get_x_y_sequences(val_set, 1, stats=False)\n",
    "\n",
    "padded_sequences_val_x = pad_sequences(user_sequences_val_x, max_seq_length, stats=False)\n",
    "padded_sequences_val_y = pad_sequences(user_sequences_val_y, max_seq_length, stats=False)\n",
    "\n",
    "sequences_data_val_x = tf.data.Dataset.from_tensor_slices(padded_sequences_val_x) \n",
    "sequences_data_val_y = tf.data.Dataset.from_tensor_slices(padded_sequences_val_y) \n",
    "\n",
    "val_dataset = tf.data.Dataset.zip((sequences_data_val_x, sequences_data_val_y))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 150)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16192, 150)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "### Configure Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './rnn_train_checkpoints'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "---\n",
    "**Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 150), (None, 150)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 25\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "253/253 [==============================] - 63s 249ms/step - loss: 9.6753 - recall: 0.0029 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/25\n",
      "253/253 [==============================] - 61s 239ms/step - loss: 9.0220 - recall: 0.0226 - val_loss: 8.4387 - val_recall: 0.0287\n",
      "Epoch 3/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 8.6484 - recall: 0.0294 - val_loss: 8.0235 - val_recall: 0.0320\n",
      "Epoch 4/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 8.3777 - recall: 0.0315 - val_loss: 7.6946 - val_recall: 0.0328\n",
      "Epoch 5/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 8.1690 - recall: 0.0317 - val_loss: 7.4200 - val_recall: 0.0324\n",
      "Epoch 6/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 8.0005 - recall: 0.0312 - val_loss: 7.1816 - val_recall: 0.0315\n",
      "Epoch 7/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 7.8592 - recall: 0.0303 - val_loss: 6.9685 - val_recall: 0.0303\n",
      "Epoch 8/25\n",
      "253/253 [==============================] - 60s 239ms/step - loss: 7.7372 - recall: 0.0293 - val_loss: 6.7740 - val_recall: 0.0293\n",
      "Epoch 9/25\n",
      "146/253 [================>.............] - ETA: 23s - loss: 7.6464 - recall: 0.0285"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c02f40800a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, validation_data=val_dataset, epochs=epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMQBMjJfc-Vt"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(n_items, embedding_dim, rnn_units, batch_size=100)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.compile(optimizer='Adagrad', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "aditional_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=aditional_epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY0mtM26c-V_"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-Ths7-hc-WE"
   },
   "outputs": [],
   "source": [
    "model = build_model(total_items, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "                   \n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQfRtD71c-WH"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQNPBkyQc-WI"
   },
   "source": [
    "---\n",
    "## Create Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3A-hRV-c-WJ"
   },
   "source": [
    "**Using train_set sequences to predict test_set item(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSmlKF14c-WP"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, train_set, test_set, rank_at, temp=1):\n",
    "\n",
    "    predictions_df = pd.DataFrame(columns=['user', 'pred_seq', 'true_seq'])\n",
    "    for u in test_set.user_id.unique():\n",
    "        test_user_seq = np.array(train_set[train_set['user_id']==u]['item_id'])\n",
    "        true_items = list(test_set[test_set['user_id']==u]['item_id'])\n",
    "        generated_predictions = []\n",
    "\n",
    "        #Predict\n",
    "        for item in range(rank_at): #could be any number of recommended items you want to predict\n",
    "            predictions = model(test_user_seq.reshape(-1,1).T)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "            predictions = predictions / temp\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "            test_user_seq = np.append(test_user_seq, predicted_id).reshape(-1,1).transpose()\n",
    "\n",
    "    #         half_test_seq = tf.expand_dims([predicted_id], 0)\n",
    "            generated_predictions.append(predicted_id)\n",
    "\n",
    "        predictions_df = predictions_df.append({'user':u, 'pred_seq':generated_predictions, 'true_seq':true_items}, ignore_index=True)\n",
    "        \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "predictions_df = get_predictions(model, train_set, test_set, rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in predictions_df.iterrows():\n",
    "    if len(row['true_seq']) > 1:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNn4Lq9sc-WY"
   },
   "outputs": [],
   "source": [
    "result_path = 'Results/CFRNN/'\n",
    "predictions = pd.read_pickle(path + result_path + 'CFRNN_res_400_ML_01_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ranked_df, steps, max_rank):\n",
    "    s = time.time()\n",
    "    ranks_at = [1] + [i for i in range(steps, max_rank + steps, steps)]\n",
    "    hitcounts = []\n",
    "    recs_at = []\n",
    "    precs_at = []\n",
    "    metrics = pd.DataFrame(columns=['rank_at', 'hitcounts', 'recall', 'precision'])\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for i, row in ranked_df.iterrows():\n",
    "            hitcount +=  len(set(row['true_id']) & set(row['pred_items_ranked'][:rank]))\n",
    "\n",
    "        prec_at = hitcount / rank / len(ranked_df)\n",
    "        rec_at = hitcount / len(ranked_df.iloc[0]['true_id']) / len(ranked_df)\n",
    "\n",
    "        hitcounts.append(hitcount)                     \n",
    "        recs_at.append(rec_at)\n",
    "        precs_at.append(prec_at)\n",
    "\n",
    "    metrics['rank_at'] = ranks_at\n",
    "    metrics['hitcounts'] = hitcounts\n",
    "    metrics['recall'] = recs_at\n",
    "    metrics['precision'] = precs_at\n",
    "    print('Obtaining metrics time:', round(time.time() - s,2))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {'pred_seq':'pred_items_ranked', 'true_seq':'true_id'}\n",
    "predictions = predictions.rename(renames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBun0RHBc-Wc"
   },
   "outputs": [],
   "source": [
    "metrics = get_metrics(predictions, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_pickle(path + 'Results/CFRNN/' + 'metrics_CFRNN_' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
