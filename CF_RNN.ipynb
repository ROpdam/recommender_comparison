{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0 \n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('TF version:', tf.__version__ , '\\nGPU available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets are datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '../' # Paperspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "data_path = 'datasets/' # Paperspace\n",
    "# data_path = 'Data/Amazon/'\n",
    "file_name = 'Amazon_01_users'\n",
    "# file_name = 'am_like_ml_01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "# data_path = 'datasets/' # Paperspace\n",
    "# data_path = 'Data/ML/'\n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983863</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00FXSELCM</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104506</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294092</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00VDPQ884</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175639</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809981</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00EWC0W3W</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99224</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337932</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01EZKMD64</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>238824</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832820</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01ABS4646</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222085</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating  item_id  user_id\n",
       "4983863  A39ZLL8ILVT2J8  B00FXSELCM 2014-03-24     3.0   104506    73226\n",
       "7294092  A39ZLL8ILVT2J8  B00VDPQ884 2016-06-29     5.0   175639    73226\n",
       "4809981  A39ZLL8ILVT2J8  B00EWC0W3W 2016-08-14     5.0    99224    73226\n",
       "9337932  A39ZLL8ILVT2J8  B01EZKMD64 2016-10-03     5.0   238824    73226\n",
       "8832820  A39ZLL8ILVT2J8  B01ABS4646 2016-12-22     5.0   222085    73226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_items = len(df.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "all_models = pd.read_pickle(path + 'results/' + res_ext + '/all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_id = str(int(all_models.model_id.max()[0]) + 1) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "new_model_id = str(0) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'model_id':new_model_id,\n",
    "'train_time':0,\n",
    "'epochs':0,\n",
    "'BATCH_SIZE':32,\n",
    "'learning_rate':0.1,\n",
    "'delta':0.6,             # Diversity Bias\n",
    "'max_seq_len':30,        # Max length of sequence71=median\n",
    "\n",
    "'val_perc':0.1,          # Percentage of users from df in val and test set\n",
    "'test_perc':0.1, \n",
    "'n_items_val':0,        # Number of last (chronologically) items in val and test set\n",
    "'n_items_test':1,\n",
    "\n",
    "'pad_value':total_items, # Pad with total_items+1 => masked => still use item 0\n",
    "'shift_targets_by':1     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = params['BATCH_SIZE']\n",
    "learning_rate = params['learning_rate']\n",
    "delta = params['delta']\n",
    "max_seq_len = params['max_seq_len']\n",
    "\n",
    "val_perc = params['val_perc']\n",
    "test_perc = params['test_perc']\n",
    "n_items_val = params['n_items_val']\n",
    "n_items_test = params['n_items_test']\n",
    "\n",
    "pad_value = params['pad_value']\n",
    "shift_targets_by = params['shift_targets_by'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "\n",
    "# Train Test Val Split\n",
    "data_split = train_val_test_split(df, val_perc, test_perc, n_items_val, n_items_test, seqs=True)\n",
    "\n",
    "train_set, val_set, val_left_out_items, test_set, test_left_out_items = data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import create_seq_batch_dataset\n",
    " \n",
    "#Train Set\n",
    "train_dataset = create_seq_batch_dataset(df=train_set, \n",
    "                                         shift=shift_targets_by, \n",
    "                                         max_seq_len=max_seq_len, \n",
    "                                         pad_value=pad_value, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         stats=False,\n",
    "                                         drop_remainder=True)\n",
    "\n",
    "#Val Set\n",
    "val_dataset = create_seq_batch_dataset(df=val_set, \n",
    "                                       shift=shift_targets_by, \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       pad_value=pad_value, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       stats=False,\n",
    "                                       drop_remainder=True)\n",
    "\n",
    "# #Test Set\n",
    "# test_dataset = create_seq_batch_dataset(df=test_set, \n",
    "#                                        shift=shift_targets_by, \n",
    "#                                        max_seq_len=max_seq_len, \n",
    "#                                        pad_value=pad_value, \n",
    "#                                        batch_size=BATCH_SIZE, \n",
    "#                                        stats=False,\n",
    "#                                        drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks\n",
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code: https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, # +1 because padding is total_items+1\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "## Add Custom Metric=Recall and Loss=Diversity Bias Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 100)           24746600  \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (32, None, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 247465)        5196765   \n",
      "=================================================================\n",
      "Total params: 29,953,045\n",
      "Trainable params: 29,953,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "## Configure Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '_' + file_name[:2] #ML or Am\n",
    "# directory = './ckpts/ckpts' \n",
    "directory = '../ckpts/ckpts'\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = directory + '_' + str(params['model_id'])\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "from Helpers import TimingCallback\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix,    \n",
    "                                                         monitor = 'val_recall',    \n",
    "                                                         mode = 'max',    \n",
    "                                                         save_best_only = True,\n",
    "                                                         save_weights_only = True)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_recall',\n",
    "                                                           min_delta = 0.0001,\n",
    "                                                           mode = 'max',\n",
    "                                                           patience = 15)\n",
    "    \n",
    "\n",
    "timing_callback = TimingCallback()\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stopping_callback, timing_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Batches: 3034\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "print('#Batches:', tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LSTM with max sequence length: 30\n",
      "Epoch 1/2\n",
      "3034/3034 [==============================] - 741s 244ms/step - loss: 0.1388 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3034/3034 [==============================] - 710s 234ms/step - loss: 0.1381 - recall: 3.4185e-06 - val_loss: 0.5172 - val_recall: 4.0410e-06\n"
     ]
    }
   ],
   "source": [
    "print('Fitting LSTM with max sequence length:', str(max_seq_len))\n",
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Loss, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = history.history\n",
    "plt.plot(results['loss'])\n",
    "plt.plot(results['val_loss'])\n",
    "plt.show()\n",
    "plt.plot(results['recall'])\n",
    "plt.plot(results['val_recall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff4821beac8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items,\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir)).expect_partial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias\n",
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': '0_Am',\n",
       " 'train_time': 0,\n",
       " 'epochs': 0,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'learning_rate': 0.1,\n",
       " 'delta': 0.6,\n",
       " 'max_seq_len': 30,\n",
       " 'val_perc': 0.1,\n",
       " 'test_perc': 0.1,\n",
       " 'n_items_val': 0,\n",
       " 'n_items_test': 1,\n",
       " 'pad_value': 247465,\n",
       " 'shift_targets_by': 1}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "initial_epoch = 2\n",
    "total_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "3034/3034 [==============================] - 737s 243ms/step - loss: 0.1373 - recall: 4.3644e-06 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2386/3034 [======================>.......] - ETA: 2:17 - loss: 0.1362 - recall: 2.9888e-05"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=total_epochs, \n",
    "                    callbacks=callbacks, \n",
    "                    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint from: ../ckpts/ckpts_0_Am/ckpt\n"
     ]
    }
   ],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, \n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = 1,\n",
    "                         return_sequences=False)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print('Latest checkpoint from:', tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "- CREATE MULTIPROCESSING FOR PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import standard_padding\n",
    "def get_predictions_local(test_set, test_left_out_items, max_seq_len, rank_at):\n",
    "    \"\"\"\n",
    "    Uses a Keras model with batch size set to 1 to predict the rest of the sequences from the train_set per user.\n",
    "    Finally creates predictions_df where each row represents user, a list pred_items_ranked and a list containing true_ids\n",
    "    from the test_set\n",
    "    :param model: Keras RNN model with batch size set to 1\n",
    "    :param test_set: pandas df containing: user_id, last item_id(s) per user, without their last (chron) item\n",
    "    :param test_left_out_items: pandas df of the last (chron) item of every user in test_test\n",
    "    :param rank_at: maximum of top ranked items per user\n",
    "    :param temp: temperature, 1 means no deviation from model prediction\n",
    "    :return: pandas df where each row represents a user, the columns represent: pred_items_ranked at rank_at,\n",
    "             true_id extracted from test_set\n",
    "    \"\"\"\n",
    "    list_sequences = []\n",
    "    for user_sequence in user_sequences_df:\n",
    "        list_sequences.append(user_sequence)\n",
    "    user_sequences = standard_padding_local(list_sequences, max_seq_len, pad_value=pad_value, stats=False)\n",
    "    \n",
    "    users = user_true_items.index\n",
    "    all_predictions = []\n",
    "    all_true_items = []\n",
    "    from progressbar import progressbar\n",
    "    pBar = progressbar.ProgressBar()\n",
    "\n",
    "    for i, user in enumerate(users):\n",
    "        predictions = []\n",
    "        user_seq = list(user_sequences[i][:max_seq_len])\n",
    "        for i in range(rank_at):\n",
    "            pred_item_id = model.predict_classes(np.array([user_seq,]), batch_size=1)[0]\n",
    "            user_seq.append(pred_item_id)\n",
    "            predictions.append(pred_item_id)\n",
    "\n",
    "        all_true_items.append(user_true_items[user])\n",
    "        all_predictions.append(predictions)\n",
    "\n",
    "    predictions_df = pd.DataFrame(list(zip(user_sequences_df.index, all_predictions, all_true_items)),\n",
    "                              columns=['user', 'pred_items_ranked', 'true_id'])\n",
    "\n",
    "#     return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.67 s, sys: 9.27 s, total: 15.9 s\n",
      "Wall time: 15.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>pred_items_ranked</th>\n",
       "      <th>true_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[37032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[112863]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[197843]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[163242]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[177251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[66586]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[1703]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[50806]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                  pred_items_ranked   true_id\n",
       "0     0  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...   [37032]\n",
       "1    24  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...  [112863]\n",
       "2    33  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...  [197843]\n",
       "3    38  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...  [163242]\n",
       "4    50  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...  [177251]\n",
       "5    66  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...   [66586]\n",
       "6    75  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...    [1703]\n",
       "7    85  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...   [50806]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time get_predictions_local(test_set, test_left_out_items[:8], max_seq_len, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_padding_local(sequences, max_length, pad_value=0.0, stats=True):\n",
    "    \"\"\"\n",
    "    Pads (post) sequences up until max_length with zeros\n",
    "    :param sequences: list of sequences per user\n",
    "    :param max_length: maximum length to pad sequences to\n",
    "    :param stats: print number of sequences, acg sequence length, st_dev of sequence length\n",
    "    :return: tensorflow dataset consisting of the padded sequences\n",
    "    \"\"\"\n",
    "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                        sequences, maxlen=int(max_length), padding='post', truncating='pre', value=pad_value)\n",
    "    if stats:\n",
    "        print('number of sequences:', padded_sequences.shape[0], \n",
    "              '\\navg sequence length:', np.average([i.shape[0] for i in padded_sequences]),\n",
    "              '\\nstd_dev sequence length:', np.std([i.shape[0] for i in padded_sequences]))\n",
    "        \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from Data_prep import split_df_by_users\n",
    "cpus = mp.cpu_count()\n",
    "test_set_splits, test_left_out_items_split = split_df_by_users(test_set, test_left_out_items, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_df = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "user_true_items = test_left_out_items.groupby('user_id')['item_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-8230d3fc9676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparent_r\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Evaluation import get_predictions\n",
    "import time\n",
    "rank_at = 20\n",
    "s = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    manager = mp.Manager()\n",
    "    results = manager.list()\n",
    "    \n",
    "    jobs = []\n",
    "    for cpu in range(4):\n",
    "        jobs.append(mp.Process(target=get_predictions_local, \n",
    "                               args=(test_set_splits[cpu], test_left_out_items_split[cpu][:2], max_seq_len, rank_at)))\n",
    "        \n",
    "    for job in jobs:\n",
    "        job.start()\n",
    "                    \n",
    "    for job in jobs:\n",
    "        job.join()\n",
    "                    \n",
    "print(f'time: {time.time()-s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-7a36f46fb12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_predictions_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'time: {time.time()-s}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Evaluation import get_predictions\n",
    "import time\n",
    "rank_at = 20\n",
    "s = time.time()\n",
    "if __name__ == '__main__':\n",
    "    arguments = []\n",
    "    try:\n",
    "        mp.set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    for cpu in range(cpus):\n",
    "        arguments.append((test_set_splits[cpu], test_left_out_items_split[cpu][:1], max_seq_len, rank_at))\n",
    "\n",
    "    with mp.get_context('spawn').Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.starmap(get_predictions_local, arguments)\n",
    "print(f'time: {time.time()-s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% |##                                                                      |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-4887fa2a3242>\u001b[0m in \u001b[0;36mget_predictions_local\u001b[0;34m(test_set, test_left_out_items, rank_at)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0muser_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mpred_item_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0muser_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_item_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_item_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time get_predictions_local(test_set_splits[0], test_left_out_items_split[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds_df = get_predictions(model, test_set, test_left_out_items[:500], rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "8602      1787\n",
       "465       1330\n",
       "344       1324\n",
       "8154      1204\n",
       "8150      1200\n",
       "10983     1090\n",
       "10984     1090\n",
       "167487    1018\n",
       "167488    1018\n",
       "181637    1015\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('item_id')['user_id'].count().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>pred_items_ranked</th>\n",
       "      <th>true_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[187605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[465]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[202905]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[85878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5100</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[1235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5127</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[76171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5129</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[13126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5147</td>\n",
       "      <td>[100253, 8602, 8602, 8602, 8602, 8602, 8602, 8...</td>\n",
       "      <td>[245718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5181</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[140773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user                                  pred_items_ranked   true_id\n",
       "0       0  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [187605]\n",
       "1      24  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...     [465]\n",
       "2      33  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [202905]\n",
       "3      38  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...   [85878]\n",
       "4      50  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...     [508]\n",
       "..    ...                                                ...       ...\n",
       "495  5100  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...    [1235]\n",
       "496  5127  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...   [76171]\n",
       "497  5129  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...   [13126]\n",
       "498  5147  [100253, 8602, 8602, 8602, 8602, 8602, 8602, 8...  [245718]\n",
       "499  5181  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [140773]\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = pd.read_pickle('CFRNN_res_200_ML_01_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "---\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 0.36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts  recall  precision\n",
       "0        1          1   0.002   0.002000\n",
       "1        5          1   0.002   0.000400\n",
       "2       10          1   0.002   0.000200\n",
       "3       15          1   0.002   0.000133\n",
       "4       20          1   0.002   0.000100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test = get_metrics(preds_df, steps, rank_at)\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import store_LSTM_model\n",
    "# store_path = path + 'results/CFRNN/' + res_ext + '/all_models'\n",
    "store_path = path + 'results/' + res_ext + '/all_models'\n",
    "train_time = np.sum(timing_callback.logs)\n",
    "all_models = store_LSTM_model(store_path, params.copy(), history.history.copy(), train_time, metrics_test, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set Metrics ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         15  0.009014   0.000901\n",
       "3       15         21  0.012620   0.000841\n",
       "4       20         27  0.016226   0.000811"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val_set_vsl = get_metrics(preds_val, 5, 20)\n",
    "metrics_val_set_vsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = 30\n",
    "# min_seq_len = 10\n",
    "# shift_targets_by = 1\n",
    "\n",
    "# from Data_prep import get_x_y_sequences, min_padding\n",
    "# vsl = True # Set for training later\n",
    "\n",
    "# # Train Set\n",
    "# user_sequences_x, user_sequences_y, user_order = get_x_y_sequences(train_set, shift_targets_by)\n",
    "# padded_sequences_x = min_padding(user_sequences_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_y = min_padding(user_sequences_y, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "\n",
    "# # Val Set \n",
    "# user_sequences_val_x, user_sequences_val_y, user_order = get_x_y_sequences(val_set, shift_targets_by, stats=False)\n",
    "# padded_sequences_val_x = min_padding(user_sequences_val_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_val_y = min_padding(user_sequences_val_y, BATCH_SIZE, min_seq_len, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_u_i = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "# test_X = []\n",
    "# test_y = []\n",
    "# all_predictions = []\n",
    "# for user_items in test_set_u_i:\n",
    "#     test_X.append(user_items[-200:-1])\n",
    "#     test_y.append(user_items[-1:])\n",
    "\n",
    "# for i, seq in enumerate(test_X): \n",
    "#     seq = seq.copy()\n",
    "#     predictions = []\n",
    "#     for i in range(20):\n",
    "#         pred_item_id = model.predict_classes(np.array([seq,]), batch_size=1)[0]\n",
    "#         seq.append(pred_item_id)\n",
    "#         predictions.append(pred_item_id)\n",
    "#     all_predictions.append(predictions)\n",
    "    \n",
    "# predictions_df = pd.DataFrame(list(zip(test_set.user_id.unique(), all_predictions, test_y)),\n",
    "#                               columns=['user', 'pred_items_ranked', 'true_id'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
