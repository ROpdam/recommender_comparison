{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0 \n",
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('TF version:', tf.__version__ , '\\nGPU available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets are datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = '../' # Paperspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "# data_path = 'datasets/' # Paperspace\n",
    "data_path = 'Data/Amazon/'\n",
    "file_name = 'Amazon_01_users'\n",
    "# file_name = 'am_like_ml_01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "# data_path = 'datasets/' # Paperspace\n",
    "# data_path = 'Data/ML/'\n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983863</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00FXSELCM</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104506</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294092</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00VDPQ884</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175639</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809981</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00EWC0W3W</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99224</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337932</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01EZKMD64</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>238824</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832820</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01ABS4646</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222085</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating  item_id  user_id\n",
       "4983863  A39ZLL8ILVT2J8  B00FXSELCM 2014-03-24     3.0   104506    73226\n",
       "7294092  A39ZLL8ILVT2J8  B00VDPQ884 2016-06-29     5.0   175639    73226\n",
       "4809981  A39ZLL8ILVT2J8  B00EWC0W3W 2016-08-14     5.0    99224    73226\n",
       "9337932  A39ZLL8ILVT2J8  B01EZKMD64 2016-10-03     5.0   238824    73226\n",
       "8832820  A39ZLL8ILVT2J8  B01ABS4646 2016-12-22     5.0   222085    73226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_items = len(df.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "all_models = pd.read_pickle(path + 'results/' + res_ext + '/all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_id = str(int(all_models.model_id.max()[0]) + 1) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "new_model_id = str(0) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'model_id':new_model_id,\n",
    "'train_time':0,\n",
    "'epochs':0,\n",
    "'BATCH_SIZE':32,\n",
    "'learning_rate':0.1,\n",
    "'delta':0.6,             # Diversity Bias\n",
    "'max_seq_len':30,        # Max length of sequence71=median\n",
    "\n",
    "'val_perc':0.1,          # Percentage of users from df in val and test set\n",
    "'test_perc':0.1, \n",
    "'n_items_val':0,        # Number of last (chronologically) items in val and test set\n",
    "'n_items_test':1,\n",
    "\n",
    "'pad_value':total_items, # Pad with total_items+1 => masked => still use item 0\n",
    "'shift_targets_by':1     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = params['BATCH_SIZE']\n",
    "learning_rate = params['learning_rate']\n",
    "delta = params['delta']\n",
    "max_seq_len = params['max_seq_len']\n",
    "\n",
    "val_perc = params['val_perc']\n",
    "test_perc = params['test_perc']\n",
    "n_items_val = params['n_items_val']\n",
    "n_items_test = params['n_items_test']\n",
    "\n",
    "pad_value = params['pad_value']\n",
    "shift_targets_by = params['shift_targets_by'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "\n",
    "# Train Test Val Split\n",
    "data_split = train_val_test_split(df, val_perc, test_perc, n_items_val, n_items_test, seqs=True)\n",
    "\n",
    "train_set, val_set, val_left_out_items, test_set, test_left_out_items = data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import create_seq_batch_dataset\n",
    " \n",
    "#Train Set\n",
    "train_dataset = create_seq_batch_dataset(df=train_set, \n",
    "                                         shift=shift_targets_by, \n",
    "                                         max_seq_len=max_seq_len, \n",
    "                                         pad_value=pad_value, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         stats=False,\n",
    "                                         drop_remainder=True)\n",
    "\n",
    "#Val Set\n",
    "val_dataset = create_seq_batch_dataset(df=val_set, \n",
    "                                       shift=shift_targets_by, \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       pad_value=pad_value, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       stats=False,\n",
    "                                       drop_remainder=True)\n",
    "\n",
    "# #Test Set\n",
    "# test_dataset = create_seq_batch_dataset(df=test_set, \n",
    "#                                        shift=shift_targets_by, \n",
    "#                                        max_seq_len=max_seq_len, \n",
    "#                                        pad_value=pad_value, \n",
    "#                                        batch_size=BATCH_SIZE, \n",
    "#                                        stats=False,\n",
    "#                                        drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks\n",
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code: https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, # +1 because padding is total_items+1\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "## Add Custom Metric=Recall and Loss=Diversity Bias Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 100)           24746600  \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (32, None, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 247465)        5196765   \n",
      "=================================================================\n",
      "Total params: 29,953,045\n",
      "Trainable params: 29,953,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "## Configure Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '_' + file_name[:2] #ML or Am\n",
    "# directory = './ckpts/ckpts' \n",
    "directory = '../ckpts/ckpts'\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = directory + '_' + str(params['model_id'])\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "from Helpers import TimingCallback\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix,    \n",
    "                                                         monitor = 'val_recall',    \n",
    "                                                         mode = 'max',    \n",
    "                                                         save_best_only = True,\n",
    "                                                         save_weights_only = True)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_recall',\n",
    "                                                           min_delta = 0.0001,\n",
    "                                                           mode = 'max',\n",
    "                                                           patience = 15)\n",
    "    \n",
    "\n",
    "timing_callback = TimingCallback()\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stopping_callback, timing_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Batches: 406\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "print('#Batches:', tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LSTM with max sequence length: 30\n",
      "Epoch 1/2\n",
      "     35/Unknown - 4s 117ms/step - loss: 1.7891 - recall: 0.0000e+00WARNING:tensorflow:Can save best model only with val_recall available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_recall` which is not available. Available metrics are: loss,recall\n",
      "     35/Unknown - 4s 117ms/step - loss: 1.7891 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-dd3a19975bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Fitting LSTM with max sequence length:', str(max_seq_len))\n",
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Loss, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = history.history\n",
    "plt.plot(results['loss'])\n",
    "plt.plot(results['val_loss'])\n",
    "plt.show()\n",
    "plt.plot(results['recall'])\n",
    "plt.plot(results['val_recall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdd446d4be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items,\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias\n",
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "initial_epoch = 71\n",
    "total_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "3034/3034 [==============================] - 542s 179ms/step - loss: 1.2271 - recall: 0.1093 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3034/3034 [==============================] - 534s 176ms/step - loss: 1.2269 - recall: 0.1096 - val_loss: 1.8627 - val_recall: 0.1098\n",
      "Epoch 74/100\n",
      "3034/3034 [==============================] - 537s 177ms/step - loss: 1.2265 - recall: 0.1099 - val_loss: 1.8627 - val_recall: 0.1100\n",
      "Epoch 75/100\n",
      "3034/3034 [==============================] - 532s 175ms/step - loss: 1.2262 - recall: 0.1101 - val_loss: 1.8627 - val_recall: 0.1102\n",
      "Epoch 76/100\n",
      "3034/3034 [==============================] - 534s 176ms/step - loss: 1.2259 - recall: 0.1104 - val_loss: 1.8628 - val_recall: 0.1105\n",
      "Epoch 77/100\n",
      "3034/3034 [==============================] - 536s 177ms/step - loss: 1.2256 - recall: 0.1108 - val_loss: 1.8628 - val_recall: 0.1110\n",
      "Epoch 78/100\n",
      "3034/3034 [==============================] - 538s 177ms/step - loss: 1.2253 - recall: 0.1113 - val_loss: 1.8629 - val_recall: 0.1116\n",
      "Epoch 79/100\n",
      "3034/3034 [==============================] - 535s 176ms/step - loss: 1.2250 - recall: 0.1118 - val_loss: 1.8629 - val_recall: 0.1120\n",
      "Epoch 80/100\n",
      "3034/3034 [==============================] - 538s 177ms/step - loss: 1.2247 - recall: 0.1122 - val_loss: 1.8630 - val_recall: 0.1124\n",
      "Epoch 81/100\n",
      "3034/3034 [==============================] - 537s 177ms/step - loss: 1.2244 - recall: 0.1125 - val_loss: 1.8630 - val_recall: 0.1126\n",
      "Epoch 82/100\n",
      "3034/3034 [==============================] - 539s 178ms/step - loss: 1.2241 - recall: 0.1127 - val_loss: 1.8631 - val_recall: 0.1128\n",
      "Epoch 83/100\n",
      "3034/3034 [==============================] - 543s 179ms/step - loss: 1.2239 - recall: 0.1128 - val_loss: 1.8632 - val_recall: 0.1129\n",
      "Epoch 84/100\n",
      "3034/3034 [==============================] - 537s 177ms/step - loss: 1.2236 - recall: 0.1129 - val_loss: 1.8633 - val_recall: 0.1130\n",
      "Epoch 85/100\n",
      "3034/3034 [==============================] - 540s 178ms/step - loss: 1.2233 - recall: 0.1130 - val_loss: 1.8634 - val_recall: 0.1131\n",
      "Epoch 86/100\n",
      "3034/3034 [==============================] - 540s 178ms/step - loss: 1.2231 - recall: 0.1132 - val_loss: 1.8635 - val_recall: 0.1133\n",
      "Epoch 87/100\n",
      "3034/3034 [==============================] - 532s 175ms/step - loss: 1.2228 - recall: 0.1134 - val_loss: 1.8636 - val_recall: 0.1135\n",
      "Epoch 88/100\n",
      "3034/3034 [==============================] - 529s 174ms/step - loss: 1.2225 - recall: 0.1137 - val_loss: 1.8637 - val_recall: 0.1138\n",
      "Epoch 89/100\n",
      "3034/3034 [==============================] - 536s 177ms/step - loss: 1.2223 - recall: 0.1139 - val_loss: 1.8637 - val_recall: 0.1141\n",
      "Epoch 90/100\n",
      "3034/3034 [==============================] - 535s 176ms/step - loss: 1.2220 - recall: 0.1144 - val_loss: 1.8638 - val_recall: 0.1146\n",
      "Epoch 91/100\n",
      "3034/3034 [==============================] - 547s 180ms/step - loss: 1.2218 - recall: 0.1150 - val_loss: 1.8639 - val_recall: 0.1155\n",
      "Epoch 92/100\n",
      "3034/3034 [==============================] - 546s 180ms/step - loss: 1.2215 - recall: 0.1160 - val_loss: 1.8640 - val_recall: 0.1166\n",
      "Epoch 93/100\n",
      "3034/3034 [==============================] - 548s 181ms/step - loss: 1.2213 - recall: 0.1172 - val_loss: 1.8641 - val_recall: 0.1178\n",
      "Epoch 94/100\n",
      "3034/3034 [==============================] - 549s 181ms/step - loss: 1.2210 - recall: 0.1184 - val_loss: 1.8642 - val_recall: 0.1190\n",
      "Epoch 95/100\n",
      "3034/3034 [==============================] - 550s 181ms/step - loss: 1.2208 - recall: 0.1196 - val_loss: 1.8643 - val_recall: 0.1201\n",
      "Epoch 96/100\n",
      "3034/3034 [==============================] - 548s 181ms/step - loss: 1.2205 - recall: 0.1206 - val_loss: 1.8644 - val_recall: 0.1211\n",
      "Epoch 97/100\n",
      "3034/3034 [==============================] - 552s 182ms/step - loss: 1.2203 - recall: 0.1215 - val_loss: 1.8645 - val_recall: 0.1219\n",
      "Epoch 98/100\n",
      "3034/3034 [==============================] - 553s 182ms/step - loss: 1.2201 - recall: 0.1222 - val_loss: 1.8646 - val_recall: 0.1224\n",
      "Epoch 99/100\n",
      "3034/3034 [==============================] - 557s 183ms/step - loss: 1.2198 - recall: 0.1226 - val_loss: 1.8647 - val_recall: 0.1228\n",
      "Epoch 100/100\n",
      "3034/3034 [==============================] - 555s 183ms/step - loss: 1.2196 - recall: 0.1230 - val_loss: 1.8648 - val_recall: 0.1231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=total_epochs, \n",
    "                    callbacks=callbacks, \n",
    "                    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint from: ../ckpts/ckpts_0_Am/ckpt\n"
     ]
    }
   ],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, \n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = 1,\n",
    "                         return_sequences=False)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print('Latest checkpoint from:', tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "- CREATE MULTIPROCESSING FOR PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import leave_users_out\n",
    "def split_df_by_users(df, left_out_items, n_splits):\n",
    "    user_list = df.user_id.unique()\n",
    "    data_size = len(user_list)/n_splits\n",
    "    leftovers = 0\n",
    "    \n",
    "    if data_size - int(data_size) > 0:\n",
    "        leftovers = n_splits * (data_size - int(data_size))-1   \n",
    "\n",
    "    split = [n for n in range(0, len(user_list), int(data_size))]\n",
    "    split[-1] = split[-1] + int(leftovers)\n",
    "    data_split = [data_list[split[n]:split[n+1]] for n in range(len(split)-1)]\n",
    "\n",
    "    df_splits = []\n",
    "    left_out_items_split = []\n",
    "    for users_split in data_split:\n",
    "        _, df_subset = leave_users_out(test_set, list(users_split))\n",
    "        _, subset = leave_users_out(left_out_items, list(users_split))\n",
    "        \n",
    "        df_splits.append(df_subset)\n",
    "        left_out_items_split.append(subset)\n",
    "        \n",
    "    return df_splits, left_out_items_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = mp.cpu_count()\n",
    "test_set_splits, test_left_out_items_split = split_df_by_users(test_set, test_left_out_items, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "rank_at = 20\n",
    "if __name__ == '__main__':\n",
    "    arguments = []\n",
    "    for cpu in cpus:\n",
    "        arguments.append((model, test_set_splits[cpu], test_left_out_items_split[cpu], rank_at))\n",
    "    \n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.starmap(get_predictions, [(1,2),(1,3),(1,4)])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x*2 + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "from Evaluation import get_predictions\n",
    "preds_df = get_predictions(model, test_set, test_left_out_items[:500], rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "8602      1787\n",
       "465       1330\n",
       "344       1324\n",
       "8154      1204\n",
       "8150      1200\n",
       "10983     1090\n",
       "10984     1090\n",
       "167487    1018\n",
       "167488    1018\n",
       "181637    1015\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('item_id')['user_id'].count().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>pred_items_ranked</th>\n",
       "      <th>true_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[187605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[465]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[202905]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>[8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...</td>\n",
       "      <td>[85878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>5100</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[1235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5127</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[76171]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5129</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[13126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>5147</td>\n",
       "      <td>[100253, 8602, 8602, 8602, 8602, 8602, 8602, 8...</td>\n",
       "      <td>[245718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5181</td>\n",
       "      <td>[7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...</td>\n",
       "      <td>[140773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user                                  pred_items_ranked   true_id\n",
       "0       0  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [187605]\n",
       "1      24  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...     [465]\n",
       "2      33  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [202905]\n",
       "3      38  [8602, 8602, 8602, 8602, 8602, 8602, 8602, 860...   [85878]\n",
       "4      50  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...     [508]\n",
       "..    ...                                                ...       ...\n",
       "495  5100  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...    [1235]\n",
       "496  5127  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...   [76171]\n",
       "497  5129  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...   [13126]\n",
       "498  5147  [100253, 8602, 8602, 8602, 8602, 8602, 8602, 8...  [245718]\n",
       "499  5181  [7659, 7659, 7659, 7659, 7659, 7659, 7659, 765...  [140773]\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = pd.read_pickle('CFRNN_res_200_ML_01_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "---\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 0.36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts  recall  precision\n",
       "0        1          1   0.002   0.002000\n",
       "1        5          1   0.002   0.000400\n",
       "2       10          1   0.002   0.000200\n",
       "3       15          1   0.002   0.000133\n",
       "4       20          1   0.002   0.000100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test = get_metrics(preds_df, steps, rank_at)\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import store_LSTM_model\n",
    "# store_path = path + 'results/CFRNN/' + res_ext + '/all_models'\n",
    "store_path = path + 'results/' + res_ext + '/all_models'\n",
    "train_time = np.sum(timing_callback.logs)\n",
    "all_models = store_LSTM_model(store_path, params.copy(), history.history.copy(), train_time, metrics_test, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set Metrics ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         15  0.009014   0.000901\n",
       "3       15         21  0.012620   0.000841\n",
       "4       20         27  0.016226   0.000811"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val_set_vsl = get_metrics(preds_val, 5, 20)\n",
    "metrics_val_set_vsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = 30\n",
    "# min_seq_len = 10\n",
    "# shift_targets_by = 1\n",
    "\n",
    "# from Data_prep import get_x_y_sequences, min_padding\n",
    "# vsl = True # Set for training later\n",
    "\n",
    "# # Train Set\n",
    "# user_sequences_x, user_sequences_y, user_order = get_x_y_sequences(train_set, shift_targets_by)\n",
    "# padded_sequences_x = min_padding(user_sequences_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_y = min_padding(user_sequences_y, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "\n",
    "# # Val Set \n",
    "# user_sequences_val_x, user_sequences_val_y, user_order = get_x_y_sequences(val_set, shift_targets_by, stats=False)\n",
    "# padded_sequences_val_x = min_padding(user_sequences_val_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_val_y = min_padding(user_sequences_val_y, BATCH_SIZE, min_seq_len, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_u_i = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "# test_X = []\n",
    "# test_y = []\n",
    "# all_predictions = []\n",
    "# for user_items in test_set_u_i:\n",
    "#     test_X.append(user_items[-200:-1])\n",
    "#     test_y.append(user_items[-1:])\n",
    "\n",
    "# for i, seq in enumerate(test_X): \n",
    "#     seq = seq.copy()\n",
    "#     predictions = []\n",
    "#     for i in range(20):\n",
    "#         pred_item_id = model.predict_classes(np.array([seq,]), batch_size=1)[0]\n",
    "#         seq.append(pred_item_id)\n",
    "#         predictions.append(pred_item_id)\n",
    "#     all_predictions.append(predictions)\n",
    "    \n",
    "# predictions_df = pd.DataFrame(list(zip(test_set.user_id.unique(), all_predictions, test_y)),\n",
    "#                               columns=['user', 'pred_items_ranked', 'true_id'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
