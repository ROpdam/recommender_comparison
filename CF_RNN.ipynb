{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/robin.opdam/Dropbox/'\n",
    "# path = '/Users/Robin/Dropbox'\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data\n",
    "# file_name = 'amazon_clothing_shoes_jewelry_data' \n",
    "\n",
    "#2m user above 5 ratings\n",
    "# file_name = 'amazon_csj_2m'\n",
    "\n",
    "#0.63m user above 5 ratings\n",
    "# file_name = 'df_amazon_csj_with_styles_0.63m_u_above_5_rui' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data\n",
    "# file_name = 'ml-25m'\n",
    "\n",
    "# 2m subset\n",
    "# file_name = '2m-ml'\n",
    "\n",
    "# 0.7m subset\n",
    "# file_name = 'ml_0.7_u_above_5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time sorted ml 2m dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25m rows sorted per user on datetime\n",
    "file_name = 'ml-25m_sorted_u_dt'\n",
    "\n",
    "#0.7m rows sorted per user on datetime\n",
    "# file_name = 'ml_07m_sorted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df.user.astype('category').cat.codes\n",
    "df['item_id'] = df.item.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave users out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_users_out(full_data, leave_out):\n",
    "    full_data['index'] = full_data.index\n",
    "    user_index_df = full_data.groupby('user')['index'].apply(list)\n",
    "    users = np.random.choice(list(user_index_df.index), leave_out, replace=False)\n",
    "    users_indices = []\n",
    "    \n",
    "    for user in users:\n",
    "        users_indices.extend(user_index_df.loc[user])\n",
    "    \n",
    "    sub_set = full_data.loc[users_indices]\n",
    "    remaining = full_data.drop(users_indices)\n",
    "    \n",
    "    return remaining.drop(columns=['index']), sub_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leftovers, new_df = leave_users_out(df, 4500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "First filtering active users and rated items with x or more ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = df.groupby('user')['rating'].count()\n",
    "item_ratings = df.groupby('item')['rating'].count()\n",
    "norpu = user_ratings.mean()\n",
    "norpi = item_ratings.mean()\n",
    "total_users = df.user.unique().size\n",
    "total_items = df.item.unique().size\n",
    "sparseness = 1 - len(df) / (len(df['user'].unique()) * len(df['item'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows ', len(df), '\\n#ratings', len(df[df['rating'] != 0]), '\\n#ratings/user', round(norpu,2), '\\n#ratings/item', round(norpi,2), '\\naverage rating', \"{0:.2f}\".format(np.average(df['rating'])), '\\n#users ', df['user'].unique().size, '\\n#items ', df['item'].unique().size, '\\nsparse ', round(sparseness,5), '%')\n",
    "\n",
    "df.hist(column='rating', bins=5, grid=False)\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.xticks(range(1,6))\n",
    "plt.savefig('Plots/Deliverables/rating_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(item_ratings, bins = 2000)\n",
    "plt.xlim([0,100])\n",
    "plt.title('#ratings per item distribution (1000 bins)')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_item_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(user_ratings, bins = 2000)\n",
    "plt.xlim([0,50])\n",
    "plt.title('#ratings per user distribution (1000 bins)')\n",
    "plt.xlabel('Users')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_user_dist_ml')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code:https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 100 people **train df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = 500\n",
    "df, test_df = leave_users_out(df_og, test_users)\n",
    "df['item_id'] = df.item_id.astype('category').cat.codes\n",
    "df['user_id'] = df.user_id.astype('category').cat.codes\n",
    "n_items = len(df_og.item_id.unique())\n",
    "\n",
    "print('total number of items:', n_items)\n",
    "print('total users:', len(df_og.user_id.unique()))\n",
    "print('number of train users:', len(df.user_id.unique()))\n",
    "print('number of test users:', test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Train and Target sequences\n",
    "Create the **sequences** from the item_ids per user (already sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_x = []\n",
    "user_sequences_y = []\n",
    "\n",
    "lengths = []\n",
    "for u in df.user_id.unique():\n",
    "    user_item_seq = np.array(df[df['user_id']==u]['item_id'])\n",
    "    user_sequences_x.append(user_item_seq[:-1])\n",
    "    user_sequences_y.append(user_item_seq[1:])\n",
    "    lengths.append(len(user_item_seq))\n",
    "print('number of sequences x:', len(user_sequences_x), \n",
    "      '\\navg sequence length x:', np.average(lengths),\n",
    "      '\\nstd_dev sequence length x:', np.round(np.std(lengths),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Padding\n",
    "**pad** the sequences (needed for rectangular tf.data.Dataset):\n",
    "- add zeros if they are too short\n",
    "- remove item ids from the beginning if they are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 250\n",
    "padded_sequences_x = tf.keras.preprocessing.sequence.pad_sequences(user_sequences_x, maxlen=max_length, padding='post', truncating='pre')\n",
    "padded_sequences_y = tf.keras.preprocessing.sequence.pad_sequences(user_sequences_y, maxlen=max_length, padding='post', truncating='pre')\n",
    "print('number of sequences x:', padded_sequences_x.shape[0], \n",
    "      '\\navg sequence length x:', np.average([i.shape[0] for i in padded_sequences_x]),\n",
    "      '\\nstd_dev sequence length x:', np.std([i.shape[0] for i in padded_sequences_x]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create Dataset\n",
    "**create batch dataset**\n",
    "- sequences_x inputs\n",
    "- sequences_y actuals\n",
    "- batches of size BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) \n",
    "\n",
    "#normal sequence input\n",
    "sequences_data_x = tf.data.Dataset.from_tensor_slices(padded_sequences_x) \n",
    "sequences_data_y = tf.data.Dataset.from_tensor_slices(padded_sequences_y) \n",
    "dataset = tf.data.Dataset.zip((sequences_data_x, sequences_data_y))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example, target_example in  dataset.take(1).as_numpy_iterator():\n",
    "    print ('Input data: ', input_example)\n",
    "    print ('Target data:', target_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "for i, o in dataset.take(1).as_numpy_iterator():\n",
    "    print('input:', i.shape, '\\n\\noutput:', o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_items, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(n_items, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(units=rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=False, #Reset cell states with each batch\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(n_items)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**build model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "n_items = n_items,\n",
    "embedding_dim = embedding_dim,\n",
    "rnn_units = rnn_units,\n",
    "batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Add Loss\n",
    "<br>\n",
    "one hot encode labels for dimensionality match of LSTM output\n",
    "<br> \n",
    "**Added one hot encoding of the labels to match logits output after dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    oh_labels = tf.keras.backend.one_hot(tf.dtypes.cast(labels, tf.int32), n_items)\n",
    "    return tf.keras.losses.categorical_crossentropy(oh_labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='Adagrad', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Try Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_preds = model(input_example_batch)\n",
    "    print(example_batch_preds.shape, \"# (batch_size, sequence_length, n_items)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**model summmary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Configure Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './rnn_train_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(n_items, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "                   \n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Try Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(columns=['user', 'pred_seq', 'true_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "\n",
    "for u in test_df.user_id.unique(): #Note: Can use multiprocessing for this\n",
    "    generated_predictions = []\n",
    "    user_item_seq = np.array(test_df[test_df['user_id']==u]['item_id'])\n",
    "    half_test_seq = user_item_seq[:int(len(user_item_seq)/2)]\n",
    "    half_test_seq = half_test_seq.reshape(-1,1).transpose()\n",
    "    other_half = user_item_seq[int(len(user_item_seq)/2):]\n",
    "\n",
    "    #Predict\n",
    "    for item in half_test_seq[0]:\n",
    "        predictions = model(half_test_seq)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        half_test_seq = np.append(half_test_seq, predicted_id).reshape(-1,1).transpose()\n",
    "\n",
    "        half_test_seq = tf.expand_dims([predicted_id], 0)\n",
    "        generated_predictions.append(predicted_id)\n",
    "        \n",
    "    predictions_df = predictions_df.append({'user':u, 'pred_seq':generated_predictions, 'true_seq':other_half}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_seq = np.array(test_df[test_df['user_id']==659]['item_id'])\n",
    "half_test_seq = user_item_seq[:int(len(user_item_seq)/2)]\n",
    "half_test_seq = half_test_seq.reshape(-1,1).transpose()\n",
    "other_half = user_item_seq[int(len(user_item_seq)/2):]\n",
    "\n",
    "#Predict\n",
    "for item in half_test_seq[0]:\n",
    "    predictions = model(half_test_seq)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    half_test_seq = np.append(half_test_seq, predicted_id).reshape(-1,1).transpose()\n",
    "    print('User:', u)\n",
    "    print(half_test_seq, predicted_id)\n",
    "    generated_predictions.append(predicted_id)\n",
    "\n",
    "predictions_df = predictions_df.append({'user':u, 'pred_seq':generated_predictions, 'true_seq':other_half}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_df.iloc[0]['true_seq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
