{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0 \n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('TF version:', tf.__version__ , '\\nGPU available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets are datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '../' # Paperspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "data_path = 'datasets/' # Paperspace\n",
    "# data_path = 'Data/Am/'\n",
    "file_name = 'Amazon_01_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "# data_path = 'datasets/' # Paperspace\n",
    "# data_path = 'Data/ML/'\n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983863</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00FXSELCM</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104506</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294092</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00VDPQ884</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175639</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809981</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00EWC0W3W</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99224</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337932</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01EZKMD64</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>238824</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832820</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01ABS4646</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222085</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating  item_id  user_id\n",
       "4983863  A39ZLL8ILVT2J8  B00FXSELCM 2014-03-24     3.0   104506    73226\n",
       "7294092  A39ZLL8ILVT2J8  B00VDPQ884 2016-06-29     5.0   175639    73226\n",
       "4809981  A39ZLL8ILVT2J8  B00EWC0W3W 2016-08-14     5.0    99224    73226\n",
       "9337932  A39ZLL8ILVT2J8  B01EZKMD64 2016-10-03     5.0   238824    73226\n",
       "8832820  A39ZLL8ILVT2J8  B01ABS4646 2016-12-22     5.0   222085    73226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_items = len(df.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "all_models = pd.read_pickle(path + 'results/' + res_ext + '/all_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_id = str(int(all_models.model_id.max()[0]) + 1) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "new_model_id = str(0) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'model_id':new_model_id,\n",
    "'train_time':0,\n",
    "'epochs':0,\n",
    "'BATCH_SIZE':32,\n",
    "'learning_rate':0.1,\n",
    "'delta':0.2,             # Diversity Bias\n",
    "'max_seq_len':15,        # Max length of sequence71=median\n",
    "\n",
    "'val_perc':0.1,          # Percentage of users from df in val and test set\n",
    "'test_perc':0.1, \n",
    "'n_items_val':0,        # Number of last (chronologically) items in val and test set\n",
    "'n_items_test':1,\n",
    "\n",
    "'pad_value':total_items, # Pad with total_items+1 => masked => still use item 0\n",
    "'shift_targets_by':1     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = params['BATCH_SIZE']\n",
    "learning_rate = params['learning_rate']\n",
    "delta = params['delta']\n",
    "max_seq_len = params['max_seq_len']\n",
    "\n",
    "val_perc = params['val_perc']\n",
    "test_perc = params['test_perc']\n",
    "n_items_val = params['n_items_val']\n",
    "n_items_test = params['n_items_test']\n",
    "\n",
    "pad_value = params['pad_value']\n",
    "shift_targets_by = params['shift_targets_by'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "\n",
    "# Train Test Val Split\n",
    "data_split = train_val_test_split(df, val_perc, test_perc, n_items_val, n_items_test, seqs=True)\n",
    "\n",
    "train_set, val_set, val_left_out_items, test_set, test_left_out_items = data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import create_seq_batch_dataset\n",
    " \n",
    "#Train Set\n",
    "train_dataset = create_seq_batch_dataset(df=train_set, \n",
    "                                         shift=shift_targets_by, \n",
    "                                         max_seq_len=max_seq_len, \n",
    "                                         pad_value=pad_value, \n",
    "                                         batch_size=BATCH_SIZE, \n",
    "                                         stats=False,\n",
    "                                         drop_remainder=True)\n",
    "\n",
    "#Val Set\n",
    "val_dataset = create_seq_batch_dataset(df=val_set, \n",
    "                                       shift=shift_targets_by, \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       pad_value=pad_value, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       stats=False,\n",
    "                                       drop_remainder=True)\n",
    "\n",
    "# #Test Set\n",
    "# test_dataset = create_seq_batch_dataset(df=test_set, \n",
    "#                                        shift=shift_targets_by, \n",
    "#                                        max_seq_len=max_seq_len, \n",
    "#                                        pad_value=pad_value, \n",
    "#                                        batch_size=BATCH_SIZE, \n",
    "#                                        stats=False,\n",
    "#                                        drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks\n",
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code: https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, # +1 because padding is total_items+1\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "## Add Custom Metric=Recall and Loss=Diversity Bias Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 100)           24746600  \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (32, None, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 247465)        5196765   \n",
      "=================================================================\n",
      "Total params: 29,953,045\n",
      "Trainable params: 29,953,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "## Configure Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '_' + file_name[:2] #ML or Am\n",
    "# directory = './ckpts/ckpts' \n",
    "directory = '../ckpts/ckpts'\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = directory + '_' + str(params['model_id'])\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "from Helpers import TimingCallback\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix,    \n",
    "                                                         monitor = 'val_recall',    \n",
    "                                                         mode = 'max',    \n",
    "                                                         save_best_only = True,\n",
    "                                                         save_weights_only = True)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_recall',\n",
    "                                                           min_delta = 0.0001,\n",
    "                                                           mode = 'max',\n",
    "                                                           patience = 15)\n",
    "    \n",
    "\n",
    "timing_callback = TimingCallback()\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stopping_callback, timing_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Batches: 3034\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "print('#Batches:', tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LSTM with max sequence length: 15\n",
      "Epoch 1/100\n",
      "3034/3034 [==============================] - 569s 187ms/step - loss: 1.5102 - recall: 1.4662e-06 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3034/3034 [==============================] - 548s 181ms/step - loss: 1.5045 - recall: 4.8310e-05 - val_loss: 2.0740 - val_recall: 1.0102e-04\n",
      "Epoch 3/100\n",
      "3034/3034 [==============================] - 549s 181ms/step - loss: 1.4956 - recall: 1.8207e-04 - val_loss: 2.0593 - val_recall: 2.8525e-04\n",
      "Epoch 4/100\n",
      "3034/3034 [==============================] - 551s 182ms/step - loss: 1.4623 - recall: 5.4745e-04 - val_loss: 2.0097 - val_recall: 9.7868e-04\n",
      "Epoch 5/100\n",
      "3034/3034 [==============================] - 554s 183ms/step - loss: 1.4167 - recall: 0.0017 - val_loss: 1.9815 - val_recall: 0.0023\n",
      "Epoch 6/100\n",
      "3034/3034 [==============================] - 566s 187ms/step - loss: 1.3934 - recall: 0.0033 - val_loss: 1.9662 - val_recall: 0.0045\n",
      "Epoch 7/100\n",
      "3034/3034 [==============================] - 570s 188ms/step - loss: 1.3784 - recall: 0.0056 - val_loss: 1.9546 - val_recall: 0.0066\n",
      "Epoch 8/100\n",
      "3034/3034 [==============================] - 566s 187ms/step - loss: 1.3664 - recall: 0.0074 - val_loss: 1.9454 - val_recall: 0.0082\n",
      "Epoch 9/100\n",
      "3034/3034 [==============================] - 570s 188ms/step - loss: 1.3566 - recall: 0.0092 - val_loss: 1.9380 - val_recall: 0.0103\n",
      "Epoch 10/100\n",
      "3034/3034 [==============================] - 568s 187ms/step - loss: 1.3484 - recall: 0.0115 - val_loss: 1.9319 - val_recall: 0.0127\n",
      "Epoch 11/100\n",
      "3034/3034 [==============================] - 569s 188ms/step - loss: 1.3413 - recall: 0.0139 - val_loss: 1.9267 - val_recall: 0.0151\n",
      "Epoch 12/100\n",
      "3034/3034 [==============================] - 569s 187ms/step - loss: 1.3351 - recall: 0.0163 - val_loss: 1.9224 - val_recall: 0.0174\n",
      "Epoch 13/100\n",
      "3034/3034 [==============================] - 570s 188ms/step - loss: 1.3297 - recall: 0.0184 - val_loss: 1.9186 - val_recall: 0.0192\n",
      "Epoch 14/100\n",
      "3034/3034 [==============================] - 567s 187ms/step - loss: 1.3249 - recall: 0.0200 - val_loss: 1.9154 - val_recall: 0.0207\n",
      "Epoch 15/100\n",
      "3034/3034 [==============================] - 569s 187ms/step - loss: 1.3207 - recall: 0.0215 - val_loss: 1.9127 - val_recall: 0.0223\n",
      "Epoch 16/100\n",
      "3034/3034 [==============================] - 569s 188ms/step - loss: 1.3169 - recall: 0.0230 - val_loss: 1.9103 - val_recall: 0.0238\n",
      "Epoch 17/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.3134 - recall: 0.0247 - val_loss: 1.9081 - val_recall: 0.0255\n",
      "Epoch 18/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.3103 - recall: 0.0263 - val_loss: 1.9063 - val_recall: 0.0271\n",
      "Epoch 19/100\n",
      "3034/3034 [==============================] - 567s 187ms/step - loss: 1.3074 - recall: 0.0280 - val_loss: 1.9047 - val_recall: 0.0290\n",
      "Epoch 20/100\n",
      "3034/3034 [==============================] - 569s 187ms/step - loss: 1.3048 - recall: 0.0298 - val_loss: 1.9032 - val_recall: 0.0307\n",
      "Epoch 21/100\n",
      "3034/3034 [==============================] - 569s 187ms/step - loss: 1.3024 - recall: 0.0317 - val_loss: 1.9020 - val_recall: 0.0327\n",
      "Epoch 22/100\n",
      "3034/3034 [==============================] - 568s 187ms/step - loss: 1.3002 - recall: 0.0336 - val_loss: 1.9009 - val_recall: 0.0346\n",
      "Epoch 23/100\n",
      "3034/3034 [==============================] - 567s 187ms/step - loss: 1.2982 - recall: 0.0355 - val_loss: 1.8999 - val_recall: 0.0365\n",
      "Epoch 24/100\n",
      "3034/3034 [==============================] - 568s 187ms/step - loss: 1.2963 - recall: 0.0374 - val_loss: 1.8990 - val_recall: 0.0383\n",
      "Epoch 25/100\n",
      "3034/3034 [==============================] - 572s 188ms/step - loss: 1.2946 - recall: 0.0392 - val_loss: 1.8983 - val_recall: 0.0401\n",
      "Epoch 26/100\n",
      "3034/3034 [==============================] - 572s 189ms/step - loss: 1.2930 - recall: 0.0411 - val_loss: 1.8976 - val_recall: 0.0421\n",
      "Epoch 27/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2914 - recall: 0.0432 - val_loss: 1.8971 - val_recall: 0.0442\n",
      "Epoch 28/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2900 - recall: 0.0451 - val_loss: 1.8966 - val_recall: 0.0461\n",
      "Epoch 29/100\n",
      "3034/3034 [==============================] - 572s 188ms/step - loss: 1.2887 - recall: 0.0470 - val_loss: 1.8961 - val_recall: 0.0477\n",
      "Epoch 30/100\n",
      "3034/3034 [==============================] - 572s 188ms/step - loss: 1.2874 - recall: 0.0486 - val_loss: 1.8957 - val_recall: 0.0494\n",
      "Epoch 31/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2863 - recall: 0.0503 - val_loss: 1.8954 - val_recall: 0.0511\n",
      "Epoch 32/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2852 - recall: 0.0518 - val_loss: 1.8951 - val_recall: 0.0526\n",
      "Epoch 33/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2841 - recall: 0.0533 - val_loss: 1.8948 - val_recall: 0.0539\n",
      "Epoch 34/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2831 - recall: 0.0543 - val_loss: 1.8946 - val_recall: 0.0547\n",
      "Epoch 35/100\n",
      "3034/3034 [==============================] - 572s 188ms/step - loss: 1.2822 - recall: 0.0552 - val_loss: 1.8944 - val_recall: 0.0558\n",
      "Epoch 36/100\n",
      "3034/3034 [==============================] - 572s 189ms/step - loss: 1.2813 - recall: 0.0563 - val_loss: 1.8943 - val_recall: 0.0568\n",
      "Epoch 37/100\n",
      "3034/3034 [==============================] - 572s 188ms/step - loss: 1.2804 - recall: 0.0572 - val_loss: 1.8941 - val_recall: 0.0577\n",
      "Epoch 38/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.2796 - recall: 0.0581 - val_loss: 1.8940 - val_recall: 0.0587\n",
      "Epoch 39/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.2788 - recall: 0.0593 - val_loss: 1.8939 - val_recall: 0.0599\n",
      "Epoch 40/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.2781 - recall: 0.0605 - val_loss: 1.8939 - val_recall: 0.0610\n",
      "Epoch 41/100\n",
      "3034/3034 [==============================] - 566s 187ms/step - loss: 1.2773 - recall: 0.0614 - val_loss: 1.8938 - val_recall: 0.0619\n",
      "Epoch 42/100\n",
      "3034/3034 [==============================] - 568s 187ms/step - loss: 1.2767 - recall: 0.0623 - val_loss: 1.8938 - val_recall: 0.0627\n",
      "Epoch 43/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2760 - recall: 0.0631 - val_loss: 1.8938 - val_recall: 0.0634\n",
      "Epoch 44/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.2754 - recall: 0.0638 - val_loss: 1.8938 - val_recall: 0.0641\n",
      "Epoch 45/100\n",
      "3034/3034 [==============================] - 570s 188ms/step - loss: 1.2748 - recall: 0.0645 - val_loss: 1.8938 - val_recall: 0.0649\n",
      "Epoch 46/100\n",
      "3034/3034 [==============================] - 571s 188ms/step - loss: 1.2742 - recall: 0.0655 - val_loss: 1.8939 - val_recall: 0.0662\n",
      "Epoch 47/100\n",
      "3034/3034 [==============================] - 573s 189ms/step - loss: 1.2737 - recall: 0.0668 - val_loss: 1.8939 - val_recall: 0.0674\n",
      "Epoch 48/100\n",
      "3034/3034 [==============================] - 577s 190ms/step - loss: 1.2731 - recall: 0.0681 - val_loss: 1.8940 - val_recall: 0.0687\n",
      "Epoch 49/100\n",
      "3034/3034 [==============================] - 576s 190ms/step - loss: 1.2726 - recall: 0.0691 - val_loss: 1.8940 - val_recall: 0.0696\n",
      "Epoch 50/100\n",
      "3034/3034 [==============================] - 577s 190ms/step - loss: 1.2721 - recall: 0.0702 - val_loss: 1.8941 - val_recall: 0.0707\n",
      "Epoch 51/100\n",
      " 214/3034 [=>............................] - ETA: 8:07 - loss: 1.2666 - recall: 0.0707"
     ]
    }
   ],
   "source": [
    "print('Fitting LSTM with max sequence length:', str(max_seq_len))\n",
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Loss, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = history.history()\n",
    "plt.plot(results['loss'])\n",
    "plt.plot(results['val_loss'])\n",
    "plt.show()\n",
    "plt.plot(results['recall'])\n",
    "plt.plot(results['val_recall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9ea2d03f60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items,\n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = BATCH_SIZE)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias\n",
    "diversity_bias = create_diversity_bias(train_set, total_items, delta)\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "metrics=[recall_metric(total_items=total_items)]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss, \n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "initial_epoch = 57\n",
    "total_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "    144/Unknown - 33s 228ms/step - loss: 1.2349 - recall: 0.0897"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset, \n",
    "                    validation_data=val_dataset, \n",
    "                    epochs=total_epochs, \n",
    "                    callbacks=callbacks, \n",
    "                    initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import build_LSTM_model\n",
    "model = build_LSTM_model(total_items = total_items, \n",
    "                         embedding_dim = embedding_dim,\n",
    "                         mask_value = pad_value,\n",
    "                         rnn_units = rnn_units,\n",
    "                         batch_size = 1,\n",
    "                         return_sequences=False)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "print('Latest checkpoint from:', tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_predictions\n",
    "preds_df = get_predictions(model, test_set, test_left_out_items, rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = pd.read_pickle('CFRNN_res_200_ML_01_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "---\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test = get_metrics(preds_df, steps, rank_at)\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import store_LSTM_model\n",
    "# store_path = path + 'results/CFRNN/' + res_ext + '/all_models'\n",
    "store_path = path + 'results/' + res_ext + '/all_models'\n",
    "train_time = np.sum(timing_callback.logs)\n",
    "all_models = store_LSTM_model(store_path, params.copy(), history.history.copy(), train_time, metrics_test, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set Metrics ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         15  0.009014   0.000901\n",
       "3       15         21  0.012620   0.000841\n",
       "4       20         27  0.016226   0.000811"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val_set_vsl = get_metrics(preds_val, 5, 20)\n",
    "metrics_val_set_vsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = 30\n",
    "# min_seq_len = 10\n",
    "# shift_targets_by = 1\n",
    "\n",
    "# from Data_prep import get_x_y_sequences, min_padding\n",
    "# vsl = True # Set for training later\n",
    "\n",
    "# # Train Set\n",
    "# user_sequences_x, user_sequences_y, user_order = get_x_y_sequences(train_set, shift_targets_by)\n",
    "# padded_sequences_x = min_padding(user_sequences_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_y = min_padding(user_sequences_y, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "\n",
    "# # Val Set \n",
    "# user_sequences_val_x, user_sequences_val_y, user_order = get_x_y_sequences(val_set, shift_targets_by, stats=False)\n",
    "# padded_sequences_val_x = min_padding(user_sequences_val_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "# padded_sequences_val_y = min_padding(user_sequences_val_y, BATCH_SIZE, min_seq_len, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_u_i = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "# test_X = []\n",
    "# test_y = []\n",
    "# all_predictions = []\n",
    "# for user_items in test_set_u_i:\n",
    "#     test_X.append(user_items[-200:-1])\n",
    "#     test_y.append(user_items[-1:])\n",
    "\n",
    "# for i, seq in enumerate(test_X): \n",
    "#     seq = seq.copy()\n",
    "#     predictions = []\n",
    "#     for i in range(20):\n",
    "#         pred_item_id = model.predict_classes(np.array([seq,]), batch_size=1)[0]\n",
    "#         seq.append(pred_item_id)\n",
    "#         predictions.append(pred_item_id)\n",
    "#     all_predictions.append(predictions)\n",
    "    \n",
    "# predictions_df = pd.DataFrame(list(zip(test_set.user_id.unique(), all_predictions, test_y)),\n",
    "#                               columns=['user', 'pred_items_ranked', 'true_id'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
