{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(f'TF version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' # file_name = 'Amazon_05_users' \n",
    "file_name = 'Amazon_01_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' # file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983863</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00FXSELCM</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104506</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294092</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00VDPQ884</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175639</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809981</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00EWC0W3W</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99224</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337932</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01EZKMD64</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>238824</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832820</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01ABS4646</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222085</td>\n",
       "      <td>73226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating  item_id  user_id\n",
       "4983863  A39ZLL8ILVT2J8  B00FXSELCM 2014-03-24     3.0   104506    73226\n",
       "7294092  A39ZLL8ILVT2J8  B00VDPQ884 2016-06-29     5.0   175639    73226\n",
       "4809981  A39ZLL8ILVT2J8  B00EWC0W3W 2016-08-14     5.0    99224    73226\n",
       "9337932  A39ZLL8ILVT2J8  B01EZKMD64 2016-10-03     5.0   238824    73226\n",
       "8832820  A39ZLL8ILVT2J8  B01ABS4646 2016-12-22     5.0   222085    73226"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.user_id = df.user_id.astype('category').cat.codes\n",
    "df.item_id = df.item_id.astype('category').cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1\n",
    "\n",
    "total_items = len(df.item_id.unique())\n",
    "total_users = len(df.user_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "datasets = train_val_test_split(df, val_perc, test_perc, n_last_items_val, n_last_items_test)\n",
    "train_set, val_set, test_set = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Neural Collaborative Filtering (NCF)\n",
    "Using the NCF we build Generalized Matrix Factorisation (GMF), Multiplayer Perceptron Matrix Factorisation (MLP) and combine the two in Neural Matrix Factorisation (NeuMF)\n",
    "- paper: http://papers.www2017.com.au.s3-website-ap-southeast-2.amazonaws.com/proceedings/p173.pdf\n",
    "- blog: https://medium.com/@victorkohler/collaborative-filtering-using-deep-neural-networks-in-tensorflow-96e5d41a39a1\n",
    "- code: https://github.com/Leavingseason/NeuralCF/blob/master/GMF.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMF_params = {\n",
    "    'learning_rate': 0.0001,\n",
    "    'batch_size': 64,\n",
    "    'nolf': 16,\n",
    "    'regs': [0,0],\n",
    "    'epochs': 1,#20,\n",
    "    'sample_size': int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 5,\n",
    "    'ckpt_dir': '../NeuMF_storage/GMF_ckpts/ckpts',\n",
    "    'optimizer':'rmsprop'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 256,\n",
    "    'layers': [32,16,8],\n",
    "    'reg_layers': [0,0,0],\n",
    "    'epochs': 1,#20,\n",
    "    'sample_size': int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 4,\n",
    "    'ckpt_dir': '../NeuMF_storage/MLP_ckpts/ckpts',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuMF_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'layers': [32,16,8],\n",
    "    'reg_layers': [0,0,0],\n",
    "    'reg_mf': [0,0],\n",
    "    'nolf': 16,\n",
    "    'epochs': 1,#20,\n",
    "    'sample_size': 10000, #int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 4,\n",
    "    'ckpt_dir': '../NeuMF_storage/MLP_ckpts/ckpts',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NCF import NCF\n",
    "NCF = NCF(total_users, total_items, GMF_params, MLP_params, NeuMF_params)\n",
    "\n",
    "NCF.build_GMF_model()\n",
    "NCF.build_MLP_model()\n",
    "NCF.build_NeuMF_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Samples for GMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Samples for MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "GMF_samples = NCF.create_samples(name='GMF', data=train_set)\n",
    "MLP_samples = NCF.create_samples(name='MLP', data=train_set)\n",
    "# NeuMF_samples = NCF.create_samples(name='GMF', data=train_set)\n",
    "NeuMF_samples = MLP_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting GMF with parameters:\n",
      "                                              0\n",
      "learning_rate                            0.0001\n",
      "batch_size                                   64\n",
      "nolf                                         16\n",
      "regs                                     [0, 0]\n",
      "epochs                                        1\n",
      "sample_size                               10000\n",
      "num_neg                                       5\n",
      "ckpt_dir       ../NeuMF_storage/GMF_ckpts/ckpts\n",
      "optimizer                               rmsprop\n",
      "Epoch: 0\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.6490\n"
     ]
    }
   ],
   "source": [
    "NCF.train_model('GMF', GMF_samples, store_path='../NeuMF_storage/GMF_weights/GMF_weights') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting MLP with parameters:\n",
      "                                              0\n",
      "learning_rate                              0.01\n",
      "batch_size                                  256\n",
      "layers                              [32, 16, 8]\n",
      "reg_layers                            [0, 0, 0]\n",
      "epochs                                        1\n",
      "sample_size                               10000\n",
      "num_neg                                       4\n",
      "ckpt_dir       ../NeuMF_storage/MLP_ckpts/ckpts\n",
      "optimizer                                  Adam\n",
      "Epoch: 0\n",
      "196/196 [==============================] - 20s 101ms/step - loss: 0.1436\n"
     ]
    }
   ],
   "source": [
    "NCF.train_model('MLP', MLP_samples, store_path='../NeuMF_storage/MLP_weights/MLP_weights') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCF.use_pretrain_model(GMF_weights_path='../NeuMF_storage/GMF_weights/GMF_weights',\n",
    "                       MLP_weights_path='../NeuMF_storage/MLP_weights/MLP_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting NeuMF with parameters:\n",
      "                                              0\n",
      "learning_rate                             0.001\n",
      "batch_size                                  256\n",
      "layers                              [32, 16, 8]\n",
      "reg_layers                            [0, 0, 0]\n",
      "reg_mf                                   [0, 0]\n",
      "nolf                                         16\n",
      "epochs                                        1\n",
      "sample_size                               10000\n",
      "num_neg                                       4\n",
      "ckpt_dir       ../NeuMF_storage/MLP_ckpts/ckpts\n",
      "optimizer                                  Adam\n",
      "Epoch: 0\n",
      "196/196 [==============================] - 36s 183ms/step - loss: 0.0919\n"
     ]
    }
   ],
   "source": [
    "# NCF.train_model('NeuMF', NeuMF_samples) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
