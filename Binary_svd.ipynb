{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full CSJ fashion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('Data/df_amazon_csj_with_styles')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSJ 0.63m user above 5, r_u_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2OLY7TMIYHOQQ</td>\n",
       "      <td>B00EAKJUUW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3F6ZP5VM8QUC6</td>\n",
       "      <td>B00D98EGE6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A21PFJA2O7Z5GY</td>\n",
       "      <td>B01DTEXSHA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV9HIUYXBZODJ</td>\n",
       "      <td>B0045DBUBQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A73X3PFCRTJVX</td>\n",
       "      <td>B00DEWBMU8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating  verified\n",
       "0  A2OLY7TMIYHOQQ  B00EAKJUUW     5.0      True\n",
       "1  A3F6ZP5VM8QUC6  B00D98EGE6     5.0      True\n",
       "2  A21PFJA2O7Z5GY  B01DTEXSHA     2.0      True\n",
       "3   AV9HIUYXBZODJ  B0045DBUBQ     3.0      True\n",
       "4   A73X3PFCRTJVX  B00DEWBMU8     5.0      True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('Data/df_amazon_csj_with_styles_0.63m_u_above_5_rui')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.7m user above 5 r_u_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('Data/ml_0.7_u_above_5')\n",
    "# print('rating interval:', df.rating.unique().min(), ',', df.rating.unique().max())\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "First filtering active users and rated items with x or more ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = df.groupby('user')['rating'].count()\n",
    "item_ratings = df.groupby('item')['rating'].count()\n",
    "norpu = user_ratings.mean()\n",
    "norpi = item_ratings.mean()\n",
    "total_users = df.user.unique().size\n",
    "total_items = df.item.unique().size\n",
    "sparseness = 1 - len(df) / (len(df['user'].unique()) * len(df['item'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.9, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows  629889 \n",
      "#ratings 629889 \n",
      "#ratings/user 6.91 \n",
      "#ratings/item 5.47 \n",
      "average rating 4.30 \n",
      "#users  91216 \n",
      "#items  115063 \n",
      "sparse  0.99994 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('rows ', len(df), '\\n#ratings', len(df[df['rating'] != 0]), '\\n#ratings/user', round(norpu,2), '\\n#ratings/item', round(norpi,2), '\\naverage rating', \"{0:.2f}\".format(np.average(df['rating'])), '\\n#users ', df['user'].unique().size, '\\n#items ', df['item'].unique().size, '\\nsparse ', round(sparseness,5), '%')\n",
    "df.hist(column='rating', bins=5, grid=False)\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.xticks(range(1,6))\n",
    "plt.savefig('Plots/Deliverables/rating_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(item_ratings, bins = 1000)\n",
    "plt.xlim([0,100])\n",
    "plt.title('#ratings per item distribution (1000 bins)')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_item_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(user_ratings, bins = 100)\n",
    "plt.xlim([0,30])\n",
    "plt.title('#ratings per user distribution (100 bins)')\n",
    "plt.xlabel('Users')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_user_dist_ml')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Analysis\n",
    "Only keep verified ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified: 0.9118257343754217\n",
      "verified: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('verified:', df['verified'].sum() / len(df))\n",
    "df = df[df['verified']==True]\n",
    "print('verified:', df['verified'].sum() / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df['rating']\n",
    "df['rating'] = df['verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = df\n",
    "df = df_og.sample(frac=0.01, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24161</th>\n",
       "      <td>ABMRK1O13436Y</td>\n",
       "      <td>B00JBJCLG2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396411</th>\n",
       "      <td>A36IZ3GX3RI33W</td>\n",
       "      <td>B00VWKWWMG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426457</th>\n",
       "      <td>AZWGNYTKSK9JS</td>\n",
       "      <td>B000KPXYCG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587848</th>\n",
       "      <td>AQLT5XRHA958G</td>\n",
       "      <td>B000CEM6FG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198173</th>\n",
       "      <td>A31IV9AHRLVY3O</td>\n",
       "      <td>B0077BX3GI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user        item  rating  verified\n",
       "24161    ABMRK1O13436Y  B00JBJCLG2     5.0         1\n",
       "396411  A36IZ3GX3RI33W  B00VWKWWMG     5.0         1\n",
       "426457   AZWGNYTKSK9JS  B000KPXYCG     5.0         1\n",
       "587848   AQLT5XRHA958G  B000CEM6FG     5.0         1\n",
       "198173  A31IV9AHRLVY3O  B0077BX3GI     5.0         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Implicit Feedback Implementation\n",
    "Slow and inaccurate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data, n_users, n_items):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        train_matrix = sparse.coo_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "    \n",
    "        return train_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "m_train = create_matrix(train_set, total_users, total_items)\n",
    "m_val = create_matrix(train_set, total_users, total_items)\n",
    "\n",
    "p = np.random.normal(0, .1, (total_users, params['nolf']))  # users\n",
    "q = np.random.normal(0, .1, (total_items, params['nolf']))  # items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate\n",
    "s = time.time()\n",
    "errors = []\n",
    "for e in range(params['n_epochs']):\n",
    "    for u in range(total_users):\n",
    "        for i in range(total_items):\n",
    "            b_ui = m_train[u,i]\n",
    "            error = b_ui - np.dot(p[u], q[i])\n",
    "\n",
    "            #update\n",
    "            p[u] += params['alpha'] * (error * q[i])# - self.pu_reg * p[u])\n",
    "            q[i] += params['alpha'] * (error * p[u])# - self.qi_reg * q[i])\n",
    "            errors.append(np.square(error))\n",
    "        \n",
    "t = time.time() - s\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Implicit Feedback Implementation with Confidence\n",
    "- From Paper: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.5120&rep=rep1&type=pdf\n",
    "- Code Found: https://github.com/MrChrisJohnson/implicit-mf/blob/master/mf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_epochs\":10,\n",
    "\"alpha\":5, # Impact of confidence\n",
    "          \n",
    "#Regularizers, still tweaking the values\n",
    "\"reg\":0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "class ALS_impl_fb():\n",
    "    \n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg = params['reg']\n",
    "        self.model = {}\n",
    "\n",
    "    \n",
    "    def fit(self, train_set, val_set):\n",
    "        #Init\n",
    "        m_train, m_ones_train = self.create_matrices(train_set, self.total_users, self.total_items)\n",
    "        m_val, m_ones_val = self.create_matrices(val_set, self.total_users, self.total_items)\n",
    "        p = np.random.normal(0, .1, (total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (total_items, self.nolf))  # items\n",
    "        #Solve with ALS\n",
    "        s = time.time()\n",
    "        for e in range(self.n_epochs):\n",
    "            print('solving for user vectors')\n",
    "            p = self.calc_vector(True, sparse.csr_matrix(q), m_train, m_ones_train)\n",
    "            print('solving for item vectors')\n",
    "            q = self.calc_vector(False, sparse.csr_matrix(p), m_train, m_ones_train)\n",
    "\n",
    "        t = time.time() - s\n",
    "        print('Total time:', t)\n",
    "        self.model['p'] = p\n",
    "        self.model['q'] = q\n",
    "        self.model['time'] = t\n",
    "        \n",
    "        self.evaluate(m_ones_val, val=True)\n",
    "        return self.model\n",
    "        \n",
    "    def create_matrices(self, data, n_users, n_items):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1\n",
    "                               \n",
    "        return m, m_ones\n",
    "    \n",
    "    def calc_vector(self, calc_user, fixed, m, m_ones):\n",
    "        s = time.time()\n",
    "        num_solve = self.total_users if calc_user else self.total_items\n",
    "        num_fixed = fixed.shape[0]\n",
    "        YTY = fixed.T.dot(fixed)\n",
    "        I_for_C = sparse.eye(num_fixed) # The 1 in the confidence formula\n",
    "        lambda_I = self.reg * sparse.eye(self.nolf)\n",
    "        solve_vecs = np.zeros([num_solve, self.nolf])\n",
    "        \n",
    "        for i in range(num_solve):\n",
    "            if calc_user:\n",
    "                pu = m_ones[i].toarray()\n",
    "                Cu = self.alpha * sparse.diags(m[i].toarray(), [0])\n",
    "            else:\n",
    "                pu = m_ones[:, i].T.toarray()\n",
    "                Cu = self.alpha * sparse.diags(m[:, i].T.toarray(), [0])\n",
    "                \n",
    "            YTCuIY = fixed.T.dot(Cu + I_for_C).dot(fixed)\n",
    "            YTCupu = fixed.T.dot(Cu).dot(sparse.csr_matrix(pu).T) #result\n",
    "            xu = spsolve(YTY + YTCuIY + lambda_I, YTCupu)\n",
    "            solve_vecs[i] = xu\n",
    "        \n",
    "        print('user:', calc_user, 'takes: ', round((time.time() - s)/60,2) 'minutes')\n",
    "        \n",
    "        return solve_vecs\n",
    "    \n",
    "     def evaluate(self, data, val):\n",
    "        errors = []\n",
    "        for u in range(data.shape[0]):\n",
    "            sq_total_error_u = 0\n",
    "            for i in range(data.shape[1]):\n",
    "                sq_total_error_u += np.square(data[u,i] - np.dot(self.model['p'].T, self.model['q']))\n",
    "                \n",
    "            errors.append(sq_total_error_u / (data.shape[0]*data.shape[1]))\n",
    "            \n",
    "        rmse = np.sqrt(np.sum(errors))\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solving for user vectors\n",
      "user: True takes:  68.59919619560242\n",
      "solving for item vectors\n",
      "user: False takes:  58.16086030006409\n",
      "solving for user vectors\n",
      "user: True takes:  56.435056924819946\n",
      "solving for item vectors\n",
      "user: False takes:  53.73285102844238\n",
      "solving for user vectors\n",
      "user: True takes:  55.195950746536255\n",
      "solving for item vectors\n",
      "user: False takes:  54.473292112350464\n",
      "solving for user vectors\n",
      "user: True takes:  71.71853017807007\n",
      "solving for item vectors\n",
      "user: False takes:  72.37699794769287\n",
      "solving for user vectors\n",
      "user: True takes:  66.21227431297302\n",
      "solving for item vectors\n",
      "user: False takes:  61.97181415557861\n",
      "solving for user vectors\n",
      "user: True takes:  55.82038402557373\n",
      "solving for item vectors\n",
      "user: False takes:  59.11095690727234\n",
      "solving for user vectors\n",
      "user: True takes:  57.936084032058716\n",
      "solving for item vectors\n",
      "user: False takes:  62.93949890136719\n",
      "solving for user vectors\n",
      "user: True takes:  59.00298523902893\n",
      "solving for item vectors\n",
      "user: False takes:  54.92886400222778\n",
      "solving for user vectors\n",
      "user: True takes:  61.4036328792572\n",
      "solving for item vectors\n",
      "user: False takes:  63.149580001831055\n",
      "solving for user vectors\n",
      "user: True takes:  57.58171105384827\n",
      "solving for item vectors\n",
      "user: False takes:  64.91901421546936\n",
      "Total time: 1215.7738008499146\n"
     ]
    }
   ],
   "source": [
    "model = ALS_impl_fb(total_users, total_items, params)\n",
    "results = model.fit(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, val, model):\n",
    "        errors = []\n",
    "        for u in range(data.shape[0]):\n",
    "            sq_total_error_u = 0\n",
    "            for i in range(data.shape[1]):\n",
    "                sq_total_error_u += np.square(data[u,i] - np.dot(model['p'][u], model['q'][i].T))\n",
    "                \n",
    "            errors.append(sq_total_error_u / (data.shape[0]*data.shape[1]))\n",
    "            \n",
    "        rmse = np.sqrt(np.sum(errors))\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrices(data, n_users, n_items):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1\n",
    "                               \n",
    "        return m, m_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.0107652 ,  0.02175233,  0.00127649, ..., -0.00995033,\n",
       "        -0.01367885, -0.02153329],\n",
       "       [ 0.00857229, -0.01766926,  0.00544033, ...,  0.00600137,\n",
       "         0.00654894, -0.00656053],\n",
       "       ...,\n",
       "       [-0.00027596,  0.00405759, -0.00466972, ..., -0.00099562,\n",
       "        -0.02164893,  0.00510585],\n",
       "       [ 0.01473534, -0.01226229, -0.00265135, ..., -0.00638375,\n",
       "        -0.01416581, -0.00569172],\n",
       "       [ 0.01413288,  0.01170482, -0.00241612, ...,  0.00466244,\n",
       "         0.00141392, -0.00452497]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.model['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-5e2328c961a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ones_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_ones_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-22bd3b4a10da>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data, val, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0msq_total_error_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0msq_total_error_u\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m_val, m_ones_val = create_matrices(val_set, total_users, total_items)\n",
    "print(evaluate(m_ones_val, val=True, model=results.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data #row:  5743\n"
     ]
    }
   ],
   "source": [
    "def transform(df):\n",
    "    items = df['item'].unique()\n",
    "    itemsDF = pd.DataFrame(data=items, columns=['original_item_id'])\n",
    "    itemsDF['new_item_id'] = itemsDF.index\n",
    "\n",
    "    users = df['user'].unique()\n",
    "    usersDF = pd.DataFrame(data=users, columns=['original_user_id'])\n",
    "    usersDF['new_user_id'] = usersDF.index\n",
    "\n",
    "    ratingDF = df.merge(itemsDF, left_on='item', right_on='original_item_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_item_id'])\n",
    "\n",
    "    ratingDF = ratingDF.merge(usersDF, left_on='user', right_on='original_user_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_user_id'])\n",
    "\n",
    "    df_new_ids = ratingDF\n",
    "    print('Full data #row: ', df_new_ids.shape[0])\n",
    "    df_new_ids.head()\n",
    "    \n",
    "    return df_new_ids\n",
    "\n",
    "df_new_ids = transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split\n",
    "Train 0.8, Train 0.2, Test 0.1, could add validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  4594\n",
      "Size of validation set:  574\n",
      "Size of test set:  575\n"
     ]
    }
   ],
   "source": [
    "random_state = 1234\n",
    "train_set, test_set = train_test_split(df_new_ids, test_size=0.20, shuffle=True, random_state=random_state)\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.50, shuffle=True, random_state=random_state)\n",
    "\n",
    "print('Size of train set: ', len(train_set))\n",
    "print('Size of validation set: ', len(val_set))\n",
    "print('Size of test set: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_epochs\":10,\n",
    "\"random_state\":1234,\n",
    "\n",
    "#Learning rate\n",
    "\"alpha\":0.004, #Low alpha to prevent diverging => sgd all over the place => error up\n",
    "\"alpha_b\":0.004,\n",
    "\"alpha_cb\":0.001,\n",
    "\n",
    "\"stop\":True, #Stops when val set does not improve\n",
    "\"use_bias\":True,\n",
    "\"use_color\":False,\n",
    "\"use_impl_fb\":False,\n",
    "\"use_weight_ver\":False,\n",
    "\n",
    "#Regularizers, still tweaking the values\n",
    "\"bu_reg\":0.05,\n",
    "\"bi_reg\":0.05,\n",
    "\"pu_reg\":0.001,\n",
    "\"qi_reg\":0.001,\n",
    "\"x_reg\":0.001,\n",
    "\"cb_reg\": 0.01,\n",
    "\"ver_weight\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb, no reg ML 0.7m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin.opdam\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\ipykernel_launcher.py:193: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-837e7a22ac9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Amazon_0.63m_svd_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-ae01f8440e8d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, val_data, verbose, plot, plot_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-ae01f8440e8d>\u001b[0m in \u001b[0;36mSVD\u001b[1;34m(self, train_data, val_data, verbose, plot, plot_name)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_ui\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_item\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimpl_fb_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_weight_ver\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi_verified\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mver_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SVD(params, total_users, total_items)\n",
    "model.fit(train_set, val_set, 1, plot=True, plot_name='Amazon_0.63m_svd_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 0.8879020055996585\n"
     ]
    }
   ],
   "source": [
    "model4.test(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results added\n"
     ]
    }
   ],
   "source": [
    "log_path = 'Results/'\n",
    "res_name = 'diff_amazon_0.63m_ml_0.7m_svd_res'\n",
    "model4.store_results(log_path, res_name, user_thres, item_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_b</th>\n",
       "      <th>alpha_cb</th>\n",
       "      <th>stop</th>\n",
       "      <th>use_bias</th>\n",
       "      <th>use_color</th>\n",
       "      <th>use_impl_fb</th>\n",
       "      <th>use_weight_ver</th>\n",
       "      <th>bu_reg</th>\n",
       "      <th>bi_reg</th>\n",
       "      <th>pu_reg</th>\n",
       "      <th>qi_reg</th>\n",
       "      <th>x_reg</th>\n",
       "      <th>cb_reg</th>\n",
       "      <th>ver_weight</th>\n",
       "      <th>u_thres</th>\n",
       "      <th>i_thres</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974660</td>\n",
       "      <td>735.11</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0964998875525962, 1.077890991237727, 1.0608...</td>\n",
       "      <td>[1.084106734973401, 1.0758673188719923, 1.0685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888983</td>\n",
       "      <td>465.07</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0043209703724225, 0.9585997879316766, 0.934...</td>\n",
       "      <td>[0.9806632719832211, 0.9571649684980635, 0.942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901546</td>\n",
       "      <td>4008.69</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0046325333388055, 0.9575346658147529, 0.932...</td>\n",
       "      <td>[0.9817306182226897, 0.9583214980718305, 0.943...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977303</td>\n",
       "      <td>4730.79</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0972634826578922, 1.0768362886928646, 1.058...</td>\n",
       "      <td>[1.0846694856842962, 1.0764145198595443, 1.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973846</td>\n",
       "      <td>4631.19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.097150938913198, 1.0771435306183033, 1.0591...</td>\n",
       "      <td>[1.0839654683510576, 1.07568371842164, 1.06832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.889150</td>\n",
       "      <td>5334.53</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0043539915594077, 0.9584704485902822, 0.934...</td>\n",
       "      <td>[0.9808354598102975, 0.9573517194884253, 0.942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973801</td>\n",
       "      <td>5955.84</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0969116476784215, 1.077229741787626, 1.0596...</td>\n",
       "      <td>[1.0837589423958007, 1.0754705353744252, 1.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.887902</td>\n",
       "      <td>7476.37</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.004291125392521, 0.9585592188954637, 0.9345...</td>\n",
       "      <td>[0.9806332918833931, 0.9571463139308806, 0.942...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_test  train_speed nolf n_epochs random_state  alpha  alpha_b  \\\n",
       "0   0.974660       735.11   20       40         1234  0.004    0.004   \n",
       "1   0.888983       465.07   20       40         1234  0.004    0.004   \n",
       "2   0.901546      4008.69   20       40         1234  0.004    0.004   \n",
       "3   0.977303      4730.79   20       40         1234  0.004    0.004   \n",
       "4   0.973846      4631.19   20       40         1234  0.004    0.004   \n",
       "5   0.889150      5334.53   20       40         1234  0.004    0.004   \n",
       "6   0.973801      5955.84   20       40         1234  0.004    0.004   \n",
       "7   0.887902      7476.37   20       40         1234  0.004    0.004   \n",
       "\n",
       "   alpha_cb  stop use_bias use_color use_impl_fb use_weight_ver  bu_reg  \\\n",
       "0     0.001  True     True     False       False          False    0.05   \n",
       "1     0.001  True     True     False       False          False    0.05   \n",
       "2     0.001  True     True     False        True          False    0.05   \n",
       "3     0.001  True     True     False        True          False    0.05   \n",
       "4     0.001  True     True     False        True          False    0.05   \n",
       "5     0.001  True     True     False        True          False    0.05   \n",
       "6     0.001  True     True     False        True          False    0.05   \n",
       "7     0.001  True     True     False        True          False    0.05   \n",
       "\n",
       "   bi_reg  pu_reg  qi_reg  x_reg  cb_reg  ver_weight u_thres i_thres  \\\n",
       "0    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "1    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "2    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "3    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "4    0.05   0.001   0.001  0.500    0.01         0.5       5       5   \n",
       "5    0.05   0.001   0.001  0.500    0.01         0.5       5       5   \n",
       "6    0.05   0.001   0.001  2.000    0.01         0.5       5       5   \n",
       "7    0.05   0.001   0.001  2.000    0.01         0.5       5       5   \n",
       "\n",
       "   train_size  test_size  val_size  \\\n",
       "0         0.8        0.1       0.1   \n",
       "1         0.8        0.1       0.1   \n",
       "2         0.8        0.1       0.1   \n",
       "3         0.8        0.1       0.1   \n",
       "4         0.8        0.1       0.1   \n",
       "5         0.8        0.1       0.1   \n",
       "6         0.8        0.1       0.1   \n",
       "7         0.8        0.1       0.1   \n",
       "\n",
       "                                          train_rmse  \\\n",
       "0  [1.0964998875525962, 1.077890991237727, 1.0608...   \n",
       "1  [1.0043209703724225, 0.9585997879316766, 0.934...   \n",
       "2  [1.0046325333388055, 0.9575346658147529, 0.932...   \n",
       "3  [1.0972634826578922, 1.0768362886928646, 1.058...   \n",
       "4  [1.097150938913198, 1.0771435306183033, 1.0591...   \n",
       "5  [1.0043539915594077, 0.9584704485902822, 0.934...   \n",
       "6  [1.0969116476784215, 1.077229741787626, 1.0596...   \n",
       "7  [1.004291125392521, 0.9585592188954637, 0.9345...   \n",
       "\n",
       "                                            val_rmse  \n",
       "0  [1.084106734973401, 1.0758673188719923, 1.0685...  \n",
       "1  [0.9806632719832211, 0.9571649684980635, 0.942...  \n",
       "2  [0.9817306182226897, 0.9583214980718305, 0.943...  \n",
       "3  [1.0846694856842962, 1.0764145198595443, 1.069...  \n",
       "4  [1.0839654683510576, 1.07568371842164, 1.06832...  \n",
       "5  [0.9808354598102975, 0.9573517194884253, 0.942...  \n",
       "6  [1.0837589423958007, 1.0754705353744252, 1.068...  \n",
       "7  [0.9806332918833931, 0.9571463139308806, 0.942...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_pickle(log_path + res_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ml = results[results['RMSE_test'] < 0.95]\n",
    "results_amazon = results[results['RMSE_test'] > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_b</th>\n",
       "      <th>alpha_cb</th>\n",
       "      <th>stop</th>\n",
       "      <th>use_bias</th>\n",
       "      <th>use_color</th>\n",
       "      <th>use_impl_fb</th>\n",
       "      <th>use_weight_ver</th>\n",
       "      <th>bu_reg</th>\n",
       "      <th>bi_reg</th>\n",
       "      <th>pu_reg</th>\n",
       "      <th>qi_reg</th>\n",
       "      <th>x_reg</th>\n",
       "      <th>cb_reg</th>\n",
       "      <th>ver_weight</th>\n",
       "      <th>u_thres</th>\n",
       "      <th>i_thres</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.973801</td>\n",
       "      <td>5955.84</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0969116476784215, 1.077229741787626, 1.0596...</td>\n",
       "      <td>[1.0837589423958007, 1.0754705353744252, 1.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973846</td>\n",
       "      <td>4631.19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.097150938913198, 1.0771435306183033, 1.0591...</td>\n",
       "      <td>[1.0839654683510576, 1.07568371842164, 1.06832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974660</td>\n",
       "      <td>735.11</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0964998875525962, 1.077890991237727, 1.0608...</td>\n",
       "      <td>[1.084106734973401, 1.0758673188719923, 1.0685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977303</td>\n",
       "      <td>4730.79</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0972634826578922, 1.0768362886928646, 1.058...</td>\n",
       "      <td>[1.0846694856842962, 1.0764145198595443, 1.069...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_test  train_speed nolf n_epochs random_state  alpha  alpha_b  \\\n",
       "6   0.973801      5955.84   20       40         1234  0.004    0.004   \n",
       "4   0.973846      4631.19   20       40         1234  0.004    0.004   \n",
       "0   0.974660       735.11   20       40         1234  0.004    0.004   \n",
       "3   0.977303      4730.79   20       40         1234  0.004    0.004   \n",
       "\n",
       "   alpha_cb  stop use_bias use_color use_impl_fb use_weight_ver  bu_reg  \\\n",
       "6     0.001  True     True     False        True          False    0.05   \n",
       "4     0.001  True     True     False        True          False    0.05   \n",
       "0     0.001  True     True     False       False          False    0.05   \n",
       "3     0.001  True     True     False        True          False    0.05   \n",
       "\n",
       "   bi_reg  pu_reg  qi_reg  x_reg  cb_reg  ver_weight u_thres i_thres  \\\n",
       "6    0.05   0.001   0.001  2.000    0.01         0.5       5       5   \n",
       "4    0.05   0.001   0.001  0.500    0.01         0.5       5       5   \n",
       "0    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "3    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "\n",
       "   train_size  test_size  val_size  \\\n",
       "6         0.8        0.1       0.1   \n",
       "4         0.8        0.1       0.1   \n",
       "0         0.8        0.1       0.1   \n",
       "3         0.8        0.1       0.1   \n",
       "\n",
       "                                          train_rmse  \\\n",
       "6  [1.0969116476784215, 1.077229741787626, 1.0596...   \n",
       "4  [1.097150938913198, 1.0771435306183033, 1.0591...   \n",
       "0  [1.0964998875525962, 1.077890991237727, 1.0608...   \n",
       "3  [1.0972634826578922, 1.0768362886928646, 1.058...   \n",
       "\n",
       "                                            val_rmse  \n",
       "6  [1.0837589423958007, 1.0754705353744252, 1.068...  \n",
       "4  [1.0839654683510576, 1.07568371842164, 1.06832...  \n",
       "0  [1.084106734973401, 1.0758673188719923, 1.0685...  \n",
       "3  [1.0846694856842962, 1.0764145198595443, 1.069...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_amazon.sort_values('RMSE_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738008513773665 0.97465995560912\n"
     ]
    }
   ],
   "source": [
    "best_impl_fb = results_amazon.sort_values('RMSE_test').iloc[0]['RMSE_test']\n",
    "best_basic = results_amazon[results_amazon['use_impl_fb'] == False]['RMSE_test'][0]\n",
    "print(best_impl_fb, best_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86, 0.98)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(2), [best_impl_fb, best_basic])\n",
    "plt.ylim([0.86,0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_b</th>\n",
       "      <th>alpha_cb</th>\n",
       "      <th>stop</th>\n",
       "      <th>use_bias</th>\n",
       "      <th>use_color</th>\n",
       "      <th>use_impl_fb</th>\n",
       "      <th>use_weight_ver</th>\n",
       "      <th>bu_reg</th>\n",
       "      <th>bi_reg</th>\n",
       "      <th>pu_reg</th>\n",
       "      <th>qi_reg</th>\n",
       "      <th>x_reg</th>\n",
       "      <th>cb_reg</th>\n",
       "      <th>ver_weight</th>\n",
       "      <th>u_thres</th>\n",
       "      <th>i_thres</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.887902</td>\n",
       "      <td>7476.37</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.004291125392521, 0.9585592188954637, 0.9345...</td>\n",
       "      <td>[0.9806332918833931, 0.9571463139308806, 0.942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888983</td>\n",
       "      <td>465.07</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0043209703724225, 0.9585997879316766, 0.934...</td>\n",
       "      <td>[0.9806632719832211, 0.9571649684980635, 0.942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.889150</td>\n",
       "      <td>5334.53</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0043539915594077, 0.9584704485902822, 0.934...</td>\n",
       "      <td>[0.9808354598102975, 0.9573517194884253, 0.942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901546</td>\n",
       "      <td>4008.69</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0046325333388055, 0.9575346658147529, 0.932...</td>\n",
       "      <td>[0.9817306182226897, 0.9583214980718305, 0.943...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_test  train_speed nolf n_epochs random_state  alpha  alpha_b  \\\n",
       "7   0.887902      7476.37   20       40         1234  0.004    0.004   \n",
       "1   0.888983       465.07   20       40         1234  0.004    0.004   \n",
       "5   0.889150      5334.53   20       40         1234  0.004    0.004   \n",
       "2   0.901546      4008.69   20       40         1234  0.004    0.004   \n",
       "\n",
       "   alpha_cb  stop use_bias use_color use_impl_fb use_weight_ver  bu_reg  \\\n",
       "7     0.001  True     True     False        True          False    0.05   \n",
       "1     0.001  True     True     False       False          False    0.05   \n",
       "5     0.001  True     True     False        True          False    0.05   \n",
       "2     0.001  True     True     False        True          False    0.05   \n",
       "\n",
       "   bi_reg  pu_reg  qi_reg  x_reg  cb_reg  ver_weight u_thres i_thres  \\\n",
       "7    0.05   0.001   0.001  2.000    0.01         0.5       5       5   \n",
       "1    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "5    0.05   0.001   0.001  0.500    0.01         0.5       5       5   \n",
       "2    0.05   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "\n",
       "   train_size  test_size  val_size  \\\n",
       "7         0.8        0.1       0.1   \n",
       "1         0.8        0.1       0.1   \n",
       "5         0.8        0.1       0.1   \n",
       "2         0.8        0.1       0.1   \n",
       "\n",
       "                                          train_rmse  \\\n",
       "7  [1.004291125392521, 0.9585592188954637, 0.9345...   \n",
       "1  [1.0043209703724225, 0.9585997879316766, 0.934...   \n",
       "5  [1.0043539915594077, 0.9584704485902822, 0.934...   \n",
       "2  [1.0046325333388055, 0.9575346658147529, 0.932...   \n",
       "\n",
       "                                            val_rmse  \n",
       "7  [0.9806332918833931, 0.9571463139308806, 0.942...  \n",
       "1  [0.9806632719832211, 0.9571649684980635, 0.942...  \n",
       "5  [0.9808354598102975, 0.9573517194884253, 0.942...  \n",
       "2  [0.9817306182226897, 0.9583214980718305, 0.943...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ml.sort_values('RMSE_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8879020055996585 0.8889826841707456\n"
     ]
    }
   ],
   "source": [
    "best_impl_fb_ml = results_ml.sort_values('RMSE_test').iloc[0]['RMSE_test']\n",
    "best_basic_ml = results_ml.sort_values('RMSE_test').iloc[1]['RMSE_test']\n",
    "print(best_impl_fb_ml, best_basic_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86, 0.98)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(2), [best_impl_fb_ml, best_basic_ml])\n",
    "plt.ylim([0.86,0.98])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete last results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(log_path + res_name)[1:].to_pickle(log_path + res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation all algs data with #ratings/item & user > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv(data, params, n_splits, res_name, model_res_name):\n",
    "    kf = KFold(n_splits = n_splits, shuffle = True)\n",
    "    full_data = data\n",
    "    scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        result = next(kf.split(full_data), None)\n",
    "        train_set = full_data.iloc[result[0]]\n",
    "        test_set = full_data.iloc[result[1]]\n",
    "        model = SVD(params, total_users, total_items)\n",
    "        model.fit(train_set, verbose = 1000, plot = False)\n",
    "        \n",
    "        model.test(test_set)\n",
    "        model.store_results('', model_res_name, user_thres, item_thres)  \n",
    "\n",
    "    df_cv_results = pd.read_pickle(model_res_name)[-5:]\n",
    "    params_dict = df_cv_results.iloc[0][['nolf', 'n_epochs', 'random_state', 'alpha', 'alpha_b', 'use_bias', 'use_impl_fb', 'use_color', 'use_weight_ver', 'ver_weight' 'bu_reg', 'bi_reg', 'pu_reg', 'qi_reg', 'x_reg', 'u_thres', 'i_thres', 'train_size', 'test_size', 'train_rmse']].to_dict()\n",
    "    avg_rmse_dict = {'avg_rmse_test':np.average(df_cv_results['RMSE_test'])}\n",
    "    final_dict = {**avg_rmse_dict, **params_dict}\n",
    "\n",
    "    if not os.path.exists(res_name):\n",
    "        cv_res = pd.DataFrame(columns=final_dict.keys())\n",
    "        print('new results created')\n",
    "\n",
    "    else:\n",
    "        cv_res = pd.read_pickle(res_name)\n",
    "        print('results added')\n",
    "\n",
    "    cv_res = cv_res.append(final_dict, ignore_index=True)\n",
    "    pd.to_pickle(cv_res, res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_bias_only'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Verification and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_weight_ver'] = True\n",
    "params['ver_weight'] = 0.7\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_ver_weight'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb with Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_weight_ver'] = False\n",
    "params['use_impl_fb'] = True\n",
    "params['x_reg'] = 0.01\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_impl_fb'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color attribute with Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = False\n",
    "params['use_color'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_color'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb with verification weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = True\n",
    "params['use_color'] = False\n",
    "params['use_weight_ver'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_ver_weight_impl_fb'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color, impl_fb, weight_ver and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = True\n",
    "params['use_color'] = True\n",
    "params['use_weight_ver'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_bias_impl_fb_weight_color'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results CV all algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.read_pickle(res_name).sort_values('avg_rmse_test')\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name = 'cv_half_df_all_algs'\n",
    "cv_res_name = 'cv_res_bias'\n",
    "log_path = 'Results/'\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = n_splits, shuffle = True)\n",
    "full_data = df_new_ids\n",
    "scores = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    result = next(kf.split(full_data), None)\n",
    "    train_set = full_data.iloc[result[0]]\n",
    "    test_set = full_data.iloc[result[1]]\n",
    "    model = SVD(params, total_users, total_items)\n",
    "    model.fit(train_set, verbose = 1000, plot = False)\n",
    "\n",
    "    model.test(test_set)\n",
    "    model.store_results(log_path, cv_res_name, user_thres, item_thres)  \n",
    "\n",
    "df_cv_results = pd.read_pickle(log_path + cv_res_name)[-5:]\n",
    "params_dict = df_cv_results.iloc[0][['nolf', 'n_epochs', 'random_state', 'alpha', 'alpha_b', 'use_bias', 'use_impl_fb', 'use_color', 'use_weight_ver', 'bu_reg', 'bi_reg', 'pu_reg', 'qi_reg', 'x_reg', 'u_thres', 'i_thres', 'train_size', 'test_size', 'train_rmse']].to_dict()\n",
    "avg_rmse_dict = {'avg_rmse_test':np.average(df_cv_results['RMSE_test'])}\n",
    "final_dict = {**avg_rmse_dict, **params_dict}\n",
    "\n",
    "if not os.path.exists(log_path + res_name):\n",
    "    cv_res = pd.DataFrame(columns=final_dict.keys())\n",
    "    print('new results created')\n",
    "\n",
    "else:\n",
    "    cv_res = pd.read_pickle(log_path + res_name)\n",
    "    print('results added')\n",
    "\n",
    "cv_res = cv_res.append(final_dict, ignore_index=True)\n",
    "pd.to_pickle(cv_res, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.read_pickle(log_path + res_name).sort_values('avg_rmse_test')\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and View Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(log_path +'all_results_movie_lens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old but gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('Results/df_comparison_impl_fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_pickle('Results/' + 'df_results_svd')\n",
    "df_results.sort_values('RMSE_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the RMSE in the first results should be higher (+1.1) due to a mistake in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['with Bias and Reg', 'with Bias', 'Plain']\n",
    "y = [1.313160, 1.314319, 2.860927]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(len(y))\n",
    "width = 0.8\n",
    "ax.bar(ind, y, width, color=['darkblue'])\n",
    "ax.set_xticks(ind+width/500)\n",
    "ax.set_xticklabels(x, minor=False)\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Model Comparison')\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(i -0.2, v + 0.02, str(v), fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model train RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best from Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df_results_b.iloc[6]\n",
    "model.plot_rmse(best['train_rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best of All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df_results_all\n",
    "model.plot_rmse(best['train_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.linalg import sqrtm\n",
    "\n",
    "# X_train, X_test = train_test_split(df, test_size=0.10, shuffle=True, random_state=1234)\n",
    "# X_validation, X_test = train_test_split(X_test, test_size=0.50, shuffle=True, random_state=1234)\n",
    "\n",
    "# def create_utility_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
    "#     \"\"\"\n",
    "#         :param data:      Array-like, 2D, nx3\n",
    "#         :param formatizer:pass the formatizer\n",
    "#         :return:          utility matrix (n x m), n=users, m=items\n",
    "#     \"\"\"\n",
    "        \n",
    "#     itemField = formatizer['item']\n",
    "#     userField = formatizer['user']\n",
    "#     valueField = formatizer['value']\n",
    "    \n",
    "#     userList = data.iloc[:,userField].tolist()\n",
    "#     itemList = data.iloc[:,itemField].tolist()\n",
    "#     valueList = data.iloc[:,valueField].tolist()\n",
    "    \n",
    "#     users = list(set(data.iloc[:,userField]))\n",
    "#     items = list(set(data.iloc[:,itemField]))\n",
    "    \n",
    "#     users_index = {users[i]: i for i in range(len(users))}\n",
    "#     pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "    \n",
    "#     for i in range(0,len(data)):\n",
    "#         item = itemList[i]\n",
    "#         user = userList[i]\n",
    "#         value = valueList[i]\n",
    "        \n",
    "#     pd_dict[item][users_index[user]] = value\n",
    "#     X = pd.DataFrame(pd_dict)\n",
    "#     X.index = users\n",
    "        \n",
    "#     itemcols = list(X.columns)\n",
    "#     items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
    "#     # users_index gives us a mapping of user_id to index of user\n",
    "#     # items_index provides the same for items\n",
    "#     return X, users_index, items_index\n",
    "\n",
    "# X, users_index, items_index = create_utility_matrix(X_train)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user.unique().shape[0]\n",
    "# n_items = df.item.unique().shape[0]\n",
    "\n",
    "# ratings_train = np.zeros((n_users, n_items))\n",
    "# for row in X_train.itertuples():\n",
    "#         ratings_train[row[5], row[4]] = row[3]\n",
    "\n",
    "# pd.DataFrame(ratings_train).head()\n",
    "# # sparse.csr_matrix((X_train['rating']),shape(n_users, n_items))\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different SGD coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_item_combos = 0\n",
    "# for epoch in range(n_epochs):\n",
    "#     for u in range(ratings_train.shape[0]): #users\n",
    "#         for i in range(ratings_train.shape[1]): #items\n",
    "#             r_ui = ratings_train[u,i]\n",
    "            \n",
    "#             if  r_ui != 0:\n",
    "#                 user_item_combos += 1\n",
    "#                 error = r_ui - np.dot(p[u], q[i])\n",
    "                \n",
    "#                 p[u] += alpha *(error * q[i])\n",
    "#                 q[i] += alpha * (error * p[u])\n",
    "                \n",
    "#                 total_error += np.square(error)\n",
    "# #         print(total_error)\n",
    "#     rmse = math.sqrt(total_error)\n",
    "#     print('epoch: ', epoch)#, '  rmse: ', rmse)\n",
    "#     print(user_item_combos, X_train['rating'].shape[0])\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_user[u] += alpha_b * (error - bu_reg * b_user[u])\n",
    "# b_item[i] += alpha_b * (error - bi_reg * b_item[i])\n",
    "            \n",
    "# p[u] += alpha * (error * q[i] - pu_reg * p[u])\n",
    "# q[i] += alpha * (error * p[u] - qi_reg * q[i])\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors binary split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [8,6]\n",
    "# pop_col = (df.groupby('Color:')['rating'].count().sort_values(ascending=False)[0:35]/len(df)).sum()\n",
    "# non_pop_col = (df.groupby('Color:')['rating'].count().sort_values(ascending=False)[35:]/len(df)).sum()\n",
    "\n",
    "# bars = plt.bar(['pop_col', 'non_pop_col'], [pop_col, non_pop_col])\n",
    "# plt.text(bars[0].get_x() + 0.13, pop_col + -0.05, pop_col, color=\"white\", fontweight = 'bold')\n",
    "# plt.text(bars[1].get_x() + 0.13, non_pop_col + -0.05, non_pop_col, color=\"white\", fontweight = 'bold')\n",
    "# plt.title('Binary split between 35 most populair colors and non populair colors')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_colors = df.groupby('Color:')['rating'].count().sort_values(ascending=False)[0:35] \n",
    "\n",
    "# def pop_color(x):\n",
    "#     x = x['Color:']\n",
    "#     if x in pop_colors:\n",
    "#         return 1\n",
    "#     elif x not in pop_colors:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# temp_df = pd.DataFrame()\n",
    "# temp_df['bin_pop_col'] = df.apply(pop_color, axis=1, result_type='expand')\n",
    "# df = df.merge(temp_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "239.774px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
