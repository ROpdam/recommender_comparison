{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_train = pd.read_pickle('Data/cnn_paper/user_train')\n",
    "df_user_val = pd.read_pickle('Data/cnn_paper/user_val')\n",
    "df_user_test = pd.read_pickle('Data/cnn_paper/user_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_user_train, df_user_val, df_user_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full csj with styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Data/df_amazon_csj_with_styles')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With styles, par_col column, colors, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Data/df_styles_and_cleaned_colors')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/amazon_fashion.csv', names=['item','user','rating'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/movie_lens_ratings_small.csv').drop(columns=['timestamp'])\n",
    "df.head()\n",
    "df.columns = ['user', 'item', 'rating']\n",
    "print('rating interval:', df.rating.unique().min(), ',', df.rating.unique().max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating interval: 0.5 , 5.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1   296     5.0\n",
       "1     1   306     3.5\n",
       "2     1   307     5.0\n",
       "3     1   665     5.0\n",
       "4     1   899     3.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/ml-25m/ratings.csv').drop(columns=['timestamp'])\n",
    "df.head()\n",
    "df.columns = ['user', 'item', 'rating']\n",
    "print('rating interval:', df.rating.unique().min(), ',', df.rating.unique().max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "First filtering active users and rated items with x or more ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_thres = 1\n",
    "user_thres = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['#ratings'] = df.groupby('item')['item'].transform('count')\n",
    "df = df[df['#ratings'] >= item_thres].drop(columns=['#ratings'])\n",
    "\n",
    "df['#ratings'] = df.groupby('user')['user'].transform('count')\n",
    "df = df[df['#ratings'] >= user_thres].drop(columns=['#ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norpu = df.groupby('user')['rating'].count().mean()\n",
    "norpi = df.groupby('item')['rating'].count().mean()\n",
    "total_users = df.user.unique().size\n",
    "total_items = df.item.unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows  2500010 \n",
      "#ratings 2500010 \n",
      "#ratings/user 153.81 \n",
      "#ratings/item 423.39 \n",
      "average rating 3.53 \n",
      "#users  159358 \n",
      "#items  31692\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('rows ', len(df), '\\n#ratings', len(df[df['rating'] != 0]), '\\n#ratings/user', round(norpu,2), '\\n#ratings/item', round(norpi,2), '\\naverage rating', \"{0:.2f}\".format(np.average(df['rating'])), '\\n#users ', df['user'].unique().size, '\\n#items ', df['item'].unique().size)\n",
    "df.hist(column='rating', bins=5, grid=False)\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(1,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['Style:',\n",
    " 'Size Name:',\n",
    " 'Metal Type:',\n",
    " 'Item Display Length:',\n",
    " 'Size:',\n",
    " 'Color:',\n",
    " 'Team Name:',\n",
    " 'Length:',\n",
    " 'Material:',\n",
    " 'Item Package Quantity:',\n",
    " 'Scent Name:',\n",
    " 'Gem Type:',\n",
    " 'Shape:',\n",
    " 'Format:',\n",
    " 'Style Name:',\n",
    " 'Package Quantity:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_perc_present = []\n",
    "for style in keys:\n",
    "    style_perc_present.append(1 - df[style].isnull().sum() / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15,10]\n",
    "bars = plt.bar(keys, style_perc_present)\n",
    "for i, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + 0.005, keys[i])\n",
    "plt.title('Percentage of data labeled with style')\n",
    "plt.xticks('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oiriginal Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_labels = df.groupby('Color:')['rating'].count().sort_values(ascending=False).index\n",
    "color_perc_present = list(list(df.groupby('Color:')['rating'].count().sort_values(ascending=False)) / (len(df) - df['Color:'].isnull().sum()))\n",
    "\n",
    "total_perc = 0\n",
    "labels = []\n",
    "for i, perc in enumerate(color_perc_present):\n",
    "    total_perc += perc\n",
    "    labels.append(color_labels[i])\n",
    "    if total_perc > 0.20:\n",
    "        break\n",
    "        \n",
    "print('20% of cum_dist labels: ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "bars = plt.bar(color_labels[:20], color_perc_present[:20])\n",
    "for i, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + 0.001, color_labels[i])\n",
    "plt.title('Distribution of color labels within colors (Pareto)')\n",
    "plt.xticks('')\n",
    "plt.text(0.43, -0.01, '23% | 77%')\n",
    "plt.axvline(x=1.5, color='red')\n",
    "plt.show()\n",
    "print('Note: 11046 color labels in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaned colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_labels = df.groupby('Color2:')['rating'].count().sort_values(ascending=False).index\n",
    "color_perc_present = list(list(df.groupby('Color2:')['rating'].count().sort_values(ascending=False)) / (len(df) - df['Color:'].isnull().sum()))\n",
    "\n",
    "total_perc = 0\n",
    "labels = []\n",
    "for i, perc in enumerate(color_perc_present):\n",
    "    total_perc += perc\n",
    "    labels.append(color_labels[i])\n",
    "    if total_perc > 0.20:\n",
    "        break\n",
    "        \n",
    "print('20% of cum_dist labels: ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "bars = plt.bar(color_labels[:20], color_perc_present[:20])\n",
    "for i, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval + 0.001, color_labels[i])\n",
    "plt.title('Distribution of color labels within colors (Pareto)')\n",
    "plt.xticks('')\n",
    "plt.text(-0.6, -0.01, '25% | 75%')\n",
    "plt.axvline(x=0.5, color='red')\n",
    "plt.show()\n",
    "print('Note: 11046 color labels in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pareto color column to df\n",
    "- 0 = no color\n",
    "- 1 = secondary color\n",
    "- 2 = primary color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['Color:'] == ' Black/Black', 'Color:'] = ' Black' # Assuming Black/Black == Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change color to most mentioned per item\n",
    "# modes_col = df.groupby('item')['Color:'].apply(pd.Series.mode)\n",
    "# modes_col.name = 'Color2:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.merge(df, modes_col, left_on='item', right_on='item', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.to_pickle('Data/df_styles_and_cleaned_colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [' Black']\n",
    "\n",
    "def pareto_color(x):\n",
    "    x = x['Color2:']\n",
    "    if type(x) is float and np.isnan(x):\n",
    "        return 0\n",
    "    elif x in labels:\n",
    "        return 2\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = pd.DataFrame()\n",
    "# df_temp['par_col2'] = df.apply(pareto_color, axis=1, result_type='expand')\n",
    "# df = df.merge(df_temp, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('Data/df_styles_and_cleaned_colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('verified:', df['verified'].sum() / len(df))\n",
    "df = df[df['verified']==True]\n",
    "print('verified:', df['verified'].sum() / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    \"\"\"\" All functions used to run, test, plot and store the\n",
    "    Singular Value Decomposition Model\"\"\"\n",
    "\n",
    "    def __init__(self, params, total_users, total_items):\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.alpha = params['alpha']\n",
    "        self.alpha_b = params['alpha_b']\n",
    "        self.alpha_cb = params['alpha_cb']\n",
    "        self.use_bias = params['use_bias']\n",
    "        self.use_impl_fb = params['use_impl_fb']\n",
    "        self.use_color = params['use_color']\n",
    "        self.use_weight_ver = params['use_weight_ver']\n",
    "        self.bu_reg = params['bu_reg']\n",
    "        self.bi_reg = params['bi_reg']\n",
    "        self.pu_reg = params['pu_reg']\n",
    "        self.qi_reg = params['qi_reg']\n",
    "        self.x_reg = params['x_reg']\n",
    "        self.cb_reg = params['cb_reg']\n",
    "        self.ver_weight = params['ver_weight']\n",
    "        self.stop = params['stop']\n",
    "        self.random_state = params['random_state']\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.params = params\n",
    "        self.mu = 0 \n",
    "        self.N = []\n",
    "        self.N_test = []\n",
    "        self.t = pd.DataFrame()\n",
    "        self.c = pd.DataFrame()\n",
    "        self.F = pd.DataFrame()\n",
    "\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.train_time = 0\n",
    "        self.best_model = {}\n",
    "        self.model = {}\n",
    "        self.test_results = {}\n",
    "\n",
    "    def fit(self, train_data, val_data=[], verbose=1, plot=True, plot_name=''):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.SVD(train_data=train_data, val_data=val_data, verbose=verbose, plot=plot, plot_name=plot_name)\n",
    "        return self\n",
    "\n",
    "    \n",
    "###############################################################################################\n",
    "    \n",
    "    def SVD(self, train_data, val_data, verbose, plot, plot_name):\n",
    "        \"\"\"\"The SVD algorithm with sgd\n",
    "        input: rating dataset with columns:['rating', 'user_id', 'item_id']\n",
    "        output: the resulting p, q, bi, bu matrices\"\"\"\n",
    "        self.mu = self.create_mu(train_data)\n",
    "        train_matrix = self.create_matrix(train_data, total_users, total_items)\n",
    "        \n",
    "        tuples_train = [tuple(x) for x in train_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        \n",
    "        p = np.random.normal(0, .1, (total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (total_items, self.nolf))  # items\n",
    "        \n",
    "        # user and item biases\n",
    "        b_user = np.zeros(total_users)\n",
    "        b_item = np.zeros(total_items)\n",
    "        \n",
    "        # using color (pareto split (0,1,2)) attribute bias\n",
    "        if self.use_color:\n",
    "            print('Creating F and c, for incorporating color bias')\n",
    "            self.F, self.c = self.init_color(train_data)\n",
    "\n",
    "        # implicit fb rated, not rated\n",
    "        x = np.random.normal(0, .1, (total_items, self.nolf))\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        if self.use_impl_fb:\n",
    "            print('Creating N, for incorporating implicit feedback')\n",
    "            self.N = train_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        \n",
    "        # 0.5 weight on the errors of verified = False user item combinations\n",
    "        if self.use_weight_ver:\n",
    "            i_verified = train_data.set_index(['new_user_id', 'new_item_id'])['verified']\n",
    "            i_verified = i_verified.loc[~i_verified.index.duplicated(keep='first')]\n",
    "        \n",
    "        sqrt_Nu = 0\n",
    "        cb = 0\n",
    "        rmses = []\n",
    "        val_rmses = []\n",
    "        smallest_val_rmse = 10000\n",
    "        val_rmse = \"na\"\n",
    "        start = time.time()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_sq_error = 0\n",
    "            for u, i, r_ui in tuples_train:\n",
    "                u = int(u)\n",
    "                i = int(i)\n",
    "                \n",
    "                if self.use_impl_fb:\n",
    "                    impl_fb_u = np.zeros(self.nolf)\n",
    "                    sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                    for j in self.N[u]:\n",
    "                        impl_fb_u += x[j] / sqrt_Nu\n",
    "\n",
    "                if self.use_color and epoch > 5:\n",
    "                    F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                    u_mu = self.mu + b_user[u]\n",
    "                    sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        cb += (r_uf - u_mu) * self.c[u,i][index]\n",
    "                    cb /=  sqrt_F_ui\n",
    "                        \n",
    "                if self.use_bias:   \n",
    "                    error = r_ui - ((self.mu + b_user[u] + b_item[i] + cb) + np.dot(p[u] + impl_fb_u, q[i]))\n",
    "                    if self.use_weight_ver and not i_verified[u,i]:\n",
    "                        error = self.ver_weight * error\n",
    "                    \n",
    "                    b_user[u] += self.alpha_b * (error - self.bu_reg * b_user[u])\n",
    "                    b_item[i] += self.alpha_b * (error - self.bi_reg * b_item[i])\n",
    "                else:\n",
    "                    error = r_ui - np.dot(p[u], q[i])\n",
    "\n",
    "                p[u] += self.alpha * (error * q[i] - self.pu_reg * p[u])\n",
    "                q[i] += self.alpha * (error * (p[u] + impl_fb_u) - self.qi_reg * q[i])\n",
    "                total_sq_error += np.square(error)\n",
    "            \n",
    "                if self.use_impl_fb:\n",
    "                    for j in self.N[u]:\n",
    "                        x[j] += self.alpha * (error * q[i] / sqrt_Nu - self.x_reg * x[j])\n",
    "                \n",
    "                if self.use_color and epoch > 5:\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        u_mu = self.mu + b_user[u]\n",
    "                        self.c[u,i][index] += self.alpha_cb * (error * (1/sqrt_F_ui) * (r_uf - u_mu) - self.cb_reg * self.c[u,i][index])\n",
    "                \n",
    "            rmse = np.sqrt(total_sq_error / len(tuples_train))\n",
    "            rmses.append(rmse)\n",
    "            \n",
    "            self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "            \n",
    "            # Validation\n",
    "            if len(val_data) > 0:\n",
    "                new_val_rmse = self.test(val_data, val=True)\n",
    "                val_rmses.append(new_val_rmse)\n",
    "                if new_val_rmse < smallest_val_rmse:\n",
    "                    smallest_val_rmse = new_val_rmse\n",
    "                    self.best_model = copy.deepcopy(self.model)\n",
    "                val_rmse = new_val_rmse\n",
    "                \n",
    "            # Epoch Printing\n",
    "            if epoch % verbose == 0:\n",
    "                if len(val_data) > 0:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse, ' Val_RMSE:', val_rmse)\n",
    "                else:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse)\n",
    "            \n",
    "            if self.stop and val_rmses[-2:][0] < val_rmse:\n",
    "                print('BREAK: Validation set not improving anymore')\n",
    "                break\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_rmse(rmses, val_rmses, plot_name)\n",
    "\n",
    "        self.train_time = time.time() - start\n",
    "        self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "#################################################################################################\n",
    "\n",
    "    def init_color(self, data_set):\n",
    "        self.t = data_set.groupby(['new_user_id', 'par_col2'])['new_item_id'].apply(list)\n",
    "        F = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items)\n",
    "        c = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items, random=True)\n",
    "        return F, c\n",
    "\n",
    "    def sim_items(self, x, random=False):\n",
    "        u_id = x.name[0]\n",
    "        col = x.iloc[0]\n",
    "        if random:\n",
    "            return np.random.normal(0,.1,len(self.t[u_id, col]))\n",
    "        return self.t[u_id, col]\n",
    "    \n",
    "    def create_matrix(self, X_train, n_users, n_items):\n",
    "        n_users = df.user.unique().shape[0]\n",
    "        n_items = df.item.unique().shape[0]\n",
    "\n",
    "        r = X_train['new_user_id']\n",
    "        c = X_train['new_item_id']\n",
    "        d = X_train['rating']\n",
    "        train_matrix = sparse.coo_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "    \n",
    "        return train_matrix.tocsr()\n",
    "    \n",
    "    def create_mu(self, train_set):\n",
    "        # Better mean calculation according to https://sifter.org/~simon/journal/20061211.html\n",
    "        va = train_set.groupby('new_user_id')['rating'].mean().var() #variance mean ratings users\n",
    "        vb = train_set.groupby('new_item_id')['rating'].mean().var() #variance mean ratings items\n",
    "        k = va/vb #variance proportion\n",
    "        better_mu = (train_set['rating'].mean() + train_set['rating'].sum()) / (k+len(train_set))\n",
    "        return better_mu\n",
    "    \n",
    "    def plot_rmse(self, rmse, val_rmses=[], plot_name=''):\n",
    "        plt.plot(np.arange(len(rmse)), rmse)\n",
    "        if len(val_rmses) > 0:\n",
    "            plt.plot(np.arange(len(val_rmses)), val_rmses, color='red')\n",
    "        plt.title('RMSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        if len(plot_name) > 0:\n",
    "            plt.savefig('Plots/' + plot_name + '.png')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self, test_data, val=False):\n",
    "        if not val:\n",
    "            self.test_data = test_data\n",
    "        tuples_test = [tuple(x) for x in test_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        test_matrix = self.create_matrix(test_data, self.total_users, self.total_items)\n",
    "        \n",
    "        if self.use_impl_fb and val:\n",
    "            self.N_test = self.val_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        elif self.use_impl_fb:\n",
    "            self.N_test = self.test_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "            \n",
    "        total_error = 0\n",
    "        estimates = []\n",
    "        for u, i, r_ui in tuples_test:\n",
    "            u = int(u)\n",
    "            i = int(i)\n",
    "            est = self.estimate(u, i, test_matrix, test_data)\n",
    "            estimates.append(est)\n",
    "            total_error += np.square(r_ui - est)\n",
    "        \n",
    "        rmse = np.sqrt(total_error / len(tuples_test))\n",
    "        \n",
    "        if not val:\n",
    "            self.test_results = {'rmse': rmse, 'estimates':estimates}\n",
    "            print('RMSE on test set:', self.test_results['rmse'])\n",
    "        else:\n",
    "            return rmse\n",
    "\n",
    "    def estimate(self, u, i, test_matrix, test_data):\n",
    "        est = self.mu + self.model['bu'][u] + self.model['bi'][i]\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        cb = 0\n",
    "        if u in self.train_data['new_user_id'] and i in self.train_data['new_item_id']:\n",
    "            \n",
    "            if self.use_impl_fb and u in self.N.index:\n",
    "                sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                for j in self.N[u]:   \n",
    "                    impl_fb_u += self.model['x'][j] / sqrt_Nu\n",
    "            \n",
    "            if self.use_color and (u,i) in self.model['cbu']:\n",
    "                F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                u_mu = self.mu + self.model['bu'][u]\n",
    "                sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                for index, f in enumerate(F_ui):\n",
    "                    r_uf = self.train_data[(self.train_data['new_user_id']==u) & (self.train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                    cb += (r_uf - u_mu) * self.model['cbu'][u,i][index]\n",
    "                cb /=  sqrt_F_ui\n",
    "                \n",
    "            est += cb + np.dot(self.model['p'][u] + impl_fb_u, self.model['q'][i])\n",
    "\n",
    "        return est\n",
    "    \n",
    "    def store_results(self, log_path, res_name, user_thres, item_thres):\n",
    "        train_size = round((len(self.train_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        test_size = round((len(self.test_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        val_size = round((len(self.val_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        \n",
    "        result_info = {'RMSE_test': self.test_results['rmse'], 'train_speed': round(self.train_time,2)}\n",
    "        other_info = {'u_thres': user_thres,'i_thres': item_thres, 'train_size':train_size, 'test_size':test_size, 'val_size':val_size, 'train_rmse':self.model['rmse'], 'val_rmse':self.model['val_rmse']}\n",
    "        final_log = dict(result_info, **self.params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data #row:  2500010\n"
     ]
    }
   ],
   "source": [
    "def transform(df):\n",
    "    items = df['item'].unique()\n",
    "    itemsDF = pd.DataFrame(data=items, columns=['original_item_id'])\n",
    "    itemsDF['new_item_id'] = itemsDF.index\n",
    "\n",
    "    users = df['user'].unique()\n",
    "    usersDF = pd.DataFrame(data=users, columns=['original_user_id'])\n",
    "    usersDF['new_user_id'] = usersDF.index\n",
    "\n",
    "    ratingDF = df.merge(itemsDF, left_on='item', right_on='original_item_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_item_id'])\n",
    "\n",
    "    ratingDF = ratingDF.merge(usersDF, left_on='user', right_on='original_user_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_user_id'])\n",
    "\n",
    "    df_new_ids = ratingDF\n",
    "    print('Full data #row: ', df_new_ids.shape[0])\n",
    "    df_new_ids.head()\n",
    "    \n",
    "    return df_new_ids\n",
    "\n",
    "df_new_ids = transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split\n",
    "Train 0.8, Train 0.2, Test 0.1, could add validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  2000008\n",
      "Size of validation set:  250001\n",
      "Size of test set:  250001\n"
     ]
    }
   ],
   "source": [
    "random_state = 1234\n",
    "train_set, test_set = train_test_split(df_new_ids, test_size=0.20, shuffle=True, random_state=random_state)\n",
    "val_set, test_set = train_test_split(test_set, test_size=0.50, shuffle=True, random_state=random_state)\n",
    "\n",
    "print('Size of train set: ', len(train_set))\n",
    "print('Size of validation set: ', len(val_set))\n",
    "print('Size of test set: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_epochs\":40,\n",
    "\"random_state\":1234,\n",
    "\n",
    "#Learning rate\n",
    "\"alpha\":0.004, #Low alpha to prevent diverging => sgd all over the place => error up\n",
    "\"alpha_b\":0.004,\n",
    "\"alpha_cb\":0.001,\n",
    "\n",
    "\"stop\":True, #Stops when val set does not improve\n",
    "\"use_bias\":True,\n",
    "\"use_color\":False,\n",
    "\"use_impl_fb\":False,\n",
    "\"use_weight_ver\":False,\n",
    "\n",
    "#Regularizers, still tweaking the values\n",
    "\"bu_reg\":0.1,\n",
    "\"bi_reg\":0.1,\n",
    "\"pu_reg\":0.001,\n",
    "\"qi_reg\":0.001,\n",
    "\"x_reg\":0.001,\n",
    "\"cb_reg\": 0.01,\n",
    "\"ver_weight\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model basic bias on ML 1.25m, more regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   RMSE: 0.982083974148823  Val_RMSE: 0.9562887502111975\n",
      "Epoch: 1   RMSE: 0.9364414680259865  Val_RMSE: 0.9352208729973551\n",
      "Epoch: 2   RMSE: 0.9161313403711229  Val_RMSE: 0.9235356630357074\n",
      "Epoch: 3   RMSE: 0.9024386443348956  Val_RMSE: 0.9158432891727681\n",
      "Epoch: 4   RMSE: 0.8919735659905226  Val_RMSE: 0.9103665233735506\n",
      "Epoch: 5   RMSE: 0.8833639318360955  Val_RMSE: 0.9062971840660867\n",
      "Epoch: 6   RMSE: 0.8758841094674105  Val_RMSE: 0.9032040226599487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8430acc88673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ML_1.25m_more_reg_svd_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-3ecfd488fe52>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, val_data, verbose, plot, plot_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3ecfd488fe52>\u001b[0m in \u001b[0;36mSVD\u001b[1;34m(self, train_data, val_data, verbose, plot, plot_name)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_ui\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_item\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimpl_fb_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_weight_ver\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi_verified\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mver_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SVD(params, total_users, total_items)\n",
    "model.fit(train_set, val_set, 1, plot=True, plot_name='ML_1.25m_more_reg_svd_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating N, for incorporating implicit feedback\n"
     ]
    }
   ],
   "source": [
    "params['bu_reg'] = 0.05\n",
    "params['bi_reg'] = 0.05\n",
    "params['use_impl_fb'] = True\n",
    "model2 = SVD(params, total_users, total_items)\n",
    "model2.fit(train_set, val_set, 1, plot=True, plot_name='ML_1.25m_svd_train_impl_fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model basic bias Amazon 1m (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVD(params, total_users, total_items)\n",
    "model2.fit(train_set, val_set, 1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.test(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'Results/'\n",
    "res_name = 'diff_amazon_ml_svd_res'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results added\n"
     ]
    }
   ],
   "source": [
    "model.store_results(log_path, res_name, user_thres, item_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results added\n"
     ]
    }
   ],
   "source": [
    "model2.store_results(log_path, res_name, user_thres, item_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>random_state</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_b</th>\n",
       "      <th>alpha_cb</th>\n",
       "      <th>stop</th>\n",
       "      <th>use_bias</th>\n",
       "      <th>use_color</th>\n",
       "      <th>use_impl_fb</th>\n",
       "      <th>use_weight_ver</th>\n",
       "      <th>bu_reg</th>\n",
       "      <th>bi_reg</th>\n",
       "      <th>pu_reg</th>\n",
       "      <th>qi_reg</th>\n",
       "      <th>x_reg</th>\n",
       "      <th>cb_reg</th>\n",
       "      <th>ver_weight</th>\n",
       "      <th>u_thres</th>\n",
       "      <th>i_thres</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>val_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904661</td>\n",
       "      <td>549.43</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.0007526591710543, 0.9572820977613882, 0.935...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997974</td>\n",
       "      <td>2934.89</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.1069741696109745, 1.0849443026301908, 1.066...</td>\n",
       "      <td>[1.1002774195757585, 1.0896664793212159, 1.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.894804</td>\n",
       "      <td>774.98</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.9820154077500364, 0.9363586693933367, 0.916...</td>\n",
       "      <td>[0.9562261376290389, 0.9351584078789088, 0.923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893831</td>\n",
       "      <td>766.16</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.9814737995364082, 0.9354437443468923, 0.914...</td>\n",
       "      <td>[0.9555007891924439, 0.9342703031655163, 0.922...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_test  train_speed nolf n_epochs random_state  alpha  alpha_b  \\\n",
       "0   0.904661       549.43   20       40         1234  0.004    0.004   \n",
       "1   0.997974      2934.89   20       40         1234  0.004    0.004   \n",
       "2   0.894804       774.98   20       40         1234  0.004    0.004   \n",
       "3   0.893831       766.16   20       40         1234  0.004    0.004   \n",
       "\n",
       "   alpha_cb  stop use_bias use_color use_impl_fb use_weight_ver  bu_reg  \\\n",
       "0     0.001  True     True     False       False          False    0.05   \n",
       "1     0.001  True     True     False       False          False    0.10   \n",
       "2     0.001  True     True     False       False          False    0.05   \n",
       "3     0.001  True     True     False       False          False    0.05   \n",
       "\n",
       "   bi_reg  pu_reg  qi_reg  x_reg  cb_reg  ver_weight u_thres i_thres  \\\n",
       "0    0.05   0.001   0.001  0.001    0.01         0.5       1       1   \n",
       "1    0.10   0.001   0.001  0.001    0.01         0.5       5       5   \n",
       "2    0.05   0.001   0.001  0.001    0.01         0.5       1       1   \n",
       "3    0.05   0.001   0.001  0.001    0.01         0.5       1       1   \n",
       "\n",
       "   train_size  test_size  val_size  \\\n",
       "0         0.8        0.1       0.1   \n",
       "1         0.8        0.1       0.1   \n",
       "2         0.8        0.1       0.1   \n",
       "3         0.8        0.1       0.1   \n",
       "\n",
       "                                          train_rmse  \\\n",
       "0  [1.0007526591710543, 0.9572820977613882, 0.935...   \n",
       "1  [1.1069741696109745, 1.0849443026301908, 1.066...   \n",
       "2  [0.9820154077500364, 0.9363586693933367, 0.916...   \n",
       "3  [0.9814737995364082, 0.9354437443468923, 0.914...   \n",
       "\n",
       "                                            val_rmse  \n",
       "0                                                NaN  \n",
       "1  [1.1002774195757585, 1.0896664793212159, 1.080...  \n",
       "2  [0.9562261376290389, 0.9351584078789088, 0.923...  \n",
       "3  [0.9555007891924439, 0.9342703031655163, 0.922...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(log_path + res_name).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete last results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(log_path + res_name)[1:].to_pickle(log_path + res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation all algs data with #ratings/item & user > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv(data, params, n_splits, res_name, model_res_name):\n",
    "    kf = KFold(n_splits = n_splits, shuffle = True)\n",
    "    full_data = data\n",
    "    scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        result = next(kf.split(full_data), None)\n",
    "        train_set = full_data.iloc[result[0]]\n",
    "        test_set = full_data.iloc[result[1]]\n",
    "        model = SVD(params, total_users, total_items)\n",
    "        model.fit(train_set, verbose = 1000, plot = False)\n",
    "        \n",
    "        model.test(test_set)\n",
    "        model.store_results('', model_res_name, user_thres, item_thres)  \n",
    "\n",
    "    df_cv_results = pd.read_pickle(model_res_name)[-5:]\n",
    "    params_dict = df_cv_results.iloc[0][['nolf', 'n_epochs', 'random_state', 'alpha', 'alpha_b', 'use_bias', 'use_impl_fb', 'use_color', 'use_weight_ver', 'ver_weight' 'bu_reg', 'bi_reg', 'pu_reg', 'qi_reg', 'x_reg', 'u_thres', 'i_thres', 'train_size', 'test_size', 'train_rmse']].to_dict()\n",
    "    avg_rmse_dict = {'avg_rmse_test':np.average(df_cv_results['RMSE_test'])}\n",
    "    final_dict = {**avg_rmse_dict, **params_dict}\n",
    "\n",
    "    if not os.path.exists(res_name):\n",
    "        cv_res = pd.DataFrame(columns=final_dict.keys())\n",
    "        print('new results created')\n",
    "\n",
    "    else:\n",
    "        cv_res = pd.read_pickle(res_name)\n",
    "        print('results added')\n",
    "\n",
    "    cv_res = cv_res.append(final_dict, ignore_index=True)\n",
    "    pd.to_pickle(cv_res, res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_bias_only'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Verification and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_weight_ver'] = True\n",
    "params['ver_weight'] = 0.7\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_ver_weight'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb with Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_weight_ver'] = False\n",
    "params['use_impl_fb'] = True\n",
    "params['x_reg'] = 0.01\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_impl_fb'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color attribute with Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = False\n",
    "params['use_color'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_color'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impl_fb with verification weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = True\n",
    "params['use_color'] = False\n",
    "params['use_weight_ver'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_ver_weight_impl_fb'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color, impl_fb, weight_ver and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['use_impl_fb'] = True\n",
    "params['use_color'] = True\n",
    "params['use_weight_ver'] = True\n",
    "log_path = 'Results/'\n",
    "res_name = log_path + 'cv_#ratings_ui_above_3_all_algs'\n",
    "cv_res_name = log_path + 'cv_#ratings_ui_above_3_bias_impl_fb_weight_color'\n",
    "n_splits = 5\n",
    "\n",
    "cv(df_new_ids, params, n_splits, res_name, cv_res_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results CV all algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.read_pickle(res_name).sort_values('avg_rmse_test')\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name = 'cv_half_df_all_algs'\n",
    "cv_res_name = 'cv_res_bias'\n",
    "log_path = 'Results/'\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = n_splits, shuffle = True)\n",
    "full_data = df_new_ids\n",
    "scores = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    result = next(kf.split(full_data), None)\n",
    "    train_set = full_data.iloc[result[0]]\n",
    "    test_set = full_data.iloc[result[1]]\n",
    "    model = SVD(params, total_users, total_items)\n",
    "    model.fit(train_set, verbose = 1000, plot = False)\n",
    "\n",
    "    model.test(test_set)\n",
    "    model.store_results(log_path, cv_res_name, user_thres, item_thres)  \n",
    "\n",
    "df_cv_results = pd.read_pickle(log_path + cv_res_name)[-5:]\n",
    "params_dict = df_cv_results.iloc[0][['nolf', 'n_epochs', 'random_state', 'alpha', 'alpha_b', 'use_bias', 'use_impl_fb', 'use_color', 'use_weight_ver', 'bu_reg', 'bi_reg', 'pu_reg', 'qi_reg', 'x_reg', 'u_thres', 'i_thres', 'train_size', 'test_size', 'train_rmse']].to_dict()\n",
    "avg_rmse_dict = {'avg_rmse_test':np.average(df_cv_results['RMSE_test'])}\n",
    "final_dict = {**avg_rmse_dict, **params_dict}\n",
    "\n",
    "if not os.path.exists(log_path + res_name):\n",
    "    cv_res = pd.DataFrame(columns=final_dict.keys())\n",
    "    print('new results created')\n",
    "\n",
    "else:\n",
    "    cv_res = pd.read_pickle(log_path + res_name)\n",
    "    print('results added')\n",
    "\n",
    "cv_res = cv_res.append(final_dict, ignore_index=True)\n",
    "pd.to_pickle(cv_res, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.read_pickle(log_path + res_name).sort_values('avg_rmse_test')\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and View Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(log_path +'all_results_movie_lens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old but gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('Results/df_comparison_impl_fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_pickle('Results/' + 'df_results_svd')\n",
    "df_results.sort_values('RMSE_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the RMSE in the first results should be higher (+1.1) due to a mistake in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['with Bias and Reg', 'with Bias', 'Plain']\n",
    "y = [1.313160, 1.314319, 2.860927]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(len(y))\n",
    "width = 0.8\n",
    "ax.bar(ind, y, width, color=['darkblue'])\n",
    "ax.set_xticks(ind+width/500)\n",
    "ax.set_xticklabels(x, minor=False)\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Model Comparison')\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(i -0.2, v + 0.02, str(v), fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model train RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best from Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df_results_b.iloc[6]\n",
    "model.plot_rmse(best['train_rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best of All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df_results_all\n",
    "model.plot_rmse(best['train_rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.linalg import sqrtm\n",
    "\n",
    "# X_train, X_test = train_test_split(df, test_size=0.10, shuffle=True, random_state=1234)\n",
    "# X_validation, X_test = train_test_split(X_test, test_size=0.50, shuffle=True, random_state=1234)\n",
    "\n",
    "# def create_utility_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
    "#     \"\"\"\n",
    "#         :param data:      Array-like, 2D, nx3\n",
    "#         :param formatizer:pass the formatizer\n",
    "#         :return:          utility matrix (n x m), n=users, m=items\n",
    "#     \"\"\"\n",
    "        \n",
    "#     itemField = formatizer['item']\n",
    "#     userField = formatizer['user']\n",
    "#     valueField = formatizer['value']\n",
    "    \n",
    "#     userList = data.iloc[:,userField].tolist()\n",
    "#     itemList = data.iloc[:,itemField].tolist()\n",
    "#     valueList = data.iloc[:,valueField].tolist()\n",
    "    \n",
    "#     users = list(set(data.iloc[:,userField]))\n",
    "#     items = list(set(data.iloc[:,itemField]))\n",
    "    \n",
    "#     users_index = {users[i]: i for i in range(len(users))}\n",
    "#     pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "    \n",
    "#     for i in range(0,len(data)):\n",
    "#         item = itemList[i]\n",
    "#         user = userList[i]\n",
    "#         value = valueList[i]\n",
    "        \n",
    "#     pd_dict[item][users_index[user]] = value\n",
    "#     X = pd.DataFrame(pd_dict)\n",
    "#     X.index = users\n",
    "        \n",
    "#     itemcols = list(X.columns)\n",
    "#     items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
    "#     # users_index gives us a mapping of user_id to index of user\n",
    "#     # items_index provides the same for items\n",
    "#     return X, users_index, items_index\n",
    "\n",
    "# X, users_index, items_index = create_utility_matrix(X_train)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_users = df.user.unique().shape[0]\n",
    "# n_items = df.item.unique().shape[0]\n",
    "\n",
    "# ratings_train = np.zeros((n_users, n_items))\n",
    "# for row in X_train.itertuples():\n",
    "#         ratings_train[row[5], row[4]] = row[3]\n",
    "\n",
    "# pd.DataFrame(ratings_train).head()\n",
    "# # sparse.csr_matrix((X_train['rating']),shape(n_users, n_items))\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different SGD coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_item_combos = 0\n",
    "# for epoch in range(n_epochs):\n",
    "#     for u in range(ratings_train.shape[0]): #users\n",
    "#         for i in range(ratings_train.shape[1]): #items\n",
    "#             r_ui = ratings_train[u,i]\n",
    "            \n",
    "#             if  r_ui != 0:\n",
    "#                 user_item_combos += 1\n",
    "#                 error = r_ui - np.dot(p[u], q[i])\n",
    "                \n",
    "#                 p[u] += alpha *(error * q[i])\n",
    "#                 q[i] += alpha * (error * p[u])\n",
    "                \n",
    "#                 total_error += np.square(error)\n",
    "# #         print(total_error)\n",
    "#     rmse = math.sqrt(total_error)\n",
    "#     print('epoch: ', epoch)#, '  rmse: ', rmse)\n",
    "#     print(user_item_combos, X_train['rating'].shape[0])\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_user[u] += alpha_b * (error - bu_reg * b_user[u])\n",
    "# b_item[i] += alpha_b * (error - bi_reg * b_item[i])\n",
    "            \n",
    "# p[u] += alpha * (error * q[i] - pu_reg * p[u])\n",
    "# q[i] += alpha * (error * p[u] - qi_reg * q[i])\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colors binary split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [8,6]\n",
    "# pop_col = (df.groupby('Color:')['rating'].count().sort_values(ascending=False)[0:35]/len(df)).sum()\n",
    "# non_pop_col = (df.groupby('Color:')['rating'].count().sort_values(ascending=False)[35:]/len(df)).sum()\n",
    "\n",
    "# bars = plt.bar(['pop_col', 'non_pop_col'], [pop_col, non_pop_col])\n",
    "# plt.text(bars[0].get_x() + 0.13, pop_col + -0.05, pop_col, color=\"white\", fontweight = 'bold')\n",
    "# plt.text(bars[1].get_x() + 0.13, non_pop_col + -0.05, non_pop_col, color=\"white\", fontweight = 'bold')\n",
    "# plt.title('Binary split between 35 most populair colors and non populair colors')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_colors = df.groupby('Color:')['rating'].count().sort_values(ascending=False)[0:35] \n",
    "\n",
    "# def pop_color(x):\n",
    "#     x = x['Color:']\n",
    "#     if x in pop_colors:\n",
    "#         return 1\n",
    "#     elif x not in pop_colors:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# temp_df = pd.DataFrame()\n",
    "# temp_df['bin_pop_col'] = df.apply(pop_color, axis=1, result_type='expand')\n",
    "# df = df.merge(temp_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
