{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1586364379603,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "eWJsd_7Pc-TZ",
    "outputId": "38fa93e1-7d3a-4b3e-9cc5-ff2f5debea21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "# data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>datetime</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18590190</th>\n",
       "      <td>120461</td>\n",
       "      <td>2501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>2410</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590032</th>\n",
       "      <td>120461</td>\n",
       "      <td>252</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>249</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590159</th>\n",
       "      <td>120461</td>\n",
       "      <td>2069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1980</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590048</th>\n",
       "      <td>120461</td>\n",
       "      <td>440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>435</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590145</th>\n",
       "      <td>120461</td>\n",
       "      <td>1959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1870</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  item  rating            datetime item_id user_id\n",
       "18590190  120461  2501     5.0 2000-04-25 02:29:35    2410  120460\n",
       "18590032  120461   252     4.0 2000-04-25 02:29:35     249  120460\n",
       "18590159  120461  2069     4.0 2000-04-25 02:29:35    1980  120460\n",
       "18590048  120461   440     4.0 2000-04-25 02:29:35     435  120460\n",
       "18590145  120461  1959     4.0 2000-04-25 02:29:35    1870  120460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "### Leave last item out of subset of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_users_out(full_data, leave_out, seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    full_data['index'] = full_data.index\n",
    "    user_index_df = full_data.groupby('user')['index'].apply(list)\n",
    "    users = np.random.choice(list(user_index_df.index), leave_out, replace=False)\n",
    "    users_indices = []\n",
    "    \n",
    "    for user in users:\n",
    "        users_indices.extend(user_index_df.loc[user])\n",
    "    \n",
    "    sub_set = full_data.loc[users_indices]\n",
    "    remaining = full_data.drop(users_indices)\n",
    "    \n",
    "    return remaining.drop(columns=['index']), sub_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_x_out(full_data, n_users, leave_out=1, seed=1234):\n",
    "    \"\"\" \n",
    "    Input: data must contain user_id\n",
    "    Output: full_data = without all last (time order) entries in leave one out set\n",
    "            leave_one_out_set = data with one user and one item from full_data\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('user_id')['index'].apply(list)\n",
    "    users = full_data.user_id.unique()\n",
    "    leave_out_indices = []\n",
    "    users_picked = []\n",
    "    \n",
    "    for i in range(len(full_data.user_id.unique())):\n",
    "        random_user = np.random.choice(users)\n",
    "        item_indices = user_items_ind[random_user] # random user's items indices\n",
    "        if random_user in users_picked or len(item_indices) <= leave_out:\n",
    "            random_user = np.random.choice(users)\n",
    "            item_indices = user_items_ind[random_user] # random user's items indices\n",
    "        else:\n",
    "            users_picked.append(random_user)\n",
    "            leave_out_indices.extend(item_indices[-leave_out:])\n",
    "        \n",
    "        if len(users_picked) == n_users:\n",
    "            break\n",
    "        \n",
    "    if len(users_picked) < n_users:\n",
    "        error = 'Cannot pick ' + str(n_users) + ' users with more than ' + str(leave_out) + ' items'\n",
    "        solution = '\\nTry a smaller test and/or validation percentage of the data'\n",
    "        raise ValueError(error + solution) \n",
    "            \n",
    "    leave_out_set = full_data.loc[leave_out_indices] # the last items of n_users users with n_item > leave_out\n",
    "    full_data_leave_one_out = full_data.drop(leave_out_indices) # drops last items for n_users users\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, batch_size, val_perc, test_perc, n_items_val, n_items_test, stats=True):\n",
    "    \"\"\"\n",
    "    Input: df with user and item id, batch size for CFRNN data, val and test perc of users\n",
    "           number of last items to leave out for val and test set\n",
    "    Output: full_data = total users and items of the original df, \n",
    "            Train, validation and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    total_users = len(df.user_id.unique()) # Need all users for BPR\n",
    "    total_items = len(df.item_id.unique()) # Need all items for CFRNN\n",
    "    \n",
    "    users_to_remove = len(df.user_id.unique())%batch_size #Batch size compatible for CFRNN\n",
    "    df_new, deleted_users = leave_users_out(df, users_to_remove)\n",
    "\n",
    "    test_users = int(test_perc*total_users / 64 + 1) * 64 # Number of users to be used for testing\n",
    "    test_last_items = n_items_test # Items to be removed from test users in train set and used in test set\n",
    "\n",
    "    val_users = int(val_perc*total_users / 64 + 1) * 64\n",
    "    val_last_items = n_items_val\n",
    "    \n",
    "    train_set, test_set = leave_last_x_out(df_new, test_users, test_last_items)\n",
    "    train_set, val_set = leave_last_x_out(train_set, val_users, val_last_items)\n",
    "    \n",
    "    if stats:\n",
    "        print('Total number of items:', total_items)\n",
    "        print('Total users:', total_users)\n",
    "        print('Number of train users:', len(train_set.user_id.unique()))\n",
    "        print('Number of test users:', test_users)\n",
    "        print('Number of validation users:', val_users, '\\n')\n",
    "        print('Users deleted:', len(deleted_users.user_id.unique()))\n",
    "    \n",
    "    return total_users, total_items, train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 27387\n",
      "Total users: 16254\n",
      "Number of train users: 16224\n",
      "Number of test users: 1664\n",
      "Number of validation users: 1664 \n",
      "\n",
      "Users deleted: 30\n"
     ]
    }
   ],
   "source": [
    "total_users, total_items, train_set, val_set, test_set = train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKThZjwtc-Tx"
   },
   "source": [
    "---\n",
    "# Data Prep\n",
    "1. Each (relatively) ordered item sequence per user will be viewed as one time series\n",
    "2. **Sequences will be batched based on their length such that padding is minimal**\n",
    "3. Each batch consists out of BATCH_SIZE users sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aneydXL_c-Uc"
   },
   "source": [
    "## Train and Target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_sequences_ordered(dataset, n_unknowns_in_y=1, stats=True):\n",
    "    user_sequences_x = []\n",
    "    user_sequences_y = []\n",
    "    lengths = []\n",
    "    users = dataset.user_id.unique()\n",
    "    shortest_u_seq_order = list(df.groupby('user_id')['item_id'].count().sort_values().index)\n",
    "    \n",
    "    for u in shortest_u_seq_order:\n",
    "        user_item_seq = np.array(dataset[dataset['user_id']==u]['item_id'])\n",
    "        user_sequences_x.append(user_item_seq[:-n_unknowns_in_y])\n",
    "        user_sequences_y.append(user_item_seq[n_unknowns_in_y:])\n",
    "        lengths.append(len(user_item_seq))\n",
    "    \n",
    "    median = np.median(lengths)\n",
    "    \n",
    "    if stats:\n",
    "        print('Number of sequences x:', len(user_sequences_x), \n",
    "              '\\nAvg sequence length x:', np.average(lengths),\n",
    "              '\\nStd_dev sequence length x:', np.round(np.std(lengths),2),\n",
    "              '\\nMedian of sequence length x:', median)\n",
    "\n",
    "    return user_sequences_x, user_sequences_y, shortest_u_seq_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_padding(sequences, batch_size, max_len):\n",
    "    padded_sequences = []\n",
    "    batch = []\n",
    "    max_batch_seq_len = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        batch.append(seq)\n",
    "        if max_batch_seq_len > max_len:\n",
    "            max_batch_seq_len = max_len\n",
    "            \n",
    "        elif max_batch_seq_len < len(seq):\n",
    "            max_batch_seq_len = len(seq)\n",
    "            \n",
    "        if (i+1)%batch_size == 0:\n",
    "            padded_sequences.append(tf.keras.preprocessing.sequence.pad_sequences(batch, maxlen=int(max_batch_seq_len), padding='post', truncating='pre'))\n",
    "            max_batch_seq_len = 0\n",
    "            batch = [] \n",
    "            \n",
    "    return padded_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create minimal padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 500\n",
    "shift_targets_by = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences x: 16254 \n",
      "Avg sequence length x: 150.0122431401501 \n",
      "Std_dev sequence length x: 242.4 \n",
      "Median of sequence length x: 70.0\n"
     ]
    }
   ],
   "source": [
    "user_sequences_x, user_sequences_y, user_order = get_x_y_sequences_ordered(train_set, shift_targets_by)\n",
    "\n",
    "padded_sequences_x = min_padding(user_sequences_x, BATCH_SIZE, max_seq_len)\n",
    "padded_sequences_y = min_padding(user_sequences_y, BATCH_SIZE, max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dfr9RyeAc-U5"
   },
   "source": [
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code: https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYbz0zq8c-U5"
   },
   "source": [
    "---\n",
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huW9kTD0c-U6"
   },
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjqXT55ic-U8"
   },
   "outputs": [],
   "source": [
    "def build_model(total_items, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(total_items, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        \n",
    "        tf.keras.layers.LSTM(units=rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=False, #Reset cell states with each batch\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(total_items)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "total_items = total_items,\n",
    "embedding_dim = embedding_dim,\n",
    "rnn_units = rnn_units,\n",
    "batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "### Add Loss\n",
    "- **Added one hot encoding of the labels to match logits output after dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recall(y_true, y_pred):\n",
    "#     K = tf.keras.backend\n",
    "#     y_true = K.one_hot(tf.dtypes.cast(y_true, tf.int32), total_items)\n",
    "#     y_true = K.ones_like(y_true) \n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "#     recall = true_positives / (all_positives + K.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE_UKWEgc-VF"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    oh_labels = tf.keras.backend.one_hot(tf.dtypes.cast(labels, tf.int32), total_items)\n",
    "    return tf.keras.losses.categorical_crossentropy(oh_labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adagrad', loss=loss)#, metrics=[recall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (32, None, 100)           2738700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, None, 27387)         575127    \n",
      "=================================================================\n",
      "Total params: 3,323,507\n",
      "Trainable params: 3,323,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator\n",
    "- Needed for the different size batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Generator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, X, y, batch_size=1, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.y)#int(np.floor(len(self.y)/self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Shuffles indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        return np.stack(self.X[index]), np.stack(self.y[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences_val_x, user_sequences_val_y, median = get_x_y_sequences_ordered(val_set, 1, stats=False)\n",
    "\n",
    "padded_sequences_val_x = min_padding(user_sequences_val_x, 32, 500)\n",
    "padded_sequences_val_y = min_padding(user_sequences_val_y, 32, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_sequences_val_x, user_sequences_val_y, median = get_x_y_sequences(val_set, 1, stats=False)\n",
    "\n",
    "# padded_sequences_val_x = pad_sequences(user_sequences_val_x, max_seq_length, stats=False)\n",
    "# padded_sequences_val_y = pad_sequences(user_sequences_val_y, max_seq_length, stats=False)\n",
    "\n",
    "# sequences_data_val_x = tf.data.Dataset.from_tensor_slices(padded_sequences_val_x) \n",
    "# sequences_data_val_y = tf.data.Dataset.from_tensor_slices(padded_sequences_val_y) \n",
    "\n",
    "# val_dataset = tf.data.Dataset.zip((sequences_data_val_x, sequences_data_val_y))\n",
    "# val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "### Configure Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './rnn_train_checkpoints'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "---\n",
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Batches: 507\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "print('#Batches:', len(padded_sequences_x))\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_generator():\n",
    "#     for X_train, y_train in zip(padded_sequences_x, padded_sequences_y):\n",
    "#         yield (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "507/507 [==============================] - 49s 97ms/step - loss: 9.5765\n",
      "Epoch 2/200\n",
      "507/507 [==============================] - 46s 91ms/step - loss: 8.9109\n",
      "Epoch 3/200\n",
      "253/507 [=============>................] - ETA: 23s - loss: 8.6455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-581739fc6dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                               use_multiprocessing=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_zeros\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fast_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_fast_fill\u001b[0;34m(value, shape, dtype)\u001b[0m\n\u001b[1;32m    621\u001b[0m   return array_ops.fill(\n\u001b[1;32m    622\u001b[0m       \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       constant_op.constant(value, dtype=dtype))\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m   3584\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   3585\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fill\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m         name, _ctx._post_execution_callbacks, dims, value)\n\u001b[0m\u001b[1;32m   3587\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=Batch_Generator(\n",
    "                              X=padded_sequences_x, \n",
    "                              y=padded_sequences_y, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True),\n",
    "                              \n",
    "#                               validation_data=Batch_Generator(\n",
    "#                               X=padded_sequences_val_x,\n",
    "#                               y=padded_sequences_val_y,\n",
    "#                               batch_size=BATCH_SIZE,\n",
    "#                               shuffle=True),\n",
    "                              \n",
    "                              epochs=epochs, \n",
    "                              callbacks=[checkpoint_callback],\n",
    "                              use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_01_users'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(history.history)\n",
    "results.to_pickle('his_vsl_01_ml_users_200_epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMQBMjJfc-Vt"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(n_items, embedding_dim, rnn_units, batch_size=100)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.compile(optimizer='Adagrad', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "aditional_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=aditional_epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY0mtM26c-V_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./rnn_train_checkpoints/ckpt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-Ths7-hc-WE"
   },
   "outputs": [],
   "source": [
    "model = build_model(total_items, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "                   \n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQfRtD71c-WH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 100)            2738700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 20)             9680      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 27387)          575127    \n",
      "=================================================================\n",
      "Total params: 3,323,507\n",
      "Trainable params: 3,323,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQNPBkyQc-WI"
   },
   "source": [
    "---\n",
    "## Create Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3A-hRV-c-WJ"
   },
   "source": [
    "**Using train_set sequences to predict test_set item(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 [10474] 145\n",
      "578 [0] 578\n",
      "576 [0] 576\n",
      "309 [0] 309\n",
      "583 [1022] 583\n",
      "331 [0] 331\n",
      "9 [2726] 9\n",
      "156 [0] 156\n",
      "0 [175] 0\n",
      "203 [9] 203\n",
      "180 [9624] 180\n",
      "448 [0] 448\n",
      "401 [25633] 401\n",
      "310 [219] 310\n",
      "445 [6981] 445\n",
      "423 [0] 423\n",
      "356 [22495] 356\n",
      "543 [9416] 543\n",
      "329 [168] 329\n",
      "348 [15398] 348\n",
      "230 [0] 230\n",
      "471 [0] 471\n",
      "431 [0] 431\n",
      "181 [2245] 181\n",
      "16 [0] 16\n",
      "137 [160] 137\n",
      "163 [85] 163\n",
      "259 [152] 259\n",
      "342 [0] 342\n",
      "369 [2372] 369\n",
      "218 [0] 218\n",
      "500 [1445] 500\n",
      "266 [5458] 266\n",
      "271 [5412] 271\n",
      "61 [1189] 61\n",
      "491 [699] 491\n",
      "349 [189] 349\n",
      "231 [1535] 231\n",
      "340 [20186] 340\n",
      "530 [4190] 530\n",
      "575 [0] 575\n",
      "585 [7748] 585\n",
      "459 [1176] 459\n",
      "506 [595] 506\n",
      "499 [1800] 499\n",
      "57 [321] 57\n",
      "4 [20450] 4\n",
      "488 [3623] 488\n",
      "360 [0] 360\n",
      "630 [1242] 630\n",
      "482 [2664] 482\n",
      "363 [7245] 363\n",
      "190 [6220] 190\n",
      "343 [5474] 343\n",
      "582 [18036] 582\n",
      "428 [3654] 428\n",
      "375 [6990] 375\n",
      "520 [1191] 520\n",
      "139 [2823] 139\n",
      "466 [1176] 466\n",
      "622 [3350] 622\n",
      "525 [15022] 525\n",
      "584 [699] 584\n",
      "353 [102] 353\n",
      "524 [9537] 524\n",
      "526 [4045] 526\n",
      "528 [3876] 528\n",
      "374 [2294] 374\n",
      "403 [0] 403\n",
      "529 [1881] 529\n",
      "339 [1032] 339\n",
      "273 [13361] 273\n",
      "532 [13364] 532\n",
      "437 [3291] 437\n",
      "42 [574] 42\n",
      "200 [23889] 200\n",
      "451 [11700] 451\n",
      "434 [20669] 434\n",
      "620 [2561] 620\n",
      "463 [6636] 463\n"
     ]
    }
   ],
   "source": [
    "test_user_seq = np.array(train_set[train_set['user_id']==10278]['item_id']).reshape(-1,1).T\n",
    "true_items = list(test_set[test_set['user_id']==10278]['item_id'])\n",
    "predictions = tf.squeeze(model(test_user_seq),0)\n",
    "predictions = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "user_seq = np.array(df[df['user_id']==10278]['item_id']).reshape(-1,1).T\n",
    "\n",
    "for item, pred_item, real in zip(list(test_user_seq[0]), predictions, user_seq[0]):\n",
    "    print(item, pred_item, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSmlKF14c-WP"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, train_set, test_set, rank_at, temp=0.9):\n",
    "\n",
    "    predictions_df = pd.DataFrame(columns=['user', 'pred_seq', 'true_seq'])\n",
    "    for u in test_set.user_id.unique():\n",
    "        test_user_seq = np.array(train_set[train_set['user_id']==u]['item_id'])\n",
    "        true_items = list(test_set[test_set['user_id']==u]['item_id'])\n",
    "        generated_predictions = []\n",
    "\n",
    "        #Predict\n",
    "        for item in range(rank_at): #could be any number of recommended items you want to predict\n",
    "            predictions = model(test_user_seq.reshape(-1,1).T)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "            predictions = predictions / temp\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "            test_user_seq = np.append(test_user_seq, predicted_id).reshape(-1,1).transpose()\n",
    "\n",
    "    #         half_test_seq = tf.expand_dims([predicted_id], 0)\n",
    "            generated_predictions.append(predicted_id)\n",
    "\n",
    "        predictions_df = predictions_df.append({'user':u, 'pred_seq':generated_predictions, 'true_seq':true_items}, ignore_index=True)\n",
    "        \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "predictions_df = get_predictions(model, train_set, val_set, rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>pred_seq</th>\n",
       "      <th>true_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10278</td>\n",
       "      <td>[2437, 1165, 7804, 12191, 0, 0, 0, 0, 0, 0, 11...</td>\n",
       "      <td>[726]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13306</td>\n",
       "      <td>[2361, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8372</td>\n",
       "      <td>[2597, 3691, 1149, 5796, 581, 0, 2590, 4847, 1...</td>\n",
       "      <td>[1141]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13798</td>\n",
       "      <td>[0, 0, 247, 18025, 1499, 0, 359, 1148, 356, 57...</td>\n",
       "      <td>[13667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348</td>\n",
       "      <td>[16519, 2550, 15150, 760, 26216, 22268, 5115, ...</td>\n",
       "      <td>[17254]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>8315</td>\n",
       "      <td>[1219, 16345, 1055, 8044, 14236, 11873, 3121, ...</td>\n",
       "      <td>[11018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>4504</td>\n",
       "      <td>[3111, 1050, 0, 10479, 12160, 1789, 0, 471, 0,...</td>\n",
       "      <td>[1351]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>2582</td>\n",
       "      <td>[191, 12191, 10510, 822, 708, 16409, 10262, 18...</td>\n",
       "      <td>[13540]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>4847</td>\n",
       "      <td>[708, 1161, 4569, 13358, 11852, 2780, 0, 11573...</td>\n",
       "      <td>[14757]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>5150</td>\n",
       "      <td>[2951, 0, 2583, 108, 296, 8087, 4921, 1794, 11...</td>\n",
       "      <td>[581]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1664 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                           pred_seq true_seq\n",
       "0     10278  [2437, 1165, 7804, 12191, 0, 0, 0, 0, 0, 0, 11...    [726]\n",
       "1     13306  [2361, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...    [181]\n",
       "2      8372  [2597, 3691, 1149, 5796, 581, 0, 2590, 4847, 1...   [1141]\n",
       "3     13798  [0, 0, 247, 18025, 1499, 0, 359, 1148, 356, 57...  [13667]\n",
       "4       348  [16519, 2550, 15150, 760, 26216, 22268, 5115, ...  [17254]\n",
       "...     ...                                                ...      ...\n",
       "1659   8315  [1219, 16345, 1055, 8044, 14236, 11873, 3121, ...  [11018]\n",
       "1660   4504  [3111, 1050, 0, 10479, 12160, 1789, 0, 471, 0,...   [1351]\n",
       "1661   2582  [191, 12191, 10510, 822, 708, 16409, 10262, 18...  [13540]\n",
       "1662   4847  [708, 1161, 4569, 13358, 11852, 2780, 0, 11573...  [14757]\n",
       "1663   5150  [2951, 0, 2583, 108, 296, 8087, 4921, 1794, 11...    [581]\n",
       "\n",
       "[1664 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_pickle('CFRNN_res_200_ML_01_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in predictions_df.iterrows():\n",
    "    if len(row['true_seq']) > 1:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNn4Lq9sc-WY"
   },
   "outputs": [],
   "source": [
    "# result_path = 'Results/CFRNN/'\n",
    "# predictions = pd.read_pickle(path + result_path + 'CFRNN_res_200_ML_01_users')\n",
    "predictions = predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ranked_df, steps, max_rank):\n",
    "    s = time.time()\n",
    "    ranks_at = [1] + [i for i in range(steps, max_rank + steps, steps)]\n",
    "    hitcounts = []\n",
    "    recs_at = []\n",
    "    precs_at = []\n",
    "    metrics = pd.DataFrame(columns=['rank_at', 'hitcounts', 'recall', 'precision'])\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for i, row in ranked_df.iterrows():\n",
    "            hitcount +=  len(set(row['true_id']) & set(row['pred_items_ranked'][:rank]))\n",
    "\n",
    "        prec_at = hitcount / rank / len(ranked_df)\n",
    "        rec_at = hitcount / len(ranked_df.iloc[0]['true_id']) / len(ranked_df)\n",
    "\n",
    "        hitcounts.append(hitcount)                     \n",
    "        recs_at.append(rec_at)\n",
    "        precs_at.append(prec_at)\n",
    "\n",
    "    metrics['rank_at'] = ranks_at\n",
    "    metrics['hitcounts'] = hitcounts\n",
    "    metrics['recall'] = recs_at\n",
    "    metrics['precision'] = precs_at\n",
    "    print('Obtaining metrics time:', round(time.time() - s,2))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "renames = {'pred_seq':'pred_items_ranked', 'true_seq':'true_id'}\n",
    "predictions = predictions.rename(renames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBun0RHBc-Wc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.15\n"
     ]
    }
   ],
   "source": [
    "metrics_val_set = get_metrics(predictions, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         10  0.006010   0.000601\n",
       "3       15         12  0.007212   0.000481\n",
       "4       20         13  0.007812   0.000391"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          2  0.001202   0.001202\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         14  0.008413   0.000841\n",
       "3       15         15  0.009014   0.000601\n",
       "4       20         17  0.010216   0.000511"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          2  0.001202   0.001202\n",
       "1        5          3  0.001803   0.000361\n",
       "2       10          3  0.001803   0.000180\n",
       "3       15          3  0.001803   0.000120\n",
       "4       20          3  0.001803   0.000090"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_temp_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.00009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          0  0.000000    0.00000\n",
       "1        5          1  0.000601    0.00012\n",
       "2       10          2  0.001202    0.00012\n",
       "3       15          2  0.001202    0.00008\n",
       "4       20          3  0.001803    0.00009"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_temp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_01_users'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_pickle(path + 'Results/CFRNN/' + 'metrics_CFRNN_' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
