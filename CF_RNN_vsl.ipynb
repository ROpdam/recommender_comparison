{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKmM1TG-c-TS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1586364379603,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "eWJsd_7Pc-TZ",
    "outputId": "38fa93e1-7d3a-4b3e-9cc5-ff2f5debea21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 2.0.0 \t\tgpu available: True\n"
     ]
    }
   ],
   "source": [
    "print('version:', tf.__version__, '\\t\\tgpu available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCYwnVWQc-Te"
   },
   "source": [
    "# Read Data\n",
    "- all datasets are datetime sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zDM1sWVc-Tf"
   },
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "data_path = '../datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8KT8aimc-Tj"
   },
   "source": [
    "## Amazon Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l62L3lv-c-Tj"
   },
   "outputs": [],
   "source": [
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLo0gKuEc-Tn"
   },
   "source": [
    "## MovieLens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbxNjxJFc-To"
   },
   "outputs": [],
   "source": [
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1586364387222,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "O8lLdQE-c-Ts",
    "outputId": "03b7ad73-f0bb-41c5-f083-7571ba3c53d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>datetime</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18590190</th>\n",
       "      <td>120461</td>\n",
       "      <td>2501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>2410</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590032</th>\n",
       "      <td>120461</td>\n",
       "      <td>252</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>249</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590159</th>\n",
       "      <td>120461</td>\n",
       "      <td>2069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1980</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590048</th>\n",
       "      <td>120461</td>\n",
       "      <td>440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>435</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590145</th>\n",
       "      <td>120461</td>\n",
       "      <td>1959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1870</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  item  rating            datetime item_id user_id\n",
       "18590190  120461  2501     5.0 2000-04-25 02:29:35    2410  120460\n",
       "18590032  120461   252     4.0 2000-04-25 02:29:35     249  120460\n",
       "18590159  120461  2069     4.0 2000-04-25 02:29:35    1980  120460\n",
       "18590048  120461   440     4.0 2000-04-25 02:29:35     435  120460\n",
       "18590145  120461  1959     4.0 2000-04-25 02:29:35    1870  120460"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 27387\n",
      "Total users: 16254\n",
      "Number of train users: 16192\n",
      "Number of test users: 1664\n",
      "Number of validation users: 1664 \n",
      "\n",
      "Users deleted: 62\n"
     ]
    }
   ],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "\n",
    "# Train Test Val Split\n",
    "total_users, total_items, train_set, val_set, test_set = \\\n",
    "train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Variable Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 30\n",
    "min_seq_len = 10\n",
    "shift_targets_by = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences x: 16192 \n",
      "Avg sequence length x: 150.41637845849803 \n",
      "Std_dev sequence length x: 242.74 \n",
      "Median of sequence length x: 71.0\n"
     ]
    }
   ],
   "source": [
    "from Data_prep import get_x_y_sequences, min_padding\n",
    "vsl = True # Set for training later\n",
    "\n",
    "# Train Set\n",
    "user_sequences_x, user_sequences_y, user_order = get_x_y_sequences(train_set, shift_targets_by)\n",
    "padded_sequences_x = min_padding(user_sequences_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "padded_sequences_y = min_padding(user_sequences_y, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "\n",
    "# Val Set \n",
    "user_sequences_val_x, user_sequences_val_y, user_order = get_x_y_sequences(val_set, shift_targets_by, stats=False)\n",
    "padded_sequences_val_x = min_padding(user_sequences_val_x, BATCH_SIZE, min_seq_len, max_seq_len)\n",
    "padded_sequences_val_y = min_padding(user_sequences_val_y, BATCH_SIZE, min_seq_len, max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Fixed Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = 71 #median\n",
    "# max_seq_len = 142 #2xmedian\n",
    "max_seq_len = 213 #3xmedian\n",
    "max_seq_len = 30\n",
    "shift_targets_by = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences x: 16192 \n",
      "Avg sequence length x: 150.41637845849803 \n",
      "Std_dev sequence length x: 242.74 \n",
      "Median of sequence length x: 71.0\n",
      "number of sequences: 16192 \n",
      "avg sequence length: 30.0 \n",
      "std_dev sequence length: 0.0\n"
     ]
    }
   ],
   "source": [
    "from Data_prep import get_x_y_sequences, standard_padding\n",
    "vsl = False\n",
    "\n",
    "#Train Set\n",
    "user_sequences_x, user_sequences_y, median = get_x_y_sequences(train_set, shift_targets_by, ordered=False)\n",
    "sequences_data_x = standard_padding(user_sequences_x, max_seq_len)\n",
    "sequences_data_y = standard_padding(user_sequences_y, max_seq_len, stats=False)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((sequences_data_x, sequences_data_y))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "#Val Set\n",
    "user_sequences_val_x, user_sequences_val_y, median = get_x_y_sequences(val_set, shift_targets_by, ordered=False, stats=False)\n",
    "sequences_data_val_x = standard_padding(user_sequences_val_x, max_seq_len, stats=False)\n",
    "sequences_data_val_y = standard_padding(user_sequences_val_y, max_seq_len, stats=False)\n",
    "\n",
    "val_dataset = tf.data.Dataset.zip((sequences_data_val_x, sequences_data_val_y))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWbRJiusc-U4"
   },
   "source": [
    "---\n",
    "# LSTM Model\n",
    "Collaborative Filtering with Recurrent Neural Networks\n",
    "- paper: https://arxiv.org/pdf/1608.07400.pdf\n",
    "- code: https://github.com/rdevooght/sequence-based-recommendations (in Theano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huW9kTD0c-U6"
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjqXT55ic-U8"
   },
   "outputs": [],
   "source": [
    "def build_model(total_items, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(total_items, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        \n",
    "        tf.keras.layers.LSTM(units=rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=False, #Reset cell states with each batch\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(total_items)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uHkY9zyc-VA"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HqmM7Gzc-VA"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "rnn_units = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzpsaebwc-VC"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "total_items = total_items,\n",
    "embedding_dim = embedding_dim,\n",
    "rnn_units = rnn_units,\n",
    "batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCRSnplpc-VF"
   },
   "source": [
    "## Add Loss\n",
    "- **Added one hot encoding of the labels to match logits output after dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    K = tf.keras.backend\n",
    "    y_true = K.one_hot(tf.dtypes.cast(y_true, tf.int32), total_items)\n",
    "    y_true = K.ones_like(y_true) \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    recall = true_positives / (all_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE_UKWEgc-VF"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    oh_labels = tf.keras.backend.one_hot(tf.dtypes.cast(labels, tf.int32), total_items)\n",
    "    return tf.keras.losses.categorical_crossentropy(oh_labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad at 0x7fb8e448d5c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEVgdcLEc-VY"
   },
   "source": [
    "## Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1586364427504,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "9d9vAqj9c-VZ",
    "outputId": "36f6f17f-64da-4387-9929-d6dc450b55bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 100)           2738700   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 20)            9680      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 27387)         575127    \n",
      "=================================================================\n",
      "Total params: 3,323,507\n",
      "Trainable params: 3,323,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9mzqTsiqc-Vc"
   },
   "source": [
    "---\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "### Configure Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWyjHT3dc-Vf"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "if vsl:\n",
    "    checkpoint_dir = '../ckpts/ckpts_vsl' + file_name + '_lr' + str(learning_rate)\n",
    "else:\n",
    "    checkpoint_dir = '../ckpts/ckpts_fixed_' + str(max_seq_len) + file_name + '_lr' + str(learning_rate)\n",
    "    \n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgpHHzp8c-Vi"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1586364435411,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "dx6G0y_Ic-Vi",
    "outputId": "045b9ca5-85e9-4a74-ac70-e002ea409212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Batches: 253.0\n",
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "print('#Batches:', len(user_sequences_x)/BATCH_SIZE)\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93383,
     "status": "error",
     "timestamp": 1586364530380,
     "user": {
      "displayName": "Robin Opdam",
      "photoUrl": "",
      "userId": "15967290835659268034"
     },
     "user_tz": -120
    },
    "id": "R0k6UFJRc-Vp",
    "outputId": "0413c5d8-6977-476c-f7c9-a06e9e63a47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LSTM with Fixed sequence length: 30\n",
      "Epoch 1/150\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 9.9502 - recall: 6.8501e-04 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 9.2718 - recall: 0.0153 - val_loss: 3.1295 - val_recall: 0.0271\n",
      "Epoch 3/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 8.7411 - recall: 0.0354 - val_loss: 3.1391 - val_recall: 0.0436\n",
      "Epoch 4/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 8.4752 - recall: 0.0496 - val_loss: 3.1283 - val_recall: 0.0560\n",
      "Epoch 5/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.3241 - recall: 0.0595 - val_loss: 3.1188 - val_recall: 0.0642\n",
      "Epoch 6/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.2260 - recall: 0.0677 - val_loss: 3.1113 - val_recall: 0.0720\n",
      "Epoch 7/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.1571 - recall: 0.0748 - val_loss: 3.1054 - val_recall: 0.0784\n",
      "Epoch 8/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.1058 - recall: 0.0810 - val_loss: 3.1007 - val_recall: 0.0843\n",
      "Epoch 9/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 8.0663 - recall: 0.0861 - val_loss: 3.0969 - val_recall: 0.0892\n",
      "Epoch 10/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.0347 - recall: 0.0914 - val_loss: 3.0937 - val_recall: 0.0942\n",
      "Epoch 11/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 8.0090 - recall: 0.0961 - val_loss: 3.0910 - val_recall: 0.0985\n",
      "Epoch 12/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.9876 - recall: 0.0999 - val_loss: 3.0886 - val_recall: 0.1022\n",
      "Epoch 13/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.9695 - recall: 0.1036 - val_loss: 3.0866 - val_recall: 0.1058\n",
      "Epoch 14/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.9540 - recall: 0.1070 - val_loss: 3.0848 - val_recall: 0.1092\n",
      "Epoch 15/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.9405 - recall: 0.1102 - val_loss: 3.0832 - val_recall: 0.1122\n",
      "Epoch 16/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.9287 - recall: 0.1135 - val_loss: 3.0818 - val_recall: 0.1155\n",
      "Epoch 17/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.9182 - recall: 0.1166 - val_loss: 3.0805 - val_recall: 0.1185\n",
      "Epoch 18/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.9089 - recall: 0.1195 - val_loss: 3.0794 - val_recall: 0.1212\n",
      "Epoch 19/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.9005 - recall: 0.1220 - val_loss: 3.0784 - val_recall: 0.1236\n",
      "Epoch 20/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8930 - recall: 0.1245 - val_loss: 3.0775 - val_recall: 0.1262\n",
      "Epoch 21/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8861 - recall: 0.1270 - val_loss: 3.0766 - val_recall: 0.1287\n",
      "Epoch 22/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8798 - recall: 0.1295 - val_loss: 3.0759 - val_recall: 0.1309\n",
      "Epoch 23/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8741 - recall: 0.1318 - val_loss: 3.0752 - val_recall: 0.1331\n",
      "Epoch 24/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8688 - recall: 0.1339 - val_loss: 3.0746 - val_recall: 0.1355\n",
      "Epoch 25/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8639 - recall: 0.1361 - val_loss: 3.0740 - val_recall: 0.1376\n",
      "Epoch 26/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8594 - recall: 0.1382 - val_loss: 3.0735 - val_recall: 0.1394\n",
      "Epoch 27/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8552 - recall: 0.1400 - val_loss: 3.0731 - val_recall: 0.1409\n",
      "Epoch 28/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8513 - recall: 0.1414 - val_loss: 3.0726 - val_recall: 0.1423\n",
      "Epoch 29/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8477 - recall: 0.1431 - val_loss: 3.0722 - val_recall: 0.1444\n",
      "Epoch 30/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8443 - recall: 0.1451 - val_loss: 3.0719 - val_recall: 0.1464\n",
      "Epoch 31/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8411 - recall: 0.1469 - val_loss: 3.0716 - val_recall: 0.1479\n",
      "Epoch 32/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8381 - recall: 0.1481 - val_loss: 3.0713 - val_recall: 0.1494\n",
      "Epoch 33/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8353 - recall: 0.1501 - val_loss: 3.0710 - val_recall: 0.1517\n",
      "Epoch 34/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8326 - recall: 0.1522 - val_loss: 3.0708 - val_recall: 0.1531\n",
      "Epoch 35/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8301 - recall: 0.1534 - val_loss: 3.0705 - val_recall: 0.1542\n",
      "Epoch 36/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8277 - recall: 0.1546 - val_loss: 3.0703 - val_recall: 0.1553\n",
      "Epoch 37/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8255 - recall: 0.1563 - val_loss: 3.0701 - val_recall: 0.1575\n",
      "Epoch 38/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8233 - recall: 0.1582 - val_loss: 3.0700 - val_recall: 0.1593\n",
      "Epoch 39/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8213 - recall: 0.1595 - val_loss: 3.0698 - val_recall: 0.1600\n",
      "Epoch 40/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8194 - recall: 0.1602 - val_loss: 3.0697 - val_recall: 0.1606\n",
      "Epoch 41/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8175 - recall: 0.1610 - val_loss: 3.0695 - val_recall: 0.1617\n",
      "Epoch 42/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8158 - recall: 0.1623 - val_loss: 3.0694 - val_recall: 0.1635\n",
      "Epoch 43/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8141 - recall: 0.1642 - val_loss: 3.0693 - val_recall: 0.1655\n",
      "Epoch 44/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8125 - recall: 0.1662 - val_loss: 3.0692 - val_recall: 0.1672\n",
      "Epoch 45/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8110 - recall: 0.1675 - val_loss: 3.0691 - val_recall: 0.1682\n",
      "Epoch 46/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8095 - recall: 0.1683 - val_loss: 3.0690 - val_recall: 0.1689\n",
      "Epoch 47/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8081 - recall: 0.1690 - val_loss: 3.0689 - val_recall: 0.1694\n",
      "Epoch 48/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8067 - recall: 0.1695 - val_loss: 3.0688 - val_recall: 0.1700\n",
      "Epoch 49/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8054 - recall: 0.1704 - val_loss: 3.0688 - val_recall: 0.1713\n",
      "Epoch 50/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8042 - recall: 0.1721 - val_loss: 3.0687 - val_recall: 0.1734\n",
      "Epoch 51/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8030 - recall: 0.1745 - val_loss: 3.0686 - val_recall: 0.1756\n",
      "Epoch 52/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.8019 - recall: 0.1759 - val_loss: 3.0686 - val_recall: 0.1765\n",
      "Epoch 53/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.8007 - recall: 0.1766 - val_loss: 3.0685 - val_recall: 0.1771\n",
      "Epoch 54/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7997 - recall: 0.1771 - val_loss: 3.0684 - val_recall: 0.1776\n",
      "Epoch 55/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7986 - recall: 0.1777 - val_loss: 3.0684 - val_recall: 0.1781\n",
      "Epoch 56/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7977 - recall: 0.1782 - val_loss: 3.0683 - val_recall: 0.1785\n",
      "Epoch 57/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7967 - recall: 0.1785 - val_loss: 3.0682 - val_recall: 0.1787\n",
      "Epoch 58/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.7958 - recall: 0.1789 - val_loss: 3.0681 - val_recall: 0.1797\n",
      "Epoch 59/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7949 - recall: 0.1802 - val_loss: 3.0680 - val_recall: 0.1814\n",
      "Epoch 60/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7940 - recall: 0.1822 - val_loss: 3.0679 - val_recall: 0.1839\n",
      "Epoch 61/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7932 - recall: 0.1846 - val_loss: 3.0678 - val_recall: 0.1856\n",
      "Epoch 62/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.7923 - recall: 0.1857 - val_loss: 3.0676 - val_recall: 0.1862\n",
      "Epoch 63/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7915 - recall: 0.1862 - val_loss: 3.0674 - val_recall: 0.1865\n",
      "Epoch 64/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7908 - recall: 0.1865 - val_loss: 3.0672 - val_recall: 0.1868\n",
      "Epoch 65/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7900 - recall: 0.1869 - val_loss: 3.0669 - val_recall: 0.1873\n",
      "Epoch 66/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7893 - recall: 0.1874 - val_loss: 3.0665 - val_recall: 0.1878\n",
      "Epoch 67/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7886 - recall: 0.1878 - val_loss: 3.0660 - val_recall: 0.1882\n",
      "Epoch 68/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7879 - recall: 0.1881 - val_loss: 3.0652 - val_recall: 0.1884\n",
      "Epoch 69/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7872 - recall: 0.1881 - val_loss: 3.0639 - val_recall: 0.1884\n",
      "Epoch 70/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7865 - recall: 0.1882 - val_loss: 3.0613 - val_recall: 0.1885\n",
      "Epoch 71/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7857 - recall: 0.1884 - val_loss: 3.0538 - val_recall: 0.1889\n",
      "Epoch 72/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7836 - recall: 0.1890 - val_loss: 2.9505 - val_recall: 0.1900\n",
      "Epoch 73/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.7667 - recall: 0.1888 - val_loss: 2.3798 - val_recall: 0.1917\n",
      "Epoch 74/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7436 - recall: 0.1892 - val_loss: 1.9233 - val_recall: 0.1940\n",
      "Epoch 75/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7229 - recall: 0.1900 - val_loss: 1.5739 - val_recall: 0.1960\n",
      "Epoch 76/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.7064 - recall: 0.1914 - val_loss: 1.3128 - val_recall: 0.1972\n",
      "Epoch 77/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6932 - recall: 0.1932 - val_loss: 1.1164 - val_recall: 0.1980\n",
      "Epoch 78/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6827 - recall: 0.1949 - val_loss: 0.9666 - val_recall: 0.1982\n",
      "Epoch 79/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6743 - recall: 0.1963 - val_loss: 0.8505 - val_recall: 0.1985\n",
      "Epoch 80/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6675 - recall: 0.1974 - val_loss: 0.7588 - val_recall: 0.1986\n",
      "Epoch 81/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6618 - recall: 0.1979 - val_loss: 0.6853 - val_recall: 0.1990\n",
      "Epoch 82/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6571 - recall: 0.1982 - val_loss: 0.6252 - val_recall: 0.1992\n",
      "Epoch 83/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6532 - recall: 0.1984 - val_loss: 0.5755 - val_recall: 0.1997\n",
      "Epoch 84/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6498 - recall: 0.1986 - val_loss: 0.5337 - val_recall: 0.2000\n",
      "Epoch 85/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6468 - recall: 0.1989 - val_loss: 0.4981 - val_recall: 0.2002\n",
      "Epoch 86/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6442 - recall: 0.1993 - val_loss: 0.4676 - val_recall: 0.2003\n",
      "Epoch 87/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6419 - recall: 0.1998 - val_loss: 0.4410 - val_recall: 0.2003\n",
      "Epoch 88/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6399 - recall: 0.2000 - val_loss: 0.4177 - val_recall: 0.2003\n",
      "Epoch 89/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6380 - recall: 0.2001 - val_loss: 0.3971 - val_recall: 0.2003\n",
      "Epoch 90/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6363 - recall: 0.2002 - val_loss: 0.3788 - val_recall: 0.2003\n",
      "Epoch 91/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6348 - recall: 0.2003 - val_loss: 0.3623 - val_recall: 0.2004\n",
      "Epoch 92/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6334 - recall: 0.2003 - val_loss: 0.3475 - val_recall: 0.2004\n",
      "Epoch 93/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6320 - recall: 0.2003 - val_loss: 0.3341 - val_recall: 0.2005\n",
      "Epoch 94/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6308 - recall: 0.2004 - val_loss: 0.3220 - val_recall: 0.2006\n",
      "Epoch 95/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6296 - recall: 0.2005 - val_loss: 0.3109 - val_recall: 0.2015\n",
      "Epoch 96/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6286 - recall: 0.2006 - val_loss: 0.3008 - val_recall: 0.2033\n",
      "Epoch 97/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6275 - recall: 0.2011 - val_loss: 0.2916 - val_recall: 0.2060\n",
      "Epoch 98/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6266 - recall: 0.2021 - val_loss: 0.2831 - val_recall: 0.2090\n",
      "Epoch 99/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6257 - recall: 0.2042 - val_loss: 0.2754 - val_recall: 0.2109\n",
      "Epoch 100/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6248 - recall: 0.2070 - val_loss: 0.2684 - val_recall: 0.2121\n",
      "Epoch 101/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6240 - recall: 0.2094 - val_loss: 0.2620 - val_recall: 0.2129\n",
      "Epoch 102/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6232 - recall: 0.2111 - val_loss: 0.2561 - val_recall: 0.2131\n",
      "Epoch 103/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6225 - recall: 0.2120 - val_loss: 0.2508 - val_recall: 0.2133\n",
      "Epoch 104/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6218 - recall: 0.2125 - val_loss: 0.2461 - val_recall: 0.2133\n",
      "Epoch 105/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6211 - recall: 0.2128 - val_loss: 0.2418 - val_recall: 0.2133\n",
      "Epoch 106/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6205 - recall: 0.2130 - val_loss: 0.2380 - val_recall: 0.2135\n",
      "Epoch 107/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6199 - recall: 0.2131 - val_loss: 0.2347 - val_recall: 0.2137\n",
      "Epoch 108/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6193 - recall: 0.2133 - val_loss: 0.2318 - val_recall: 0.2141\n",
      "Epoch 109/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6187 - recall: 0.2135 - val_loss: 0.2294 - val_recall: 0.2145\n",
      "Epoch 110/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6181 - recall: 0.2138 - val_loss: 0.2276 - val_recall: 0.2151\n",
      "Epoch 111/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6176 - recall: 0.2141 - val_loss: 0.2262 - val_recall: 0.2153\n",
      "Epoch 112/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6171 - recall: 0.2146 - val_loss: 0.2254 - val_recall: 0.2155\n",
      "Epoch 113/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6165 - recall: 0.2149 - val_loss: 0.2252 - val_recall: 0.2156\n",
      "Epoch 114/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6160 - recall: 0.2153 - val_loss: 0.2255 - val_recall: 0.2156\n",
      "Epoch 115/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6155 - recall: 0.2154 - val_loss: 0.2263 - val_recall: 0.2156\n",
      "Epoch 116/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6150 - recall: 0.2155 - val_loss: 0.2279 - val_recall: 0.2156\n",
      "Epoch 117/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6145 - recall: 0.2156 - val_loss: 0.2303 - val_recall: 0.2156\n",
      "Epoch 118/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6140 - recall: 0.2156 - val_loss: 0.2340 - val_recall: 0.2156\n",
      "Epoch 119/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6135 - recall: 0.2156 - val_loss: 0.2386 - val_recall: 0.2156\n",
      "Epoch 120/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6129 - recall: 0.2156 - val_loss: 0.2437 - val_recall: 0.2156\n",
      "Epoch 121/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6124 - recall: 0.2156 - val_loss: 0.2488 - val_recall: 0.2156\n",
      "Epoch 122/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6119 - recall: 0.2156 - val_loss: 0.2544 - val_recall: 0.2157\n",
      "Epoch 123/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6114 - recall: 0.2156 - val_loss: 0.2609 - val_recall: 0.2157\n",
      "Epoch 124/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6108 - recall: 0.2157 - val_loss: 0.2687 - val_recall: 0.2159\n",
      "Epoch 125/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6102 - recall: 0.2157 - val_loss: 0.2782 - val_recall: 0.2160\n",
      "Epoch 126/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6096 - recall: 0.2157 - val_loss: 0.2902 - val_recall: 0.2161\n",
      "Epoch 127/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6089 - recall: 0.2157 - val_loss: 0.3060 - val_recall: 0.2161\n",
      "Epoch 128/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6082 - recall: 0.2157 - val_loss: 0.3275 - val_recall: 0.2161\n",
      "Epoch 129/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6075 - recall: 0.2157 - val_loss: 0.3568 - val_recall: 0.2163\n",
      "Epoch 130/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6068 - recall: 0.2157 - val_loss: 0.3976 - val_recall: 0.2166\n",
      "Epoch 131/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6060 - recall: 0.2158 - val_loss: 0.4551 - val_recall: 0.2177\n",
      "Epoch 132/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6051 - recall: 0.2159 - val_loss: 0.5376 - val_recall: 0.2189\n",
      "Epoch 133/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6042 - recall: 0.2161 - val_loss: 0.6567 - val_recall: 0.2214\n",
      "Epoch 134/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6033 - recall: 0.2165 - val_loss: 0.8240 - val_recall: 0.2236\n",
      "Epoch 135/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6023 - recall: 0.2171 - val_loss: 1.0440 - val_recall: 0.2258\n",
      "Epoch 136/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.6013 - recall: 0.2182 - val_loss: 1.3004 - val_recall: 0.2276\n",
      "Epoch 137/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.6001 - recall: 0.2199 - val_loss: 1.5535 - val_recall: 0.2290\n",
      "Epoch 138/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.5989 - recall: 0.2220 - val_loss: 1.7580 - val_recall: 0.2300\n",
      "Epoch 139/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.5976 - recall: 0.2244 - val_loss: 1.8865 - val_recall: 0.2305\n",
      "Epoch 140/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5961 - recall: 0.2265 - val_loss: 1.9363 - val_recall: 0.2308\n",
      "Epoch 141/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5945 - recall: 0.2283 - val_loss: 1.9195 - val_recall: 0.2311\n",
      "Epoch 142/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5926 - recall: 0.2294 - val_loss: 1.8537 - val_recall: 0.2312\n",
      "Epoch 143/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5905 - recall: 0.2301 - val_loss: 1.7560 - val_recall: 0.2312\n",
      "Epoch 144/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5881 - recall: 0.2305 - val_loss: 1.6421 - val_recall: 0.2312\n",
      "Epoch 145/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5854 - recall: 0.2308 - val_loss: 1.5239 - val_recall: 0.2312\n",
      "Epoch 146/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5825 - recall: 0.2310 - val_loss: 1.4076 - val_recall: 0.2312\n",
      "Epoch 147/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5794 - recall: 0.2311 - val_loss: 1.2955 - val_recall: 0.2312\n",
      "Epoch 148/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5762 - recall: 0.2312 - val_loss: 1.1884 - val_recall: 0.2312\n",
      "Epoch 149/150\n",
      "253/253 [==============================] - 13s 52ms/step - loss: 7.5728 - recall: 0.2312 - val_loss: 1.0880 - val_recall: 0.2312\n",
      "Epoch 150/150\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 7.5694 - recall: 0.2312 - val_loss: 0.9956 - val_recall: 0.2313\n"
     ]
    }
   ],
   "source": [
    "if vsl:\n",
    "    print('Fitting LSTM with Variable sequence length')\n",
    "    from Helpers import Batch_Generator\n",
    "    history = model.fit_generator(generator=Batch_Generator(\n",
    "                                  X=padded_sequences_x, \n",
    "                                  y=padded_sequences_y, \n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True),\n",
    "\n",
    "    #                               validation_data=Batch_Generator(\n",
    "    #                               X=padded_sequences_val_x,\n",
    "    #                               y=padded_sequences_val_y,\n",
    "    #                               batch_size=BATCH_SIZE,\n",
    "    #                               shuffle=True),\n",
    "\n",
    "                                  epochs=epochs, \n",
    "                                  callbacks=[checkpoint_callback],\n",
    "                                  use_multiprocessing=True)\n",
    "else:\n",
    "    print('Fitting LSTM with Fixed sequence length:', str(max_seq_len))\n",
    "    history = model.fit(dataset, \n",
    "                        validation_data=val_dataset, \n",
    "                        epochs=epochs, \n",
    "                        callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_01_users'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(history.history)\n",
    "if vsl:\n",
    "    results.to_pickle('../results/his_vsl_01_ml_users_100_epochs' + '_lr' + str(learning_rate))\n",
    "else:\n",
    "    results.to_pickle('../results/his_fixed_' + str(max_seq_len) + '_01_ml_users_100_epochs' + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(pd.read_pickle('../results/his_fixed_' + str(max_seq_len) + '_01_ml_users_100_epochs' + '_lr' + str(learning_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res['loss'])\n",
    "plt.plot(res['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res['recall'])\n",
    "plt.plot(res['val_recall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG6qSlkuc-Vs"
   },
   "source": [
    "---\n",
    "## Continue training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMQBMjJfc-Vt"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EplgEE4Zc-Vz"
   },
   "outputs": [],
   "source": [
    "# tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# model = build_model(total_items, embedding_dim, rnn_units, batch_size=BATCH_SIZE)\n",
    "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=[recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kisl-tXEc-V3"
   },
   "outputs": [],
   "source": [
    "# aditional_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wte4RyUsc-V7"
   },
   "outputs": [],
   "source": [
    "# model.fit(dataset, validation_data=val_dataset, epochs=aditional_epochs, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ltj7HkPxc-V-"
   },
   "source": [
    "---\n",
    "# Predict Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Spy42iNc-V_"
   },
   "source": [
    "## Restore Latest Checkpoints\n",
    "- **TODO: Can keep batches of 64 for evaluation => faster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY0mtM26c-V_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../ckpts/ckpts_fixed_30ML_01_users_lr0.1/ckpt'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, train_set, test_set, rank_at, temp=1):\n",
    "    \"\"\"\n",
    "    Uses a Keras model with batch size set to 1 to predict the rest of the sequences from the train_set per user\n",
    "    finally puts user, a list pred_items_ranked and a list containing true_ids from the test set\n",
    "    :param model: Keras RNN model with batch size set to 1\n",
    "    :param train_set: pandas df containing user_id, item_id sorted on datetime per user\n",
    "    :param test_set: pandas df containing: user_id, last item_id(s) per user\n",
    "    :param rank_at: maximum of top ranked items per user\n",
    "    :param temp: temperature, 1 means no deviation from model prediction\n",
    "    :return: pandas df where each row represents a user, the columns represent: pred_items_ranked at rank_at,\n",
    "             true_id extracted from test_set\n",
    "    \"\"\"\n",
    "    predictions_df = pd.DataFrame(columns=['user', 'pred_items_ranked', 'true_id'])\n",
    "    for u in test_set.user_id.unique():\n",
    "        test_user_seq = np.array(train_set[train_set['user_id'] == u]['item_id'])\n",
    "        true_items = list(test_set[test_set['user_id'] == u]['item_id'])\n",
    "        generated_predictions = []\n",
    "\n",
    "        # Predict\n",
    "        for item in range(rank_at):  # could be any number of recommended items you want to predict\n",
    "            predictions = model(test_user_seq.reshape(-1, 1).T)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "            predictions = predictions / temp\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "            test_user_seq = np.append(test_user_seq, predicted_id).reshape(-1, 1).transpose()\n",
    "\n",
    "            #         half_test_seq = tf.expand_dims([predicted_id], 0)\n",
    "            generated_predictions.append(predicted_id)\n",
    "\n",
    "        predictions_df = predictions_df.append(\n",
    "            {'user': u, 'pred_items_ranked': generated_predictions, 'true_id': true_items}, ignore_index=True)\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 10278\n",
    "test_user_seq = np.array(train_set[train_set['user_id'] == u]['item_id'])\n",
    "true_items = list(test_set[test_set['user_id'] == u]['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_set = train_set[train_set.user_id.isin(test_set.user_id.unique())].groupby('user_id')['item_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[70],\n",
       "        [80],\n",
       "        [90]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, 3, 1))\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_set.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = new_test_set.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[0,250] = 410805 is not in [0, 27387)\n\t [[node embedding_4/embedding_lookup (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\t [[embedding_4/embedding_lookup/_6]]\n  (1) Invalid argument:  indices[0,250] = 410805 is not in [0, 27387)\n\t [[node embedding_4/embedding_lookup (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_7267]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-ed23d4765ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_item_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[0,250] = 410805 is not in [0, 27387)\n\t [[node embedding_4/embedding_lookup (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n\t [[embedding_4/embedding_lookup/_6]]\n  (1) Invalid argument:  indices[0,250] = 410805 is not in [0, 27387)\n\t [[node embedding_4/embedding_lookup (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_7267]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "pred_item_id = model.predict(np.array([sequence,])).argmax()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits should be a matrix, got shape [1,23,27387] [Op:Multinomial]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-03b723158a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_test_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mcategorical\u001b[0;34m(logits, num_samples, dtype, seed, name)\u001b[0m\n\u001b[1;32m    387\u001b[0m   \"\"\"\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultinomial_categorical_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mmultinomial_categorical_impl\u001b[0;34m(logits, num_samples, dtype, seed)\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m   return gen_random_ops.multinomial(\n\u001b[0;32m--> 397\u001b[0;31m       logits, num_samples, seed=seed1, seed2=seed2, output_dtype=dtype)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mmultinomial\u001b[0;34m(logits, num_samples, seed, seed2, output_dtype, name)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits should be a matrix, got shape [1,23,27387] [Op:Multinomial]"
     ]
    }
   ],
   "source": [
    "sequence = new_test_set.iloc[16]\n",
    "tf.random.categorical(model.predict(np.array([sequence,])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[348, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "sequence = new_test_set.iloc[1] \n",
    "for i in range(20):\n",
    "    pred_item_id = model.predict(np.array([sequence,])).argmax()\n",
    "    predictions.append(pred_item_id)\n",
    "    sequence.append(pred_item_id)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(new_test_set.iloc[3], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "796"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27387"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.5579305 ,  4.195658  ,  3.8592424 , ..., -0.4317268 ,\n",
       "         -0.43991497, -0.42959884]],\n",
       "\n",
       "       [[ 6.646965  ,  4.200689  ,  3.8638463 , ..., -0.43216455,\n",
       "         -0.44044372, -0.43007022]],\n",
       "\n",
       "       [[ 6.865742  ,  4.2183046 ,  3.8801608 , ..., -0.43373075,\n",
       "         -0.44208387, -0.43189982]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.409998  ,  4.181034  ,  3.8457491 , ..., -0.4303646 ,\n",
       "         -0.4385426 , -0.42813313]],\n",
       "\n",
       "       [[ 8.562332  ,  4.3772454 ,  4.027392  , ..., -0.44853246,\n",
       "         -0.45810473, -0.44862837]],\n",
       "\n",
       "       [[ 8.53319   ,  4.3581448 ,  4.009252  , ..., -0.44650066,\n",
       "         -0.45612025, -0.44668055]]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(test_user_seq.reshape(-1, 1).T)\n",
    "preds = tf.squeeze(preds, 0 )\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-Ths7-hc-WE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'accumulator' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(total_items, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQfRtD71c-WH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 100)            2738700   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (1, None, 20)             9680      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, None, 27387)          575127    \n",
      "=================================================================\n",
      "Total params: 3,323,507\n",
      "Trainable params: 3,323,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQNPBkyQc-WI"
   },
   "source": [
    "## Create Predictions\n",
    "- **TODO: Can keep batches of 64 for evaluation => faster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3A-hRV-c-WJ"
   },
   "source": [
    "Using train_set sequences to predict test_set / val_set item(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_01_users'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "preds_val = get_predictions(model, train_set, val_set, rank_at)\n",
    "preds_val.to_pickle('../results/preds_val_CFRNN_vsl_100_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "preds_val = get_predictions(model, train_set, val_set, rank_at)\n",
    "preds_val.to_pickle('../results/preds_val_CFRNN_fixed_100_' + str(max_seq_len) + '_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "preds_test = get_predictions(model, train_set, test_set, rank_at)\n",
    "preds_test.to_pickle('../results/preds_test_CFRNN_vsl_100_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "preds_test = get_predictions(model, train_set, test_set, rank_at)\n",
    "preds_test.to_pickle('../results/preds_test_CFRNN_fixed_100_' + str(max_seq_len) + '_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = pd.read_pickle('CFRNN_res_200_ML_01_users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XobdlG9Wc-WY"
   },
   "source": [
    "---\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import get_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          8  0.004808   0.000962\n",
       "2       10         15  0.009014   0.000901\n",
       "3       15         21  0.012620   0.000841\n",
       "4       20         27  0.016226   0.000811"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_val_set_vsl = get_metrics(preds_val, 5, 20)\n",
    "metrics_val_set_vsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val_set_vsl.to_pickle('../results/metrics_val_CFRNN_fixed_' + str(max_seq_len) + '_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_val_set_vsl.to_pickle('../results/metrics_val_CFRNN_vsl_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining metrics time: 1.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          1  0.000601   0.000601\n",
       "1        5          4  0.002404   0.000481\n",
       "2       10          8  0.004808   0.000481\n",
       "3       15         12  0.007212   0.000481\n",
       "4       20         19  0.011418   0.000571"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test_set_vsl = get_metrics(preds_test, 5, 20)\n",
    "metrics_test_set_vsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test_set_vsl.to_pickle('../results/metrics_test_CFRNN_fixed_' + str(max_seq_len) + '_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_test_set_vsl.to_pickle('../results/metrics_test_CFRNN_vsl_' + file_name + '_lr' + str(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bfN_yhzc-Wq"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Icth_zsCc-Wr"
   },
   "outputs": [],
   "source": [
    "# oh_input = tf.keras.backend.one_hot(padded, n_items)\n",
    "# e = tf.keras.layers.Embedding(n_items, 100, input_length=max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhXrmLnc-Wu"
   },
   "outputs": [],
   "source": [
    "# One hot encoded input\n",
    "# sequences_data_x = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_x, n_items)) \n",
    "# sequences_data_y = tf.data.Dataset.from_tensor_slices(tf.keras.backend.one_hot(padded_sequences_y, n_items)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2Spy42iNc-V_",
    "XQNPBkyQc-WI"
   ],
   "name": "CF_RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
