{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0 \n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('TF version:', tf.__version__ , '\\nGPU available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../'\n",
    "data_path = 'datasets/' # Paperspace\n",
    "file_name = 'am_like_ml_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A0039616ADOZ0KMWQRNX</td>\n",
       "      <td>B00QFJG1U8</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A0039616ADOZ0KMWQRNX</td>\n",
       "      <td>B010ACF2PK</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>104761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A0039616ADOZ0KMWQRNX</td>\n",
       "      <td>B00BFE0IZ2</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A0039616ADOZ0KMWQRNX</td>\n",
       "      <td>B01CZMQCPC</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>127248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A0039616ADOZ0KMWQRNX</td>\n",
       "      <td>B01B5DLG7G</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  user        item   datetime  rating  item_id\n",
       "0        0  A0039616ADOZ0KMWQRNX  B00QFJG1U8 2016-10-04     5.0    87754\n",
       "1        0  A0039616ADOZ0KMWQRNX  B010ACF2PK 2016-10-04     5.0   104761\n",
       "2        0  A0039616ADOZ0KMWQRNX  B00BFE0IZ2 2016-10-04     5.0    42989\n",
       "3        0  A0039616ADOZ0KMWQRNX  B01CZMQCPC 2016-10-04     5.0   127248\n",
       "4        0  A0039616ADOZ0KMWQRNX  B01B5DLG7G 2016-10-26     4.0   123866"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ext = file_name[:2]\n",
    "total_items = len(df.item_id.unique())\n",
    "first_model_id = str(0) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.read_pickle(path + 'results/' + res_ext + '/all_models')\n",
    "# new_model_id = str(int(all_models.model_id.max()[0]) + 1) + '_' + res_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_time</th>\n",
       "      <th>epochs</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>delta</th>\n",
       "      <th>max_seq_len</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>rnn_units</th>\n",
       "      <th>val_perc</th>\n",
       "      <th>test_perc</th>\n",
       "      <th>n_items_val</th>\n",
       "      <th>n_items_test</th>\n",
       "      <th>pad_value</th>\n",
       "      <th>shift_targets_by</th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_am</td>\n",
       "      <td>18013.840090</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.554909733422284, 2.533241045152025, 2.46037...</td>\n",
       "      <td>[2.9381583e-06, 0.00013195378, 0.0002920571, 0...</td>\n",
       "      <td>[4.938571519190722, 4.908481937823909, 4.74607...</td>\n",
       "      <td>[7.3646435e-05, 0.00019554954, 0.00045513033, ...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_am</td>\n",
       "      <td>13535.720657</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.492791804774054, 2.2577781175157705, 2.2073...</td>\n",
       "      <td>[0.000210802, 0.0020089652, 0.005307905, 0.009...</td>\n",
       "      <td>[4.710240729964606, 4.646537842136799, 4.62718...</td>\n",
       "      <td>[0.0008115798, 0.0032872779, 0.007526714, 0.01...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_am</td>\n",
       "      <td>20846.932909</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.8265074285967597, 1.820659847388714, 1.8136...</td>\n",
       "      <td>[0.0, 0.0, 5.561642e-05, 0.00017923162, 0.0003...</td>\n",
       "      <td>[3.542339720726013, 3.5360026788711547, 3.5261...</td>\n",
       "      <td>[0.0, 0.0, 0.00011016104, 0.00022123894, 0.000...</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_am</td>\n",
       "      <td>22982.548593</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.8206264367831753, 1.7478289891933572, 1.602...</td>\n",
       "      <td>[1.6873295e-05, 0.0003124849, 0.0017495692, 0....</td>\n",
       "      <td>[3.5291484594345093, 3.3599658823013305, 3.323...</td>\n",
       "      <td>[9.494675e-05, 0.00086618867, 0.0027825893, 0....</td>\n",
       "      <td>0.005538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7_am</td>\n",
       "      <td>28558.309178</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.48747242005367586, 0.4793317374576048, 0.46...</td>\n",
       "      <td>[0.0, 5.3082982e-05, 0.00014864586, 0.00021017...</td>\n",
       "      <td>[3.3119295375181896, 3.302900663696893, 3.2845...</td>\n",
       "      <td>[0.0, 0.00010310501, 0.00016938652, 0.00022666...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8_am</td>\n",
       "      <td>30543.622423</td>\n",
       "      <td>161</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.47687314659026747, 0.3434375589208797, 0.27...</td>\n",
       "      <td>[7.4939e-05, 0.00035860614, 0.0007600899, 0.00...</td>\n",
       "      <td>[3.27543308239172, 3.2868811257995003, 3.33043...</td>\n",
       "      <td>[0.0001913656, 0.00055657554, 0.0010071265, 0....</td>\n",
       "      <td>0.009231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9_am</td>\n",
       "      <td>28914.833008</td>\n",
       "      <td>172</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.36525425487863167, 0.36047429656105234, 0.3...</td>\n",
       "      <td>[0.0, 1.0721208e-05, 0.000107472086, 0.0001692...</td>\n",
       "      <td>[2.378137436243567, 2.3730297124031745, 2.3672...</td>\n",
       "      <td>[0.0, 8.837572e-05, 0.00016628666, 0.000169386...</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10_am</td>\n",
       "      <td>32447.180922</td>\n",
       "      <td>172</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.35959263617549037, 0.2782717178589458, 0.20...</td>\n",
       "      <td>[5.1701416e-05, 0.00027426844, 0.0005778312, 0...</td>\n",
       "      <td>[2.360568891657461, 2.3202049153866153, 2.3722...</td>\n",
       "      <td>[0.00016938652, 0.000488495, 0.00066382345, 0....</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_am</td>\n",
       "      <td>37728.076944</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.48949657668694485, 0.48542612732337614, 0.4...</td>\n",
       "      <td>[0.0, 0.0, 1.3075499e-05, 9.339205e-05, 0.0001...</td>\n",
       "      <td>[3.317415142059326, 3.3130080938339233, 3.3085...</td>\n",
       "      <td>[0.0, 0.0, 8.7734064e-05, 0.00010310488, 0.000...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3_am</td>\n",
       "      <td>36173.264363</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4853863109251842, 0.46703839228658256, 0.37...</td>\n",
       "      <td>[5.960496e-06, 0.00014358677, 0.00027341425, 0...</td>\n",
       "      <td>[3.3082576990127563, 3.272194962501526, 3.2140...</td>\n",
       "      <td>[8.837564e-05, 0.00020663152, 0.00039936486, 0...</td>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4_am</td>\n",
       "      <td>19245.330291</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3664456828327602, 0.36405172819280857, 0.36...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.4796907e-05, 9.415441e-05, 0...</td>\n",
       "      <td>[2.3816349697113037, 2.3790840530395507, 2.376...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 8.837563e-05, 0.0001027686, 0....</td>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id    train_time epochs BATCH_SIZE  learning_rate  delta max_seq_len  \\\n",
       "0      0_am  18013.840090    200         16            0.1    0.2          18   \n",
       "1      1_am  13535.720657    160         16            0.3    0.2          18   \n",
       "2      5_am  20846.932909    200         32            0.1    0.2          30   \n",
       "3      6_am  22982.548593    200         32            0.3    0.2          30   \n",
       "4      7_am  28558.309178    200         16            0.1    0.6          18   \n",
       "5      8_am  30543.622423    161         16            0.3    0.6          18   \n",
       "6      9_am  28914.833008    172         16            0.1    0.6          30   \n",
       "7     10_am  32447.180922    172         16            0.3    0.6          30   \n",
       "8      2_am  37728.076944    200         32            0.1    0.6          18   \n",
       "9      3_am  36173.264363    200         32            0.3    0.6          18   \n",
       "10     4_am  19245.330291    200         32            0.1    0.6          30   \n",
       "\n",
       "   embedding_dim rnn_units  val_perc  test_perc n_items_val n_items_test  \\\n",
       "0            100        20       0.1        0.1           0            1   \n",
       "1            100        20       0.1        0.1           0            1   \n",
       "2            100        50       0.1        0.1           0            1   \n",
       "3            100        50       0.1        0.1           0            1   \n",
       "4            100        20       0.1        0.1           0            1   \n",
       "5            100        20       0.1        0.1           0            1   \n",
       "6            100        20       0.1        0.1           0            1   \n",
       "7            100        20       0.1        0.1           0            1   \n",
       "8            100        20       0.1        0.1           0            1   \n",
       "9            100        20       0.1        0.1           0            1   \n",
       "10           100        20       0.1        0.1           0            1   \n",
       "\n",
       "   pad_value shift_targets_by  \\\n",
       "0     135784                1   \n",
       "1     135784                1   \n",
       "2     135784                1   \n",
       "3     135784                1   \n",
       "4     135784                1   \n",
       "5     135784                1   \n",
       "6     135784                1   \n",
       "7     135784                1   \n",
       "8     135784                1   \n",
       "9     135784                1   \n",
       "10    135784                1   \n",
       "\n",
       "                                                 loss  \\\n",
       "0   [2.554909733422284, 2.533241045152025, 2.46037...   \n",
       "1   [2.492791804774054, 2.2577781175157705, 2.2073...   \n",
       "2   [1.8265074285967597, 1.820659847388714, 1.8136...   \n",
       "3   [1.8206264367831753, 1.7478289891933572, 1.602...   \n",
       "4   [0.48747242005367586, 0.4793317374576048, 0.46...   \n",
       "5   [0.47687314659026747, 0.3434375589208797, 0.27...   \n",
       "6   [0.36525425487863167, 0.36047429656105234, 0.3...   \n",
       "7   [0.35959263617549037, 0.2782717178589458, 0.20...   \n",
       "8   [0.48949657668694485, 0.48542612732337614, 0.4...   \n",
       "9   [0.4853863109251842, 0.46703839228658256, 0.37...   \n",
       "10  [0.3664456828327602, 0.36405172819280857, 0.36...   \n",
       "\n",
       "                                               recall  \\\n",
       "0   [2.9381583e-06, 0.00013195378, 0.0002920571, 0...   \n",
       "1   [0.000210802, 0.0020089652, 0.005307905, 0.009...   \n",
       "2   [0.0, 0.0, 5.561642e-05, 0.00017923162, 0.0003...   \n",
       "3   [1.6873295e-05, 0.0003124849, 0.0017495692, 0....   \n",
       "4   [0.0, 5.3082982e-05, 0.00014864586, 0.00021017...   \n",
       "5   [7.4939e-05, 0.00035860614, 0.0007600899, 0.00...   \n",
       "6   [0.0, 1.0721208e-05, 0.000107472086, 0.0001692...   \n",
       "7   [5.1701416e-05, 0.00027426844, 0.0005778312, 0...   \n",
       "8   [0.0, 0.0, 1.3075499e-05, 9.339205e-05, 0.0001...   \n",
       "9   [5.960496e-06, 0.00014358677, 0.00027341425, 0...   \n",
       "10  [0.0, 0.0, 0.0, 2.4796907e-05, 9.415441e-05, 0...   \n",
       "\n",
       "                                             val_loss  \\\n",
       "0   [4.938571519190722, 4.908481937823909, 4.74607...   \n",
       "1   [4.710240729964606, 4.646537842136799, 4.62718...   \n",
       "2   [3.542339720726013, 3.5360026788711547, 3.5261...   \n",
       "3   [3.5291484594345093, 3.3599658823013305, 3.323...   \n",
       "4   [3.3119295375181896, 3.302900663696893, 3.2845...   \n",
       "5   [3.27543308239172, 3.2868811257995003, 3.33043...   \n",
       "6   [2.378137436243567, 2.3730297124031745, 2.3672...   \n",
       "7   [2.360568891657461, 2.3202049153866153, 2.3722...   \n",
       "8   [3.317415142059326, 3.3130080938339233, 3.3085...   \n",
       "9   [3.3082576990127563, 3.272194962501526, 3.2140...   \n",
       "10  [2.3816349697113037, 2.3790840530395507, 2.376...   \n",
       "\n",
       "                                           val_recall  test_recall  \n",
       "0   [7.3646435e-05, 0.00019554954, 0.00045513033, ...     0.006154  \n",
       "1   [0.0008115798, 0.0032872779, 0.007526714, 0.01...     0.006154  \n",
       "2   [0.0, 0.0, 0.00011016104, 0.00022123894, 0.000...     0.003077  \n",
       "3   [9.494675e-05, 0.00086618867, 0.0027825893, 0....     0.005538  \n",
       "4   [0.0, 0.00010310501, 0.00016938652, 0.00022666...     0.006154  \n",
       "5   [0.0001913656, 0.00055657554, 0.0010071265, 0....     0.009231  \n",
       "6   [0.0, 8.837572e-05, 0.00016628666, 0.000169386...     0.003077  \n",
       "7   [0.00016938652, 0.000488495, 0.00066382345, 0....     0.006154  \n",
       "8   [0.0, 0.0, 8.7734064e-05, 0.00010310488, 0.000...     0.006154  \n",
       "9   [8.837564e-05, 0.00020663152, 0.00039936486, 0...     0.012308  \n",
       "10  [0.0, 0.0, 0.0, 8.837563e-05, 0.0001027686, 0....     0.012308  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for value in all_models['loss']:\n",
    "    plt.plot(value)\n",
    "    plt.legend(all_models['model_id'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'model_id':first_model_id,\n",
    "'train_time':0,\n",
    "'epochs':0,\n",
    "\n",
    "# Grid Search params\n",
    "'BATCH_SIZE':32,\n",
    "'learning_rate':0.1,\n",
    "'delta':0.2,             # Diversity Bias\n",
    "'max_seq_len':30,        # Max length of sequence71=median\n",
    "'embedding_dim':100,\n",
    "'rnn_units':20,\n",
    "    \n",
    "'val_perc':0.1,          # Percentage of users from df in val and test set\n",
    "'test_perc':0.1, \n",
    "'n_items_val':0,        # Number of last (chronologically) items in val and test set\n",
    "'n_items_test':1,\n",
    "\n",
    "'pad_value':total_items, # Pad with total_items+1 => masked => still use item 0\n",
    "'shift_targets_by':1  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = params['BATCH_SIZE']\n",
    "learning_rate = params['learning_rate']\n",
    "delta = params['delta']\n",
    "max_seq_len = params['max_seq_len']\n",
    "\n",
    "val_perc = params['val_perc']\n",
    "test_perc = params['test_perc']\n",
    "n_items_val = params['n_items_val']\n",
    "n_items_test = params['n_items_test']\n",
    "\n",
    "pad_value = params['pad_value']\n",
    "shift_targets_by = params['shift_targets_by'] \n",
    "\n",
    "embedding_dim = params['embedding_dim']\n",
    "rnn_units = params['rnn_units']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import train_val_test_split, create_seq_batch_dataset\n",
    "from Models import build_LSTM_model, store_LSTM_model\n",
    "from Evaluation import recall_metric, diversity_bias_loss, create_diversity_bias, get_predictions, get_metrics\n",
    "from Helpers import TimingCallback\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Val Split\n",
    "data_split = train_val_test_split(df, val_perc, test_perc, n_items_val, n_items_test, seqs=True)\n",
    "train_set, val_set, val_left_out_items, test_set, test_left_out_items = data_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FetP-6nDc-Vd"
   },
   "source": [
    "# Configure Checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '_' + file_name[:2] #ML or Am\n",
    "# directory = './ckpts/ckpts' \n",
    "directory = '../ckpts/ckpts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>train_time</th>\n",
       "      <th>epochs</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>delta</th>\n",
       "      <th>max_seq_len</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>rnn_units</th>\n",
       "      <th>val_perc</th>\n",
       "      <th>test_perc</th>\n",
       "      <th>n_items_val</th>\n",
       "      <th>n_items_test</th>\n",
       "      <th>pad_value</th>\n",
       "      <th>shift_targets_by</th>\n",
       "      <th>loss</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_am</td>\n",
       "      <td>18013.840090</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.554909733422284, 2.533241045152025, 2.46037...</td>\n",
       "      <td>[2.9381583e-06, 0.00013195378, 0.0002920571, 0...</td>\n",
       "      <td>[4.938571519190722, 4.908481937823909, 4.74607...</td>\n",
       "      <td>[7.3646435e-05, 0.00019554954, 0.00045513033, ...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_am</td>\n",
       "      <td>13535.720657</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.492791804774054, 2.2577781175157705, 2.2073...</td>\n",
       "      <td>[0.000210802, 0.0020089652, 0.005307905, 0.009...</td>\n",
       "      <td>[4.710240729964606, 4.646537842136799, 4.62718...</td>\n",
       "      <td>[0.0008115798, 0.0032872779, 0.007526714, 0.01...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_am</td>\n",
       "      <td>20846.932909</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.8265074285967597, 1.820659847388714, 1.8136...</td>\n",
       "      <td>[0.0, 0.0, 5.561642e-05, 0.00017923162, 0.0003...</td>\n",
       "      <td>[3.542339720726013, 3.5360026788711547, 3.5261...</td>\n",
       "      <td>[0.0, 0.0, 0.00011016104, 0.00022123894, 0.000...</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_am</td>\n",
       "      <td>22982.548593</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.8206264367831753, 1.7478289891933572, 1.602...</td>\n",
       "      <td>[1.6873295e-05, 0.0003124849, 0.0017495692, 0....</td>\n",
       "      <td>[3.5291484594345093, 3.3599658823013305, 3.323...</td>\n",
       "      <td>[9.494675e-05, 0.00086618867, 0.0027825893, 0....</td>\n",
       "      <td>0.005538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7_am</td>\n",
       "      <td>28558.309178</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.48747242005367586, 0.4793317374576048, 0.46...</td>\n",
       "      <td>[0.0, 5.3082982e-05, 0.00014864586, 0.00021017...</td>\n",
       "      <td>[3.3119295375181896, 3.302900663696893, 3.2845...</td>\n",
       "      <td>[0.0, 0.00010310501, 0.00016938652, 0.00022666...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8_am</td>\n",
       "      <td>30543.622423</td>\n",
       "      <td>161</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.47687314659026747, 0.3434375589208797, 0.27...</td>\n",
       "      <td>[7.4939e-05, 0.00035860614, 0.0007600899, 0.00...</td>\n",
       "      <td>[3.27543308239172, 3.2868811257995003, 3.33043...</td>\n",
       "      <td>[0.0001913656, 0.00055657554, 0.0010071265, 0....</td>\n",
       "      <td>0.009231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9_am</td>\n",
       "      <td>28914.833008</td>\n",
       "      <td>172</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.36525425487863167, 0.36047429656105234, 0.3...</td>\n",
       "      <td>[0.0, 1.0721208e-05, 0.000107472086, 0.0001692...</td>\n",
       "      <td>[2.378137436243567, 2.3730297124031745, 2.3672...</td>\n",
       "      <td>[0.0, 8.837572e-05, 0.00016628666, 0.000169386...</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10_am</td>\n",
       "      <td>32447.180922</td>\n",
       "      <td>172</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.35959263617549037, 0.2782717178589458, 0.20...</td>\n",
       "      <td>[5.1701416e-05, 0.00027426844, 0.0005778312, 0...</td>\n",
       "      <td>[2.360568891657461, 2.3202049153866153, 2.3722...</td>\n",
       "      <td>[0.00016938652, 0.000488495, 0.00066382345, 0....</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2_am</td>\n",
       "      <td>37728.076944</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.48949657668694485, 0.48542612732337614, 0.4...</td>\n",
       "      <td>[0.0, 0.0, 1.3075499e-05, 9.339205e-05, 0.0001...</td>\n",
       "      <td>[3.317415142059326, 3.3130080938339233, 3.3085...</td>\n",
       "      <td>[0.0, 0.0, 8.7734064e-05, 0.00010310488, 0.000...</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3_am</td>\n",
       "      <td>36173.264363</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.4853863109251842, 0.46703839228658256, 0.37...</td>\n",
       "      <td>[5.960496e-06, 0.00014358677, 0.00027341425, 0...</td>\n",
       "      <td>[3.3082576990127563, 3.272194962501526, 3.2140...</td>\n",
       "      <td>[8.837564e-05, 0.00020663152, 0.00039936486, 0...</td>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4_am</td>\n",
       "      <td>19245.330291</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135784</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3664456828327602, 0.36405172819280857, 0.36...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.4796907e-05, 9.415441e-05, 0...</td>\n",
       "      <td>[2.3816349697113037, 2.3790840530395507, 2.376...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 8.837563e-05, 0.0001027686, 0....</td>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id    train_time epochs BATCH_SIZE  learning_rate  delta max_seq_len  \\\n",
       "0      0_am  18013.840090    200         16            0.1    0.2          18   \n",
       "1      1_am  13535.720657    160         16            0.3    0.2          18   \n",
       "2      5_am  20846.932909    200         32            0.1    0.2          30   \n",
       "3      6_am  22982.548593    200         32            0.3    0.2          30   \n",
       "4      7_am  28558.309178    200         16            0.1    0.6          18   \n",
       "5      8_am  30543.622423    161         16            0.3    0.6          18   \n",
       "6      9_am  28914.833008    172         16            0.1    0.6          30   \n",
       "7     10_am  32447.180922    172         16            0.3    0.6          30   \n",
       "8      2_am  37728.076944    200         32            0.1    0.6          18   \n",
       "9      3_am  36173.264363    200         32            0.3    0.6          18   \n",
       "10     4_am  19245.330291    200         32            0.1    0.6          30   \n",
       "\n",
       "   embedding_dim rnn_units  val_perc  test_perc n_items_val n_items_test  \\\n",
       "0            100        20       0.1        0.1           0            1   \n",
       "1            100        20       0.1        0.1           0            1   \n",
       "2            100        50       0.1        0.1           0            1   \n",
       "3            100        50       0.1        0.1           0            1   \n",
       "4            100        20       0.1        0.1           0            1   \n",
       "5            100        20       0.1        0.1           0            1   \n",
       "6            100        20       0.1        0.1           0            1   \n",
       "7            100        20       0.1        0.1           0            1   \n",
       "8            100        20       0.1        0.1           0            1   \n",
       "9            100        20       0.1        0.1           0            1   \n",
       "10           100        20       0.1        0.1           0            1   \n",
       "\n",
       "   pad_value shift_targets_by  \\\n",
       "0     135784                1   \n",
       "1     135784                1   \n",
       "2     135784                1   \n",
       "3     135784                1   \n",
       "4     135784                1   \n",
       "5     135784                1   \n",
       "6     135784                1   \n",
       "7     135784                1   \n",
       "8     135784                1   \n",
       "9     135784                1   \n",
       "10    135784                1   \n",
       "\n",
       "                                                 loss  \\\n",
       "0   [2.554909733422284, 2.533241045152025, 2.46037...   \n",
       "1   [2.492791804774054, 2.2577781175157705, 2.2073...   \n",
       "2   [1.8265074285967597, 1.820659847388714, 1.8136...   \n",
       "3   [1.8206264367831753, 1.7478289891933572, 1.602...   \n",
       "4   [0.48747242005367586, 0.4793317374576048, 0.46...   \n",
       "5   [0.47687314659026747, 0.3434375589208797, 0.27...   \n",
       "6   [0.36525425487863167, 0.36047429656105234, 0.3...   \n",
       "7   [0.35959263617549037, 0.2782717178589458, 0.20...   \n",
       "8   [0.48949657668694485, 0.48542612732337614, 0.4...   \n",
       "9   [0.4853863109251842, 0.46703839228658256, 0.37...   \n",
       "10  [0.3664456828327602, 0.36405172819280857, 0.36...   \n",
       "\n",
       "                                               recall  \\\n",
       "0   [2.9381583e-06, 0.00013195378, 0.0002920571, 0...   \n",
       "1   [0.000210802, 0.0020089652, 0.005307905, 0.009...   \n",
       "2   [0.0, 0.0, 5.561642e-05, 0.00017923162, 0.0003...   \n",
       "3   [1.6873295e-05, 0.0003124849, 0.0017495692, 0....   \n",
       "4   [0.0, 5.3082982e-05, 0.00014864586, 0.00021017...   \n",
       "5   [7.4939e-05, 0.00035860614, 0.0007600899, 0.00...   \n",
       "6   [0.0, 1.0721208e-05, 0.000107472086, 0.0001692...   \n",
       "7   [5.1701416e-05, 0.00027426844, 0.0005778312, 0...   \n",
       "8   [0.0, 0.0, 1.3075499e-05, 9.339205e-05, 0.0001...   \n",
       "9   [5.960496e-06, 0.00014358677, 0.00027341425, 0...   \n",
       "10  [0.0, 0.0, 0.0, 2.4796907e-05, 9.415441e-05, 0...   \n",
       "\n",
       "                                             val_loss  \\\n",
       "0   [4.938571519190722, 4.908481937823909, 4.74607...   \n",
       "1   [4.710240729964606, 4.646537842136799, 4.62718...   \n",
       "2   [3.542339720726013, 3.5360026788711547, 3.5261...   \n",
       "3   [3.5291484594345093, 3.3599658823013305, 3.323...   \n",
       "4   [3.3119295375181896, 3.302900663696893, 3.2845...   \n",
       "5   [3.27543308239172, 3.2868811257995003, 3.33043...   \n",
       "6   [2.378137436243567, 2.3730297124031745, 2.3672...   \n",
       "7   [2.360568891657461, 2.3202049153866153, 2.3722...   \n",
       "8   [3.317415142059326, 3.3130080938339233, 3.3085...   \n",
       "9   [3.3082576990127563, 3.272194962501526, 3.2140...   \n",
       "10  [2.3816349697113037, 2.3790840530395507, 2.376...   \n",
       "\n",
       "                                           val_recall  test_recall  \n",
       "0   [7.3646435e-05, 0.00019554954, 0.00045513033, ...     0.006154  \n",
       "1   [0.0008115798, 0.0032872779, 0.007526714, 0.01...     0.006154  \n",
       "2   [0.0, 0.0, 0.00011016104, 0.00022123894, 0.000...     0.003077  \n",
       "3   [9.494675e-05, 0.00086618867, 0.0027825893, 0....     0.005538  \n",
       "4   [0.0, 0.00010310501, 0.00016938652, 0.00022666...     0.006154  \n",
       "5   [0.0001913656, 0.00055657554, 0.0010071265, 0....     0.009231  \n",
       "6   [0.0, 8.837572e-05, 0.00016628666, 0.000169386...     0.003077  \n",
       "7   [0.00016938652, 0.000488495, 0.00066382345, 0....     0.006154  \n",
       "8   [0.0, 0.0, 8.7734064e-05, 0.00010310488, 0.000...     0.006154  \n",
       "9   [8.837564e-05, 0.00020663152, 0.00039936486, 0...     0.012308  \n",
       "10  [0.0, 0.0, 0.0, 8.837563e-05, 0.0001027686, 0....     0.012308  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 32\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.3]\n",
    "epochs = [1]\n",
    "deltas = [0.2, 0.6]\n",
    "batch_sizes = [16, 32]\n",
    "max_seq_lens = [18, 30] #Median=18\n",
    "rnn_units = [20, 50]\n",
    "rank_at = 20\n",
    "\n",
    "total_runs = len(learning_rates) * len(epochs) * len(deltas) * len(batch_sizes) * len(max_seq_lens) * len(rnn_units)\n",
    "runs = 0\n",
    "print(f'Total runs: {total_runs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== \n",
      "Run: 1/32\n",
      "Number of epochs:\t 1\n",
      "Number of (h) units:\t 20\n",
      "Batch size:\t\t 16\n",
      "Max seq len:\t\t 18\n",
      "Learning rate:\t\t 0.1\n",
      "812/812 [==============================] - 83s 103ms/step - loss: 2.5549 - recall: 3.0499e-06 - val_loss: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Obtaining metrics time: 1.33\n",
      "Run Time: 147.01945400238037\n",
      "================================================== \n",
      "Run: 2/32\n",
      "Number of epochs:\t 1\n",
      "Number of (h) units:\t 20\n",
      "Batch size:\t\t 16\n",
      "Max seq len:\t\t 18\n",
      "Learning rate:\t\t 0.3\n",
      "    195/Unknown - 22s 114ms/step - loss: 2.5700 - recall: 0.0000e+00WARNING:tensorflow:Can save best model only with val_recall available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_recall` which is not available. Available metrics are: loss,recall\n",
      "    195/Unknown - 22s 114ms/step - loss: 2.5700 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d8733b3ce630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                             verbose=1)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics=[recall_metric(total_items=total_items)]\n",
    "for epoch in epochs:\n",
    "    params['epochs'] = epoch\n",
    "    for delta in deltas:\n",
    "        params['delta'] = delta\n",
    "        \n",
    "        # Pre-Calculate diversity_bias\n",
    "        diversity_bias = create_diversity_bias(train_set, total_items, delta)\n",
    "        loss=diversity_bias_loss(db=diversity_bias, total_items=total_items)\n",
    "        \n",
    "        for rnn_unit in rnn_units:\n",
    "            params['rnn_units'] = rnn_unit\n",
    "        \n",
    "            for batch_size in batch_sizes:\n",
    "                params['BATCH_SIZE'] = batch_size\n",
    "                \n",
    "                # Rebuild model \n",
    "                model = build_LSTM_model(total_items = total_items, embedding_dim = embedding_dim, mask_value = pad_value, rnn_units = rnn_unit, batch_size = batch_size, return_sequences=True)\n",
    "\n",
    "                for max_seq_len in max_seq_lens:\n",
    "                    params['max_seq_len'] = max_seq_len\n",
    "\n",
    "                    # Create new datasets\n",
    "                    train_dataset = create_seq_batch_dataset(df=train_set, shift=shift_targets_by, max_seq_len=max_seq_len, pad_value=pad_value, batch_size=batch_size, stats=False, drop_remainder=True)\n",
    "                    val_dataset = create_seq_batch_dataset(df=val_set, shift=shift_targets_by, max_seq_len=max_seq_len, pad_value=pad_value, batch_size=batch_size, stats=False, drop_remainder=True) \n",
    "\n",
    "                    for learning_rate in learning_rates:\n",
    "                        runs += 1\n",
    "                        s = time.time()\n",
    "\n",
    "                        # Print current run\n",
    "                        print('='*50, '\\nRun:', str(runs) + '/' + str(total_runs))\n",
    "                        print('Number of epochs:\\t', epoch)\n",
    "                        print('Number of (h) units:\\t', rnn_unit)\n",
    "                        print('Batch size:\\t\\t', batch_size)\n",
    "                        print('Max seq len:\\t\\t', max_seq_len)\n",
    "                        print('Learning rate:\\t\\t', learning_rate)\n",
    "\n",
    "                        params['learning_rate'] =  learning_rate\n",
    "\n",
    "                        # Compile Model\n",
    "                        model = build_LSTM_model(total_items = total_items, embedding_dim = embedding_dim, mask_value = pad_value, rnn_units = rnn_unit, batch_size = batch_size, return_sequences=True)\n",
    "                        optimizer=tf.keras.optimizers.Adagrad(lr=learning_rate)\n",
    "\n",
    "                        model.compile(optimizer=optimizer,\n",
    "                                      loss=loss, \n",
    "                                      metrics=metrics)\n",
    "\n",
    "                        # Create Callbacks\n",
    "                        checkpoint_dir = directory + '_' + str(params['model_id'])\n",
    "                        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "                        \n",
    "                        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, monitor = 'val_recall', mode = 'max', save_best_only = True, save_weights_only = True)\n",
    "                        early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_recall', min_delta = 0.0001, mode = 'max', patience = 15)\n",
    "                        timing_callback = TimingCallback()\n",
    "                        callbacks = [checkpoint_callback, early_stopping_callback, timing_callback]\n",
    "                        \n",
    "                        # Run \n",
    "                        history = model.fit(x=train_dataset, \n",
    "                                            validation_data=val_dataset, \n",
    "                                            epochs=epoch,\n",
    "                                            callbacks=callbacks,\n",
    "                                            verbose=1)\n",
    "                        \n",
    "                        \n",
    "                        # Restore lates checkpoint and predict \n",
    "                        model = build_LSTM_model(total_items = total_items, embedding_dim = embedding_dim, mask_value = pad_value, rnn_units = rnn_unit, batch_size = None, return_sequences=False)\n",
    "                        model.load_weights(tf.train.latest_checkpoint(checkpoint_dir)).expect_partial()\n",
    "                        model.build(tf.TensorShape([1, None]))\n",
    "                        test_batch_size = 1\n",
    "                        preds_df = get_predictions(model, test_set, test_left_out_items, test_batch_size, max_seq_len, pad_value, rank_at)\n",
    "                        metrics_test = get_metrics(preds_df, 5, rank_at)\n",
    "#                         print(metrics_test)\n",
    "                        \n",
    "                        # Store model\n",
    "                        store_path = path + 'results/' + res_ext + '/all_models_2'\n",
    "                        train_time = np.sum(timing_callback.logs)\n",
    "                        all_models = store_LSTM_model(store_path, params.copy(), history.history.copy(), train_time, metrics_test, store=True)\n",
    "                        \n",
    "                        # Change Model Id for next model\n",
    "                        params['model_id'] = str(int(params['model_id'][0]) + 1) + '_am'\n",
    "                        print(f'Run Time: {time.time() - s}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
