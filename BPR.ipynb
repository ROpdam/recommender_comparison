{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5282697</th>\n",
       "      <td>A1QP7FHEZRZ1LZ</td>\n",
       "      <td>B00HMXYKMM</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>168923</td>\n",
       "      <td>238328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819596</th>\n",
       "      <td>A1QP7FHEZRZ1LZ</td>\n",
       "      <td>B01A88MEV6</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>335203</td>\n",
       "      <td>238328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335926</th>\n",
       "      <td>A1QP7FHEZRZ1LZ</td>\n",
       "      <td>B007900UZY</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77864</td>\n",
       "      <td>238328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6822032</th>\n",
       "      <td>A1QP7FHEZRZ1LZ</td>\n",
       "      <td>B00RI9TL7E</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245981</td>\n",
       "      <td>238328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500311</th>\n",
       "      <td>A1QP7FHEZRZ1LZ</td>\n",
       "      <td>B00DBUVIVQ</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>131704</td>\n",
       "      <td>238328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating item_id user_id\n",
       "5282697  A1QP7FHEZRZ1LZ  B00HMXYKMM 2017-02-08     5.0  168923  238328\n",
       "8819596  A1QP7FHEZRZ1LZ  B01A88MEV6 2017-04-10     5.0  335203  238328\n",
       "3335926  A1QP7FHEZRZ1LZ  B007900UZY 2017-04-10     5.0   77864  238328\n",
       "6822032  A1QP7FHEZRZ1LZ  B00RI9TL7E 2017-04-10     4.0  245981  238328\n",
       "4500311  A1QP7FHEZRZ1LZ  B00DBUVIVQ 2017-04-10     5.0  131704  238328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "### Leave last item out of subset of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_x_out(full_data, n_users, leave_out=1, seed=1234):\n",
    "    # Input: data must contain user_id\n",
    "    # Output: full_data = without all entries last entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('user_id')['index'].apply(list)\n",
    "    np.random.RandomState(seed)\n",
    "    users = np.random.choice(list(user_items_ind.index), n_users*3, replace=False)\n",
    "    leave_out_indices = []\n",
    "    \n",
    "    user_counter = 0\n",
    "    indices = user_items_ind.loc[users[user_counter]]\n",
    "    while user_counter < n_users or len(indices) < leave_out:\n",
    "        to_leave_out_indices = indices[- leave_out:]\n",
    "        leave_out_indices.extend(to_leave_out_indices)\n",
    "        \n",
    "        user_counter += 1\n",
    "        indices = user_items_ind.loc[users[user_counter]]\n",
    "    \n",
    "    leave_out_set = full_data.loc[leave_out_indices]\n",
    "    full_data_leave_one_out = full_data.drop(leave_out_indices)\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 12137\n"
     ]
    }
   ],
   "source": [
    "total_users = len(df.user_id.unique())\n",
    "total_items = len(df.item_id.unique())\n",
    "print('Total Users:', total_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = int(0.1*total_users) # Number of users to be used for testing\n",
    "test_last_items = 1 # Items to be removed from test users in train set and used in test set\n",
    "\n",
    "val_users = int(0.1*total_users)\n",
    "val_last_items = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = leave_last_x_out(df, test_users, test_last_items)\n",
    "train_set, val_set = leave_last_x_out(train_set, val_users, val_last_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking\n",
    "- Paper: https://arxiv.org/pdf/1205.2618.pdf\n",
    "- Code:  https://github.com/valerystrizh/bpr/blob/master/BPR.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_iterations = params['n_iterations']\n",
    "        self.sample_size = params['sample_size']\n",
    "        self.seed = params['seed']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg_user = params['reg_user']\n",
    "        self.reg_item = params['reg_item']\n",
    "        self.alpha_decay = self.alpha / self.n_iterations\n",
    "        \n",
    "        self.model = {}\n",
    "        self.model['val_auc'] = []\n",
    "        self.user_items = pd.DataFrame()\n",
    "        self.train_users = []\n",
    "        self.train_items = []\n",
    "        \n",
    "        self.val_user_items = pd.DataFrame()\n",
    "        self.val_users = []\n",
    "        \n",
    "    def fit(self, train_set, val_set):\n",
    "        # Init\n",
    "        s = time.time()\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        p = np.random.normal(0, .1, (self.total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (self.total_items, self.nolf))  # items\n",
    "        \n",
    "        ## Used for sampling\n",
    "        self.user_items = train_set.groupby('user_id')['item_id'].apply(list)\n",
    "        self.train_users  = train_set.user_id.unique()\n",
    "        self.train_items = train_set.item_id.unique()\n",
    "        \n",
    "        ## Used for testing\n",
    "        self.val_user_items = val_set.groupby('user_id')['item_id'].apply(list)\n",
    "        self.val_users = val_set.user_id.unique()\n",
    "        \n",
    "        ## Track losses and alphas used\n",
    "        loss_list = []\n",
    "        alphas = []\n",
    "        \n",
    "        ## Create samples for all iterations\n",
    "        all_uij_samples = self.sample()\n",
    "        \n",
    "        # Training Loop\n",
    "        for iteration in range(self.n_iterations):\n",
    "            it_loss = 0\n",
    "            uij_samples = all_uij_samples[iteration]\n",
    "            \n",
    "            for uij_sample in uij_samples:\n",
    "                u = uij_sample[0]\n",
    "                i = uij_sample[1]\n",
    "                j = uij_sample[2]\n",
    "                \n",
    "                ## Calculate the difference between positive and negative item\n",
    "                diff = np.dot(p[u], (q[i] - q[j]).T)\n",
    "                \n",
    "                ## Obtain loss \n",
    "                loss_value = - np.log(self.sigmoid(diff))\n",
    "                regulariser = self.reg_user * np.dot(p[u], p[u]) + self.reg_item * np.dot(q[i],q[i]) + self.reg_item/10 * np.dot(q[j], q[j])\n",
    "                it_loss += loss_value + regulariser\n",
    "                \n",
    "                ## Derivative of the difference for update \n",
    "                diff_deriv = self.sigmoid(- diff)\n",
    "                \n",
    "                ## Update the factors of the latent features, using their respective derivatives\n",
    "                ## See http://ethen8181.github.io/machine-learning/recsys/4_bpr.html\n",
    "                p[u] += self.alpha * (diff_deriv * (q[i] - q[j]) - self.reg_user * p[u])\n",
    "                q[i] += self.alpha * (diff_deriv * p[u] - self.reg_item * q[i])\n",
    "                q[j] += self.alpha * (diff_deriv * (-p[u]) - self.reg_item * q[j])\n",
    "            \n",
    "            ## Store iteration variables\n",
    "            self.model['p'] = p\n",
    "            self.model['q'] = q\n",
    "            \n",
    "            if len(val_set) > 0: # TO DO: safe best & early stopping\n",
    "                val_auc = self.AUC()\n",
    "                self.model['val_auc'].append(val_auc)\n",
    "                print('iteration:', iteration, ' loss:', round(it_loss/self.sample_size,6), ' val AUC:', val_auc)#, ' val prec@' + str(val_rank), ':', round(prec_at,5), ' val rec@' + str(val_rank), ':', round(rec_at,5), '  Hits:', hitcount)#'  alpha:', self.alpha)\n",
    "            else:\n",
    "                print('iteration:', iteration, ' loss:', round(it_loss/self.sample_size,6))\n",
    "                \n",
    "            if iteration > 0:\n",
    "                self.update_alpha(loss_list[-1], it_loss)\n",
    "                \n",
    "            alphas.append(self.alpha)\n",
    "            loss_list.append(it_loss)\n",
    "        \n",
    "        # Store train values\n",
    "        train_time = time.time() - s\n",
    "        self.model['train_loss'] = loss_list\n",
    "        self.model['learning_rate'] = alphas\n",
    "        self.model['train_time'] = train_time\n",
    "        \n",
    "        \n",
    "    def sample(self):\n",
    "        n_samples = self.n_iterations\n",
    "        sample_size = int(self.sample_size)\n",
    "        print('Creating', str(n_samples), 'samples of length', str(sample_size))\n",
    "        all_uij_samples = []\n",
    "        \n",
    "        for n in range(n_samples):\n",
    "            uij_samples = []\n",
    "            for s in range(sample_size):\n",
    "                u = int(np.random.choice(self.train_users))\n",
    "                u_items = self.user_items[u]\n",
    "                i = random.choice(u_items)\n",
    "                j = int(np.random.choice(self.train_items)) \n",
    "                while j in u_items: #neg item j cannot be in the set of pos items of user u\n",
    "                    j = int(np.random.choice(self.train_items))\n",
    "                \n",
    "                uij_samples.append([u,i,j])\n",
    "                \n",
    "            all_uij_samples.append(uij_samples)\n",
    "            \n",
    "        return all_uij_samples\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    \n",
    "    def update_alpha(self, last_loss, it_loss):\n",
    "        if(last_loss < it_loss): #bold driver\n",
    "            self.alpha = 0.5 * self.alpha\n",
    "            return\n",
    "        \n",
    "        self.alpha = (1 - self.alpha_decay) * self.alpha\n",
    "    \n",
    "    def AUC(self):\n",
    "        auc = 0.0\n",
    "        n_users = len(self.val_users)\n",
    "\n",
    "        for u in self.val_users:\n",
    "            y_pred = np.dot(self.model['p'][u], self.model['q'].T)\n",
    "            y_true = np.zeros(self.total_items)\n",
    "            y_true[self.val_user_items[u]] = 1\n",
    "            auc += roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        auc /= n_users\n",
    "        return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_iterations\":20, #around 20 is sufficient\n",
    "\"sample_size\":len(train_set),\n",
    "\"seed\":1234,\n",
    "\"alpha\":0.1, # Learning rate\n",
    "          \n",
    "#Regularizers, still tweaking the values\n",
    "\"reg_user\":0.1,\n",
    "\"reg_item\":0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon_001_users'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPR_amazon_001 = BPR(total_users, total_items, params)\n",
    "BPR_amazon_001.fit(train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(results, log_path, res_name, file_name):\n",
    "        result_info = {'train_loss': results['train_loss'], 'train_speed': results['train_time'], 'lr':results['learning_rate'], 'file':file_name}\n",
    "        other_info = {'p':results['p'], 'q':results['q']} #'train_size':train_size, 'test_size':test_size, 'val_size':val_size}\n",
    "        final_log = dict(result_info, **params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = path + 'Results/BPR/'\n",
    "res_name = 'BPR_models'\n",
    "# store_results(BPR_amazon_001.model, log_path, res_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_pickle(log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>lr</th>\n",
       "      <th>file</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_iterations</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>alpha</th>\n",
       "      <th>reg_user</th>\n",
       "      <th>reg_item</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[37738.70952998008, 37367.62344250592, 37031.8...</td>\n",
       "      <td>671.664264</td>\n",
       "      <td>[0.1, 0.0995, 0.09900250000000001, 0.098507487...</td>\n",
       "      <td>Amazon_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.241923070934538, 0.06920972810691176, 0.04...</td>\n",
       "      <td>[[-0.16611172135509036, 0.08507575831053416, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[37394.440958291874, 36425.44377131431, 33992....</td>\n",
       "      <td>145.184773</td>\n",
       "      <td>[0.1, 0.0995, 0.09900250000000001, 0.098507487...</td>\n",
       "      <td>ML_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.04680908775364259, -0.3158303038758334, 0....</td>\n",
       "      <td>[[0.007149378623512315, -0.48439582309758, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[37735.955305987096, 37354.300465847715, 37016...</td>\n",
       "      <td>1340.069238</td>\n",
       "      <td>[0.1, 0.09975, 0.09950062500000001, 0.09925187...</td>\n",
       "      <td>Amazon_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.11660639595035503, -0.27620851231911575, 0...</td>\n",
       "      <td>[[0.2775415538836662, 0.031194809120961516, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[37404.337474763335, 36450.83321674445, 34028....</td>\n",
       "      <td>133.616620</td>\n",
       "      <td>[0.1, 0.0995, 0.09900250000000001, 0.098507487...</td>\n",
       "      <td>ML_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[-0.26730203980550665, 0.37941205752800944, -...</td>\n",
       "      <td>[[-0.2754524304552424, 0.35559385306824404, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[36687.04665538535, 36364.61788972847, 36022.9...</td>\n",
       "      <td>1297.946364</td>\n",
       "      <td>[0.1, 0.09975, 0.09950062500000001, 0.09925187...</td>\n",
       "      <td>Amazon_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.022538348429418188, 0.5387829961733387, -0...</td>\n",
       "      <td>[[-0.27003640020991404, 0.01091206380890876, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[92032.12642368786, 87582.42161757455, 87083.2...</td>\n",
       "      <td>282.715095</td>\n",
       "      <td>[0.1, 0.0995, 0.09900250000000001, 0.098507487...</td>\n",
       "      <td>ML_001_users</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>103218</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.009304258038289716, 0.0037796272219539325,...</td>\n",
       "      <td>[[0.01781748548482589, 0.007234042871937463, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train_loss  train_speed  \\\n",
       "0  [37738.70952998008, 37367.62344250592, 37031.8...   671.664264   \n",
       "1  [37394.440958291874, 36425.44377131431, 33992....   145.184773   \n",
       "2  [37735.955305987096, 37354.300465847715, 37016...  1340.069238   \n",
       "3  [37404.337474763335, 36450.83321674445, 34028....   133.616620   \n",
       "4  [36687.04665538535, 36364.61788972847, 36022.9...  1297.946364   \n",
       "5  [92032.12642368786, 87582.42161757455, 87083.2...   282.715095   \n",
       "\n",
       "                                                  lr              file nolf  \\\n",
       "0  [0.1, 0.0995, 0.09900250000000001, 0.098507487...  Amazon_001_users   20   \n",
       "1  [0.1, 0.0995, 0.09900250000000001, 0.098507487...      ML_001_users   20   \n",
       "2  [0.1, 0.09975, 0.09950062500000001, 0.09925187...  Amazon_001_users   20   \n",
       "3  [0.1, 0.0995, 0.09900250000000001, 0.098507487...      ML_001_users   20   \n",
       "4  [0.1, 0.09975, 0.09950062500000001, 0.09925187...  Amazon_001_users   20   \n",
       "5  [0.1, 0.0995, 0.09900250000000001, 0.098507487...      ML_001_users   20   \n",
       "\n",
       "  n_iterations sample_size  seed  alpha  reg_user  reg_item  \\\n",
       "0           20      103218  1234    0.1       0.1       0.1   \n",
       "1           20      103218  1234    0.1       0.1       0.1   \n",
       "2           20      103218  1234    0.1       0.1       0.1   \n",
       "3           20      103218  1234    0.1       0.1       0.1   \n",
       "4           20      103218  1234    0.1       0.1       0.1   \n",
       "5           20      103218  1234    0.1       0.1       0.1   \n",
       "\n",
       "                                                   p  \\\n",
       "0  [[0.241923070934538, 0.06920972810691176, 0.04...   \n",
       "1  [[0.04680908775364259, -0.3158303038758334, 0....   \n",
       "2  [[0.11660639595035503, -0.27620851231911575, 0...   \n",
       "3  [[-0.26730203980550665, 0.37941205752800944, -...   \n",
       "4  [[0.022538348429418188, 0.5387829961733387, -0...   \n",
       "5  [[0.009304258038289716, 0.0037796272219539325,...   \n",
       "\n",
       "                                                   q  \n",
       "0  [[-0.16611172135509036, 0.08507575831053416, -...  \n",
       "1  [[0.007149378623512315, -0.48439582309758, 0.3...  \n",
       "2  [[0.2775415538836662, 0.031194809120961516, -0...  \n",
       "3  [[-0.2754524304552424, 0.35559385306824404, -0...  \n",
       "4  [[-0.27003640020991404, 0.01091206380890876, 0...  \n",
       "5  [[0.01781748548482589, 0.007234042871937463, -...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = len(df_res['train_loss']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['train_loss'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['lr'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df = pd.DataFrame(columns=['pred_items_ranked', 'true_id'], index=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_items_ranked</th>\n",
       "      <th>true_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_items_ranked true_id\n",
       "1               NaN     NaN\n",
       "2               NaN     NaN\n",
       "3               NaN     NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_predictions(model, test_set, rank_at, multiprocessing=True):\n",
    "    import eval_rank_bpr\n",
    "    \n",
    "    s = time.time()\n",
    "    users = test_set.user_id.unique()\n",
    "    items = test_set.item_id.unique()\n",
    "    test_user_items = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "    ranked_df = pd.DataFrame(columns=['pred_items_ranked', 'true_id'], index=users)\n",
    "    \n",
    "    if multiprocessing:\n",
    "        mp_splits = 4\n",
    "        users_split = np.array_split(users, mp_splits)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = mp.Pool(processes = mp_splits)\n",
    "            ranked = pool.map(eval_rank_bpr.eval_rank_bpr, [\n",
    "                                                    [model, users_split[0], items, test_user_items, rank_at], \n",
    "                                                    [model, users_split[1], items, test_user_items, rank_at], \n",
    "                                                    [model, users_split[2], items, test_user_items, rank_at], \n",
    "                                                    [model, users_split[3], items, test_user_items, rank_at]\n",
    "                                                            ])\n",
    "            pool.close()\n",
    "\n",
    "            for i in range(mp_splits):\n",
    "                ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "    \n",
    "    else:\n",
    "        pred_items_ranked = []\n",
    "        true_items_list = []\n",
    "        \n",
    "        for u in users:\n",
    "            user_item_pred_score = []\n",
    "            true_items = []\n",
    "            for true_item in test_user_items.loc[u]:\n",
    "                true_items.append(true_item)\n",
    "\n",
    "            predictions = np.dot(model['p'][u], model['q'].T)\n",
    "            ids = np.argpartition(predictions, -rank_at)[-rank_at:]\n",
    "            best_ids = np.argsort(predictions[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "            \n",
    "            pred_items_ranked.append(best)\n",
    "            true_items_list.append(true_items)\n",
    "\n",
    "        ranked_df['pred_items_ranked'] = pred_items_ranked\n",
    "        ranked_df['true_id'] = true_items_list\n",
    "\n",
    "    print('Ranking time:', round(time.time() - s,2))\n",
    "    \n",
    "    return ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ranked_df, steps, max_rank):\n",
    "    s = time.time()\n",
    "    ranks_at = [1] + [i for i in range(steps, max_rank + steps, steps)]\n",
    "    hitcounts = []\n",
    "    recs_at = []\n",
    "    precs_at = []\n",
    "    metrics = pd.DataFrame(columns=['rank_at', 'hitcounts', 'recall', 'precision'])\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for i, row in ranked_df.iterrows():\n",
    "            hitcount +=  len(set(row['true_id']) & set(row['pred_items_ranked'][:rank]))\n",
    "\n",
    "        prec_at = hitcount / rank / len(ranked_df)\n",
    "        rec_at = hitcount / len(ranked_df.iloc[0]['true_id']) / len(ranked_df)\n",
    "\n",
    "        hitcounts.append(hitcount)                     \n",
    "        recs_at.append(rec_at)\n",
    "        precs_at.append(prec_at)\n",
    "\n",
    "    metrics['rank_at'] = ranks_at\n",
    "    metrics['hitcounts'] = hitcounts\n",
    "    metrics['recall'] = recs_at\n",
    "    metrics['precision'] = precs_at\n",
    "    print('Obtaining metrics time:', round(time.time() - s,2))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'p':df_res['p'][1], 'q':df_res['q'][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking time: 2.8052830696105957\n",
      "Obtaining metrics time: 1.1742150783538818\n"
     ]
    }
   ],
   "source": [
    "rank_at = 20\n",
    "ranked_df = rank_predictions(model, test_set, rank_at, True)\n",
    "\n",
    "steps = 5\n",
    "metrics = get_metrics(ranked_df, steps, rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_pickle(path + 'Results/BPR/metrics_' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts    recall  precision\n",
       "0        1          0  0.000000   0.000000\n",
       "1        5          0  0.000000   0.000000\n",
       "2       10          0  0.000000   0.000000\n",
       "3       15          1  0.000824   0.000055\n",
       "4       20          1  0.000824   0.000041"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(path + 'Results/metrics_' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['rank_at'], metrics['precision'])\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('precision@')\n",
    "plt.title('Precision for different rank values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['rank_at'], metrics['recall'])\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('recall@')\n",
    "plt.title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_run(file_names, file_paths, all_params):\n",
    "    runs = 0\n",
    "    for file_name, file_path, params in zip(file_names, file_paths, all_params):\n",
    "        # Init \n",
    "        print('\\n\\n', '='*50)\n",
    "        df = pd.read_pickle(file_path + file_name)\n",
    "        df['item_id'] = df.item.astype('category').cat.codes\n",
    "        df['user_id'] = df.user.astype('category').cat.codes\n",
    "        \n",
    "        total_users = len(df.user_id.unique())\n",
    "        total_items = len(df.item_id.unique())\n",
    "        \n",
    "        test_users = int(0.1*total_users) # Number of users to be used for testing\n",
    "        test_last_items = 1 # Items to be removed from test users in train set and used in test set\n",
    "\n",
    "        val_users = int(0.1*total_users)\n",
    "        val_last_items = 1\n",
    "\n",
    "        train_set, test_set = leave_last_x_out(df, test_users, test_last_items)\n",
    "        train_set, val_set = leave_last_x_out(train_set, val_users, val_last_items)\n",
    "        \n",
    "        train_users = len(train_set.user_id.unique())\n",
    "        \n",
    "        print('Run:', runs + 1, '\\nFile:', file_name,\n",
    "              '\\nTrain users:', train_users, '\\nTest users:', test_users,\n",
    "              '\\nVal users:', val_users)\n",
    "        \n",
    "        # Model Run\n",
    "        params['sample_size'] = 0.5*len(train_set)\n",
    "        model = BPR(total_users, total_items, params)\n",
    "        model.fit(train_set, val_set)\n",
    "        \n",
    "        log_path = path + 'Results/BPR/'\n",
    "        res_name = 'BPR_models'\n",
    "        store_results(model.model, log_path, res_name, file_name)\n",
    "        \n",
    "        rank_at = 20\n",
    "        steps = 5\n",
    "        \n",
    "        ranked_df = rank_predictions(model.model, test_set, rank_at, False)\n",
    "        metrics = get_metrics(ranked_df, steps, rank_at)\n",
    "        print('Results')\n",
    "        print(metrics)\n",
    "        \n",
    "        metrics.to_pickle(path + 'Results/BPR/metrics_' + file_name)\n",
    "        \n",
    "        runs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_amazon_001 = {\n",
    "\"nolf\":20, # Size of latent feature vectors\n",
    "\"n_iterations\":40, # Depends on number of items and users\n",
    "\"sample_size\":1, # Adjusted in loop to 0.5*len(train_set)\n",
    "\"seed\":1234,\n",
    "\"alpha\":0.1, # Learning rate\n",
    "          \n",
    "#Regularizers\n",
    "\"reg_user\":0.05, # should be in proportion to the number of items \n",
    "\"reg_item\":0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ml_001 = {\n",
    "\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_iterations\":20, # Depends on number of items and users\n",
    "\"sample_size\":1, # Adjusted in loop to 0.5*len(train_set)\n",
    "\"seed\":1234,\n",
    "\"alpha\":0.1, # Learning rate\n",
    "          \n",
    "#Regularizers\n",
    "\"reg_user\":0.5,\n",
    "\"reg_item\":0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ====================================================================================================\n",
      "\n",
      "Run: 1 \n",
      "File: Amazon_001_users \n",
      "Train users: 12127 \n",
      "Test users: 1213\n",
      "Creating 40 samples of length 51609\n",
      "iteration: 0  loss: 0.711216  val AUC: 0.5028830665972969\n",
      "iteration: 1  loss: 0.704144  val AUC: 0.5092721543820596\n",
      "iteration: 2  loss: 0.697702  val AUC: 0.5177078578592073\n",
      "iteration: 3  loss: 0.691078  val AUC: 0.525312602878858\n",
      "iteration: 4  loss: 0.682936  val AUC: 0.5323212868998314\n",
      "iteration: 5  loss: 0.674216  val AUC: 0.5384024363720707\n",
      "iteration: 6  loss: 0.666345  val AUC: 0.5420130682784807\n",
      "iteration: 7  loss: 0.657289  val AUC: 0.5467043275066787\n",
      "iteration: 8  loss: 0.648233  val AUC: 0.5499021762334384\n",
      "iteration: 9  loss: 0.638965  val AUC: 0.5512302781165304\n",
      "iteration: 10  loss: 0.629605  val AUC: 0.5551451822438871\n",
      "iteration: 11  loss: 0.619804  val AUC: 0.5573460681401993\n",
      "iteration: 12  loss: 0.609015  val AUC: 0.5583488913652096\n",
      "iteration: 13  loss: 0.599605  val AUC: 0.557782092199662\n",
      "iteration: 14  loss: 0.590952  val AUC: 0.5583222252319546\n",
      "iteration: 15  loss: 0.580603  val AUC: 0.5581249252816428\n",
      "iteration: 16  loss: 0.570878  val AUC: 0.5590303161020559\n",
      "iteration: 17  loss: 0.562195  val AUC: 0.5604487055251409\n",
      "iteration: 18  loss: 0.552897  val AUC: 0.5614603862414795\n",
      "iteration: 19  loss: 0.543751  val AUC: 0.5633061295512463\n",
      "iteration: 20  loss: 0.535927  val AUC: 0.5630473355977017\n",
      "iteration: 21  loss: 0.526873  val AUC: 0.5630264361997379\n",
      "iteration: 22  loss: 0.51965  val AUC: 0.5630095373907553\n",
      "iteration: 23  loss: 0.512795  val AUC: 0.5630387055646113\n",
      "iteration: 24  loss: 0.506759  val AUC: 0.5637606847670351\n",
      "iteration: 25  loss: 0.499326  val AUC: 0.5642177955430095\n",
      "iteration: 26  loss: 0.493351  val AUC: 0.5654319408496192\n",
      "iteration: 27  loss: 0.488288  val AUC: 0.5662778580311398\n",
      "iteration: 28  loss: 0.481991  val AUC: 0.5674878421900111\n",
      "iteration: 29  loss: 0.478716  val AUC: 0.5672305066451597\n",
      "iteration: 30  loss: 0.47486  val AUC: 0.5673375190554812\n",
      "iteration: 31  loss: 0.469896  val AUC: 0.5673044707117093\n",
      "iteration: 32  loss: 0.466985  val AUC: 0.5678498620432347\n",
      "iteration: 33  loss: 0.464143  val AUC: 0.5679563660174987\n",
      "iteration: 34  loss: 0.461224  val AUC: 0.5684876683182576\n",
      "iteration: 35  loss: 0.458157  val AUC: 0.5687936531659271\n",
      "iteration: 36  loss: 0.455164  val AUC: 0.5694429260120502\n",
      "iteration: 37  loss: 0.452922  val AUC: 0.5705726040335438\n",
      "iteration: 38  loss: 0.451149  val AUC: 0.5711194805335557\n",
      "iteration: 39  loss: 0.448756  val AUC: 0.5716444675232795\n",
      "results added\n",
      "Ranking time: 3.27\n",
      "Obtaining metrics time: 0.97\n",
      "Results\n",
      "   rank_at  hitcounts    recall  precision\n",
      "0        1         17  0.014015   0.014015\n",
      "1        5         74  0.061006   0.012201\n",
      "2       10         99  0.081616   0.008162\n",
      "3       15        109  0.089860   0.005991\n",
      "4       20        110  0.090684   0.004534\n",
      "\n",
      "\n",
      " ====================================================================================================\n",
      "\n",
      "Run: 2 \n",
      "File: ML_001_users \n",
      "Train users: 1625 \n",
      "Test users: 162\n",
      "Creating 20 samples of length 125207\n",
      "iteration: 0  loss: 0.734839  val AUC: 0.5131837927285388\n",
      "iteration: 1  loss: 0.699515  val AUC: 0.5464328197412073\n",
      "iteration: 2  loss: 0.695489  val AUC: 0.6704146683098975\n",
      "iteration: 3  loss: 0.694147  val AUC: 0.8405789748945346\n",
      "iteration: 4  loss: 0.693657  val AUC: 0.9352594275419343\n",
      "iteration: 5  loss: 0.693529  val AUC: 0.9537189646325916\n",
      "iteration: 6  loss: 0.693571  val AUC: 0.958147108755154\n",
      "iteration: 7  loss: 0.69368  val AUC: 0.959598546829604\n",
      "iteration: 8  loss: 0.693753  val AUC: 0.9596847504549408\n",
      "iteration: 9  loss: 0.693792  val AUC: 0.9600741103703373\n",
      "iteration: 10  loss: 0.693819  val AUC: 0.9602729149034115\n",
      "iteration: 11  loss: 0.693826  val AUC: 0.960291475492598\n",
      "iteration: 12  loss: 0.693834  val AUC: 0.9603764417453222\n",
      "iteration: 13  loss: 0.693838  val AUC: 0.9603628306465852\n",
      "iteration: 14  loss: 0.693841  val AUC: 0.9603752043727102\n",
      "iteration: 15  loss: 0.693839  val AUC: 0.9603731420850227\n",
      "iteration: 16  loss: 0.693842  val AUC: 0.9603624181890478\n",
      "iteration: 17  loss: 0.69384  val AUC: 0.9603632431041232\n",
      "iteration: 18  loss: 0.693842  val AUC: 0.9603636555616604\n",
      "iteration: 19  loss: 0.69384  val AUC: 0.9603661303068853\n",
      "results added\n",
      "Ranking time: 0.08\n",
      "Obtaining metrics time: 0.15\n",
      "Results\n",
      "   rank_at  hitcounts    recall  precision\n",
      "0        1          0  0.000000   0.000000\n",
      "1        5          7  0.043210   0.008642\n",
      "2       10          8  0.049383   0.004938\n",
      "3       15         13  0.080247   0.005350\n",
      "4       20         19  0.117284   0.005864\n"
     ]
    }
   ],
   "source": [
    "file_names = ['Amazon_001_users', 'ML_001_users']\n",
    "file_paths = [path + 'Data/Amazon/', path + 'Data/ML/']\n",
    "all_params = [params_amazon_001, params_ml_001]\n",
    "\n",
    "seq_run(file_names, file_paths, all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('Data/amazon_clothing_shoes_jewelry_data')\n",
    "# users = df.user.unique()\n",
    "# to_keep = users[:300000]\n",
    "\n",
    "# user_indices = df.groupby('user')['index'].apply(list)\n",
    "# to_keep_indices = []\n",
    "# for u in user_indices[to_keep]:\n",
    "#     to_keep_indices.extend(u)\n",
    "\n",
    "# new_df = df_og.loc[to_keep_indices]\n",
    "# len(to_keep_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    \"\"\"\" All functions used to run, test, plot and store the\n",
    "    Singular Value Decomposition Model\"\"\"\n",
    "\n",
    "    def __init__(self, params, total_users, total_items):\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.alpha = params['alpha']\n",
    "        self.alpha_b = params['alpha_b']\n",
    "        self.alpha_cb = params['alpha_cb']\n",
    "        self.use_bias = params['use_bias']\n",
    "        self.use_impl_fb = params['use_impl_fb']\n",
    "        self.use_color = params['use_color']\n",
    "        self.use_weight_ver = params['use_weight_ver']\n",
    "        self.bu_reg = params['bu_reg']\n",
    "        self.bi_reg = params['bi_reg']\n",
    "        self.pu_reg = params['pu_reg']\n",
    "        self.qi_reg = params['qi_reg']\n",
    "        self.x_reg = params['x_reg']\n",
    "        self.cb_reg = params['cb_reg']\n",
    "        self.ver_weight = params['ver_weight']\n",
    "        self.stop = params['stop']\n",
    "        self.random_state = params['random_state']\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.params = params\n",
    "        self.mu = 0 \n",
    "        self.N = []\n",
    "        self.N_test = []\n",
    "        self.t = pd.DataFrame()\n",
    "        self.c = pd.DataFrame()\n",
    "        self.F = pd.DataFrame()\n",
    "\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.train_time = 0\n",
    "        self.best_model = {}\n",
    "        self.model = {}\n",
    "        self.test_results = {}\n",
    "\n",
    "    def fit(self, train_data, val_data=[], verbose=1, plot=True, plot_name=''):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.SVD(train_data=train_data, val_data=val_data, verbose=verbose, plot=plot, plot_name=plot_name)\n",
    "        return self\n",
    "\n",
    "    \n",
    "###############################################################################################\n",
    "    \n",
    "    def SVD(self, train_data, val_data, verbose, plot, plot_name):\n",
    "        \"\"\"\"The SVD algorithm with sgd\n",
    "        input: rating dataset with columns:['rating', 'user_id', 'item_id']\n",
    "        output: the resulting p, q, bi, bu matrices\"\"\"\n",
    "        self.mu = self.create_mu(train_data)\n",
    "        train_matrix = self.create_matrix(train_data, self.total_users, self.total_items)\n",
    "        \n",
    "        tuples_train = [tuple(x) for x in train_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        \n",
    "        p = np.random.normal(0, .1, (total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (total_items, self.nolf))  # items\n",
    "        \n",
    "        # user and item biases\n",
    "        b_user = np.zeros(total_users)\n",
    "        b_item = np.zeros(total_items)\n",
    "        \n",
    "        # using color (pareto split (0,1,2)) attribute bias\n",
    "        if self.use_color:\n",
    "            print('Creating F and c, for incorporating color bias')\n",
    "            self.F, self.c = self.init_color(train_data)\n",
    "\n",
    "        # implicit fb rated, not rated\n",
    "        x = np.random.normal(0, .1, (total_items, self.nolf))\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        if self.use_impl_fb:\n",
    "            print('Creating N, for incorporating implicit feedback')\n",
    "            self.N = train_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        \n",
    "        # 0.5 weight on the errors of verified = False user item combinations\n",
    "        if self.use_weight_ver:\n",
    "            i_verified = train_data.set_index(['new_user_id', 'new_item_id'])['verified']\n",
    "            i_verified = i_verified.loc[~i_verified.index.duplicated(keep='first')]\n",
    "        \n",
    "        sqrt_Nu = 0\n",
    "        cb = 0\n",
    "        rmses = []\n",
    "        val_rmses = []\n",
    "        smallest_val_rmse = 10000\n",
    "        val_rmse = \"na\"\n",
    "        start = time.time()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_sq_error = 0\n",
    "            for u, i, r_ui in tuples_train:\n",
    "                u = int(u)\n",
    "                i = int(i)\n",
    "                \n",
    "                if self.use_impl_fb:\n",
    "                    impl_fb_u = np.zeros(self.nolf)\n",
    "                    sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                    for j in self.N[u]:\n",
    "                        impl_fb_u += x[j] / sqrt_Nu\n",
    "\n",
    "                if self.use_color and epoch > 5:\n",
    "                    F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                    u_mu = self.mu + b_user[u]\n",
    "                    sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        cb += (r_uf - u_mu) * self.c[u,i][index]\n",
    "                    cb /=  sqrt_F_ui\n",
    "                        \n",
    "                if self.use_bias:   \n",
    "                    error = r_ui - ((self.mu + b_user[u] + b_item[i] + cb) + np.dot(p[u] + impl_fb_u, q[i]))\n",
    "                    if self.use_weight_ver and not i_verified[u,i]:\n",
    "                        error = self.ver_weight * error\n",
    "                    \n",
    "                    b_user[u] += self.alpha_b * (error - self.bu_reg * b_user[u])\n",
    "                    b_item[i] += self.alpha_b * (error - self.bi_reg * b_item[i])\n",
    "                else:\n",
    "                    error = r_ui - np.dot(p[u], q[i])\n",
    "\n",
    "                p[u] += self.alpha * (error * q[i] - self.pu_reg * p[u])\n",
    "                q[i] += self.alpha * (error * (p[u] + impl_fb_u) - self.qi_reg * q[i])\n",
    "                total_sq_error += np.square(error)\n",
    "            \n",
    "                if self.use_impl_fb:\n",
    "                    for j in self.N[u]:\n",
    "                        x[j] += self.alpha * (error * q[i] / sqrt_Nu - self.x_reg * x[j])\n",
    "                \n",
    "                if self.use_color and epoch > 5:\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        u_mu = self.mu + b_user[u]\n",
    "                        self.c[u,i][index] += self.alpha_cb * (error * (1/sqrt_F_ui) * (r_uf - u_mu) - self.cb_reg * self.c[u,i][index])\n",
    "                \n",
    "            rmse = np.sqrt(total_sq_error / len(tuples_train))\n",
    "            rmses.append(rmse)\n",
    "            \n",
    "            self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "            \n",
    "            # Validation\n",
    "            if len(val_data) > 0:\n",
    "                new_val_rmse = self.test(val_data, val=True)\n",
    "                val_rmses.append(new_val_rmse)\n",
    "                if new_val_rmse < smallest_val_rmse:\n",
    "                    smallest_val_rmse = new_val_rmse\n",
    "                    self.best_model = copy.deepcopy(self.model)\n",
    "                val_rmse = new_val_rmse\n",
    "                \n",
    "            # Epoch Printing\n",
    "            if epoch % verbose == 0:\n",
    "                if len(val_data) > 0:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse, ' Val_RMSE:', val_rmse)\n",
    "                else:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse)\n",
    "            \n",
    "            if self.stop and val_rmses[-2:][0] < val_rmse:\n",
    "                print('BREAK: Validation set not improving anymore')\n",
    "                break\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_rmse(rmses, val_rmses, plot_name)\n",
    "\n",
    "        self.train_time = time.time() - start\n",
    "        self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "#################################################################################################\n",
    "\n",
    "    def init_color(self, data_set):\n",
    "        self.t = data_set.groupby(['new_user_id', 'par_col2'])['new_item_id'].apply(list)\n",
    "        F = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items)\n",
    "        c = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items, random=True)\n",
    "        return F, c\n",
    "\n",
    "    def sim_items(self, x, random=False):\n",
    "        u_id = x.name[0]\n",
    "        col = x.iloc[0]\n",
    "        if random:\n",
    "            return np.random.normal(0,.1,len(self.t[u_id, col]))\n",
    "        return self.t[u_id, col]\n",
    "    \n",
    "    def create_matrix(self, X_train, n_users, n_items):\n",
    "        r = X_train['new_user_id']\n",
    "        c = X_train['new_item_id']\n",
    "        d = X_train['rating']\n",
    "        train_matrix = sparse.coo_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "    \n",
    "        return train_matrix.tocsr()\n",
    "    \n",
    "    def create_mu(self, train_set):\n",
    "        # Better mean calculation according to https://sifter.org/~simon/journal/20061211.html\n",
    "        va = train_set.groupby('new_user_id')['rating'].mean().var() #variance mean ratings users\n",
    "        vb = train_set.groupby('new_item_id')['rating'].mean().var() #variance mean ratings items\n",
    "        k = va/vb #variance proportion\n",
    "        better_mu = (train_set['rating'].mean() + train_set['rating'].sum()) / (k+len(train_set))\n",
    "        return better_mu\n",
    "    \n",
    "    def plot_rmse(self, rmse, val_rmses=[], plot_name=''):\n",
    "        plt.plot(np.arange(len(rmse)), rmse)\n",
    "        if len(val_rmses) > 0:\n",
    "            plt.plot(np.arange(len(val_rmses)), val_rmses, color='red')\n",
    "        plt.title('RMSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        if len(plot_name) > 0:\n",
    "            plt.savefig('Plots/' + plot_name + '.png')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self, test_data, val=False):\n",
    "        if not val:\n",
    "            self.test_data = test_data\n",
    "        tuples_test = [tuple(x) for x in test_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        test_matrix = self.create_matrix(test_data, self.total_users, self.total_items)\n",
    "        \n",
    "        if self.use_impl_fb and val:\n",
    "            self.N_test = self.val_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        elif self.use_impl_fb:\n",
    "            self.N_test = self.test_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "            \n",
    "        total_error = 0\n",
    "        estimates = []\n",
    "        for u, i, r_ui in tuples_test:\n",
    "            u = int(u)\n",
    "            i = int(i)\n",
    "            est = self.estimate(u, i, test_matrix, test_data)\n",
    "            estimates.append(est)\n",
    "            total_error += np.square(r_ui - est)\n",
    "        \n",
    "        rmse = np.sqrt(total_error / len(tuples_test))\n",
    "        \n",
    "        if not val:\n",
    "            self.test_results = {'rmse': rmse, 'estimates':estimates}\n",
    "            print('RMSE on test set:', self.test_results['rmse'])\n",
    "        else:\n",
    "            return rmse\n",
    "\n",
    "    def estimate(self, u, i, test_matrix, test_data):\n",
    "        est = self.mu + self.model['bu'][u] + self.model['bi'][i]\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        cb = 0\n",
    "        if u in self.train_data['new_user_id'] and i in self.train_data['new_item_id']:\n",
    "            \n",
    "            if self.use_impl_fb and u in self.N.index:\n",
    "                sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                for j in self.N[u]:   \n",
    "                    impl_fb_u += self.model['x'][j] / sqrt_Nu\n",
    "            \n",
    "            if self.use_color and (u,i) in self.model['cbu']:\n",
    "                F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                u_mu = self.mu + self.model['bu'][u]\n",
    "                sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                for index, f in enumerate(F_ui):\n",
    "                    r_uf = self.train_data[(self.train_data['new_user_id']==u) & (self.train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                    cb += (r_uf - u_mu) * self.model['cbu'][u,i][index]\n",
    "                cb /=  sqrt_F_ui\n",
    "                \n",
    "            est += cb + np.dot(self.model['p'][u] + impl_fb_u, self.model['q'][i])\n",
    "\n",
    "        return est\n",
    "    \n",
    "    def store_results(self, log_path, res_name, user_thres, item_thres):\n",
    "        train_size = round((len(self.train_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        test_size = round((len(self.test_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        val_size = round((len(self.val_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        \n",
    "        result_info = {'RMSE_test': self.test_results['rmse'], 'train_speed': round(self.train_time,2)}\n",
    "        other_info = {'u_thres': user_thres,'i_thres': item_thres, 'train_size':train_size, 'test_size':test_size, 'val_size':val_size, 'train_rmse':self.model['rmse'], 'val_rmse':self.model['val_rmse']}\n",
    "        final_log = dict(result_info, **self.params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_iterations = params['n_iterations']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg_user = params['reg_user']\n",
    "        self.reg_item = params['reg_item']\n",
    "        self.reg_bias = params['reg_bias']\n",
    "        self.alpha_decay = self.alpha / self.n_iterations\n",
    "        self.model = {'loss_list':[], 'learning_rate':[]}\n",
    "        \n",
    "    def fit(self, train_set, val_set, val_rank, batch_size=1000):\n",
    "        #Init\n",
    "        s = time.time()\n",
    "        self.model['p'] = np.random.normal(0, .1, (self.total_users, self.nolf))  # users\n",
    "        self.model['q'] = np.random.normal(0, .1, (self.total_items, self.nolf))  # items\n",
    "        self.model['b'] = np.zeros(self.total_items)\n",
    "        \n",
    "#         val_prec_at = []\n",
    "#         val_rec_at = []\n",
    "#         val_hitcount = []\n",
    "        \n",
    "        # Create samples \n",
    "        n_sgd_samples = len(train_set) * self.n_iterations\n",
    "        \n",
    "        z = 0\n",
    "        self.model['train_time'] = 0\n",
    "        print('init and sampling done:', time.time() - s, 'seconds')\n",
    "        for i in range(self.n_iterations):\n",
    "            sgd_users, sgd_pos_items, sgd_neg_items = self.user_sampling(train_set, n_sgd_samples)\n",
    "        \n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            s_it = time.time()\n",
    "            it_loss = self.train(sgd_users[z*batch_size:(z+1)*batch_size], sgd_pos_items[z*batch_size:(z+1)*batch_size], sgd_neg_items[z*batch_size:(z+1)*batch_size])\n",
    "            \n",
    "            if z > 0:\n",
    "                self.update_alpha(it_loss)\n",
    "            \n",
    "            z += 1\n",
    "            self.model['loss_list'].append(it_loss) \n",
    "\n",
    "#             rec_at, prec_at, hitcount = self.eval(val_set, val_rank)\n",
    "            t_it = time.time()- s_it\n",
    "            self.model['train_time'] += t_it\n",
    "            print('batch:', z, ' loss:', round(it_loss,4), 'iteration time:', round(t_it/2,2))#, ' val prec@' + str(val_rank), ':', round(prec_at,5), ' val rec@' + str(val_rank), ':', round(rec_at,5), '  Hits:', hitcount)#'  alpha:', self.alpha)\n",
    "    \n",
    "#             val_prec_at.append(prec_at)\n",
    "#             val_rec_at.append(rec_at)\n",
    "#             val_hitcount.append(hitcount)\n",
    "            \n",
    "#         self.model['val_prec_at'] = val_prec_at\n",
    "#         self.model['val_rec_at'] = val_rec_at\n",
    "#         self.model['val_hitcount'] = val_hitcount\n",
    "        \n",
    "        \n",
    "    def create_matrices(self, data):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(self.total_users, self.total_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1                 \n",
    "        return m, m_ones\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def user_sampling(self, data, n_samples):\n",
    "        train_ratings, train_ones = self.create_matrices(train_set)\n",
    "        user_items = train_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        train_users  = train_set.new_user_id.unique()\n",
    "        train_items = train_set.new_item_id.unique()\n",
    "        \n",
    "        sgd_users, sgd_pos_items, sgd_neg_items = [], [], []\n",
    "        for sample in range(n_samples):\n",
    "            u = np.random.choice(train_users)\n",
    "            i = random.choice(user_items[u])\n",
    "\n",
    "            j = int(np.random.choice(train_items)) # neg item\n",
    "#             j_v = int(train_ones[u,j]) # Value, NEEDED?\n",
    "\n",
    "            while j in user_items[u]: # j cannot be the same item or an item with a 1\n",
    "                j = int(np.random.choice(train_items))\n",
    "#                 j_v = int(train_ones[u,j])\n",
    "            \n",
    "            sgd_users.append(u)\n",
    "            sgd_pos_items.append(i)\n",
    "            sgd_neg_items.append(j)\n",
    "            \n",
    "        return sgd_users, sgd_pos_items, sgd_neg_items\n",
    "        \n",
    "    def train(self, users, pos_items, neg_items):\n",
    "        for u, i, j in zip(users, pos_items, neg_items):\n",
    "            pos_item_pred = self.model['b'][i] + np.dot(self.model['p'][u], self.model['q'][i].T)\n",
    "            neg_item_pred = self.model['b'][j] + np.dot(self.model['p'][u], self.model['q'][j].T)\n",
    "            diff = pos_item_pred - neg_item_pred\n",
    "\n",
    "            loss_value = - np.log(self.sigmoid(diff)) #NEGATIVE?\n",
    "            regulariser = self.reg_user * np.dot(self.model['p'][u], self.model['p'][u]) + self.reg_item * np.dot(self.model['q'][i],self.model['q'][i]) + self.reg_item/10 * np.dot(self.model['q'][j], self.model['q'][j]) + self.reg_bias * (self.model['b'][i]**2 + self.model['b'][j]**2) \n",
    "            it_loss = loss_value + regulariser\n",
    "\n",
    "            diff_deriv = self.sigmoid(- diff)\n",
    "            \n",
    "            #SGD update\n",
    "            for f in range(self.nolf): # update each factor (see notes for derivatives)\n",
    "                self.model['p'][u,f] += self.alpha * (diff_deriv * (self.model['q'][i,f] - self.model['q'][j,f]) - self.reg_user * self.model['p'][u,f])\n",
    "                self.model['q'][i,f] += self.alpha * (diff_deriv * self.model['p'][u,f] - self.reg_item * self.model['q'][i,f])\n",
    "                self.model['q'][j,f] += self.alpha * (diff_deriv * (-self.model['p'][u,f]) - self.reg_item / 10 * self.model['q'][j,f])\n",
    "                self.model['b'][i] += self.alpha * (diff_deriv * self.reg_bias * self.model['b'][i])\n",
    "                self.model['b'][j] += self.alpha * (- diff_deriv * (- self.reg_bias) * self.model['b'][j])\n",
    "\n",
    "#                 it_loss += self.reg_user * self.model['p'][u,f] * self.model['p'][u,f] + self.reg_item * self.model['q'][i,f] * self.model['q'][i,f] + self.reg_item * self.model['q'][j,f] * self.model['q'][j,f]\n",
    "        return it_loss\n",
    "        \n",
    "    def update_alpha(self, it_loss):\n",
    "        last_loss = self.model['loss_list'][-1]\n",
    "        if(last_loss < it_loss): #bold driver\n",
    "            self.alpha = 0.5 * self.alpha\n",
    "            return\n",
    "        \n",
    "        self.alpha = (1 - self.alpha_decay) * self.alpha\n",
    "        self.model['learning_rate'].append(self.alpha)\n",
    "        \n",
    "    def eval(self, val_set, max_rank):\n",
    "        import eval_rank\n",
    "        val_ratings, val_ones = create_matrices(val_set, self.total_users, self.total_items)\n",
    "        result = self.model\n",
    "        users = val_set.new_user_id.unique()\n",
    "        items = val_set.new_item_id.unique()\n",
    "\n",
    "        s = time.time()\n",
    "        rank_at = max_rank\n",
    "        mp_splits = 4\n",
    "        users_split = np.array_split(users, mp_splits)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = mp.Pool(processes = mp_splits)\n",
    "            ranked = pool.map(eval_rank.eval_rank, [[result, users_split[0], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[1], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[2], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[3], items, val_ones, rank_at]])\n",
    "            pool.close()\n",
    "\n",
    "            ranked_df = pd.DataFrame()\n",
    "\n",
    "            for i in range(mp_splits):\n",
    "                ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "\n",
    "            t = time.time() - s\n",
    "            hitcount = 0\n",
    "            for u in ranked_df.index:\n",
    "                hitcount += len(set(ranked_df.loc[u]['true_id']) & set(ranked_df.loc[u]['pred_items_ranked']))\n",
    "\n",
    "            prec_at =  hitcount / (len(ranked_df) * rank_at)\n",
    "            rec_at = hitcount / (len(ranked_df) * len(ranked_df.loc[0]['true_id']))\n",
    "            \n",
    "            return prec_at, rec_at, hitcount\n",
    "#             print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
