{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import calc_vector\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data\n",
    "# file_name = 'amazon_clothing_shoes_jewelry_data' \n",
    "\n",
    "#2m user above 5 ratings\n",
    "# file_name = 'amazon_csj_2m'\n",
    "\n",
    "#0.63m user above 5 ratings\n",
    "# file_name = 'df_amazon_csj_with_styles_0.63m_u_above_5_rui' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data\n",
    "# file_name = '25m_ml'\n",
    "\n",
    "# 2m subset\n",
    "file_name = '2m-ml'\n",
    "# With 3.0 as rating threshold for a 1\n",
    "# file_name = '2m-ml_3_r_thres'\n",
    "# 0.7m subset\n",
    "# file_name = 'ml_0.7_u_above_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7511868</th>\n",
       "      <td>48786</td>\n",
       "      <td>5218</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1252520796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648248</th>\n",
       "      <td>11003</td>\n",
       "      <td>8961</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1467192135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13591401</th>\n",
       "      <td>87980</td>\n",
       "      <td>7261</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1117066110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341601</th>\n",
       "      <td>9040</td>\n",
       "      <td>858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1007862875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23660300</th>\n",
       "      <td>153635</td>\n",
       "      <td>34405</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1289255124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user   item  rating   timestamp  verified\n",
       "7511868    48786   5218     2.5  1252520796         1\n",
       "1648248    11003   8961     3.5  1467192135         1\n",
       "13591401   87980   7261     3.5  1117066110         1\n",
       "1341601     9040    858     4.0  1007862875         1\n",
       "23660300  153635  34405     5.0  1289255124         1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Data/'\n",
    "df = pd.read_pickle(path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "First filtering active users and rated items with x or more ratings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting rating threshold of 3 and above for a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_thres = 3.0\n",
    "def rating_thres(x):\n",
    "    return 1 if x >= 3.0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified'] = df['rating'].apply(rating_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_thres = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['#ratings'] = df.groupby('user')['user'].transform('count')\n",
    "# df = df[df['#ratings'] >= user_thres].drop(columns=['#ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = df.groupby('user')['rating'].count()\n",
    "item_ratings = df.groupby('item')['rating'].count()\n",
    "norpu = user_ratings.mean()\n",
    "norpi = item_ratings.mean()\n",
    "total_users = df.user.unique().size\n",
    "total_items = df.item.unique().size\n",
    "sparseness = 1 - len(df) / (len(df['user'].unique()) * len(df['item'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows  1974692 \n",
      "#ratings 1974692 \n",
      "#ratings/user 20.02 \n",
      "#ratings/item 66.04 \n",
      "average rating 3.52 \n",
      "#users  98626 \n",
      "#items  29903 \n",
      "sparse  0.99933 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('rows ', len(df), '\\n#ratings', len(df[df['rating'] != 0]), '\\n#ratings/user', round(norpu,2), '\\n#ratings/item', round(norpi,2), '\\naverage rating', \"{0:.2f}\".format(np.average(df['rating'])), '\\n#users ', df['user'].unique().size, '\\n#items ', df['item'].unique().size, '\\nsparse ', round(sparseness,5), '%')\n",
    "\n",
    "df.hist(column='rating', bins=5, grid=False)\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.xticks(range(1,6))\n",
    "plt.savefig('Plots/Deliverables/rating_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(item_ratings, bins = 1000)\n",
    "plt.xlim([0,100])\n",
    "plt.title('#ratings per item distribution (1000 bins)')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_item_dist_ml')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(user_ratings, bins = 1000)\n",
    "plt.xlim([0,30])\n",
    "plt.title('#ratings per user distribution (1000 bins)')\n",
    "plt.xlabel('Users')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('Plots/Deliverables/#ratings_per_user_dist_ml')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data #row:  1974692\n"
     ]
    }
   ],
   "source": [
    "def transform(df):\n",
    "    items = df['item'].unique()\n",
    "    itemsDF = pd.DataFrame(data=items, columns=['original_item_id'])\n",
    "    itemsDF['new_item_id'] = itemsDF.index\n",
    "\n",
    "    users = df['user'].unique()\n",
    "    usersDF = pd.DataFrame(data=users, columns=['original_user_id'])\n",
    "    usersDF['new_user_id'] = usersDF.index\n",
    "\n",
    "    ratingDF = df.merge(itemsDF, left_on='item', right_on='original_item_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_item_id'])\n",
    "\n",
    "    ratingDF = ratingDF.merge(usersDF, left_on='user', right_on='original_user_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_user_id'])\n",
    "\n",
    "    df_new_ids = ratingDF\n",
    "    print('Full data #row: ', df_new_ids.shape[0])\n",
    "    \n",
    "    return df_new_ids\n",
    "\n",
    "df_new_ids = transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave item out train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_x_out(full_data, leave_out):\n",
    "    # Input: data must be formatted by func: tranfsorm\n",
    "    # Output: full_data = without all entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('new_user_id')['index'].apply(list)\n",
    "    index_to_drop = []\n",
    "    \n",
    "    for indices in user_items_ind:\n",
    "        if len(indices) > leave_out:\n",
    "            for to_leave_out in range(leave_out):\n",
    "                index = indices[- to_leave_out]\n",
    "                index_to_drop.append(index)\n",
    "    \n",
    "    leave_one_out_set = full_data.loc[index_to_drop]\n",
    "    full_data_leave_one_out = full_data.drop(index_to_drop)\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_one_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrices(data, n_users, n_items):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1\n",
    "                               \n",
    "        return m, m_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = leave_x_out(df_new_ids, 2)\n",
    "val_set, test_set = leave_x_out(test_set, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave users out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_users_out(full_data, leave_out):\n",
    "    full_data['index'] = full_data.index\n",
    "    user_index_df = full_data.groupby('new_user_id')['index'].apply(list)\n",
    "    users = np.random.choice(list(user_index_df.index), leave_out, replace=False)\n",
    "    users_indices = []\n",
    "    \n",
    "    for user in users:\n",
    "        users_indices.extend(user_index_df.loc[user])\n",
    "    \n",
    "    sub_set = full_data.loc[users_indices]\n",
    "    remaining = full_data.drop(users_indices)\n",
    "    \n",
    "    return remaining.drop(columns=['index']), sub_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = leave_users_out(df_new_ids, 2000)\n",
    "val_set, test_set = leave_users_out(test_set, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking\n",
    "- Paper: https://arxiv.org/pdf/1205.2618.pdf\n",
    "- Code:  https://github.com/valerystrizh/bpr/blob/master/BPR.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_iterations = params['n_iterations']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg_user = params['reg_user']\n",
    "        self.reg_item = params['reg_item']\n",
    "        self.reg_bias = params['reg_bias']\n",
    "        self.alpha_decay = self.alpha / self.n_iterations\n",
    "        self.model = {}\n",
    "        \n",
    "    def fit(self, train_set, val_set, val_rank):\n",
    "        #Init\n",
    "        s = time.time()\n",
    "        p = np.random.normal(0, .1, (self.total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (self.total_items, self.nolf))  # items\n",
    "        b_item = np.zeros(self.total_items)\n",
    "        \n",
    "        train_ratings, train_ones = self.create_matrices(train_set)\n",
    "        user_items = train_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        train_users  = train_set.new_user_id.unique()\n",
    "        train_items = train_set.new_item_id.unique()\n",
    "        \n",
    "        loss_list = []\n",
    "        alphas = []\n",
    "        val_prec_at = []\n",
    "        val_rec_at = []\n",
    "        val_hitcount = []\n",
    "        \n",
    "        for iteration in range(self.n_iterations):\n",
    "            it_loss = 0\n",
    "            for sample in range(len(train_set)):\n",
    "                u = int(np.random.choice(train_users))\n",
    "                u_items = user_items[u]\n",
    "                i = random.choice(u_items)\n",
    "                j = int(np.random.choice(train_items)) # neg item\n",
    "                \n",
    "                while j in u_items: # j cannot be the same item or an item with a 1\n",
    "                    j = int(np.random.choice(train_items))\n",
    "\n",
    "                pos_item_pred = b_item[i] + np.dot(p[u], q[i].T)\n",
    "                neg_item_pred = b_item[j] + np.dot(p[u], q[j].T)\n",
    "                diff = pos_item_pred - neg_item_pred\n",
    "\n",
    "                loss_value = - np.log(self.sigmoid(diff)) #NEGATIVE?\n",
    "                regulariser = self.reg_user * np.dot(p[u], p[u]) + self.reg_item * np.dot(q[i],q[i]) + self.reg_item/10 * np.dot(q[j], q[j]) + self.reg_bias * (b_item[i]**2 + b_item[j]**2) \n",
    "                it_loss += loss_value + regulariser\n",
    "\n",
    "                diff_deriv = self.sigmoid(- diff)\n",
    "\n",
    "                for f in range(self.nolf): # update each factor (see notes for derivatives)\n",
    "                    p[u,f] += self.alpha * (diff_deriv * (q[i,f] - q[j,f]) - self.reg_user * p[u,f])\n",
    "                    q[i,f] += self.alpha * (diff_deriv * p[u,f] - self.reg_item * q[i,f])\n",
    "                    q[j,f] += self.alpha * (diff_deriv * (-p[u,f]) - self.reg_item / 10 * q[j,f])\n",
    "                \n",
    "#                 b_item[i] += self.alpha * (diff_deriv - self.reg_bias * b_item[i])\n",
    "#                 b_item[j] += self.alpha * (- diff_deriv - self.reg_bias / 10 * b_item[j])\n",
    "\n",
    "#                     it_loss += self.reg_user * p[u,f] * p[u,f] + self.reg_item * q[i,f] * q[i,f] + self.reg_item * q[j,f] * q[j,f]\n",
    "            self.model['p'] = p\n",
    "            self.model['q'] = q\n",
    "            self.model['b'] = b_item\n",
    "#             rec_at, prec_at, hitcount = self.eval(val_set, val_rank)\n",
    "            print('iteration:', iteration, ' loss:', round(it_loss,2))#, ' val prec@' + str(val_rank), ':', round(prec_at,5), ' val rec@' + str(val_rank), ':', round(rec_at,5), '  Hits:', hitcount)#'  alpha:', self.alpha)\n",
    "            \n",
    "            if iteration > 0:\n",
    "                self.update_alpha(loss_list[-1], it_loss)\n",
    "                \n",
    "            alphas.append(self.alpha)\n",
    "            loss_list.append(it_loss)\n",
    "#             val_prec_at.append(prec_at)\n",
    "#             val_rec_at.append(rec_at)\n",
    "#             val_hitcount.append(hitcount)\n",
    "        \n",
    "        t = time.time() - s\n",
    "        self.model['train_loss'] = loss_list\n",
    "        self.model['learning_rate'] = alphas\n",
    "        self.model['train_time'] = t\n",
    "        self.model['val_prec_at'] = val_prec_at\n",
    "        self.model['val_rec_at'] = val_rec_at\n",
    "        self.model['val_hitcount'] = val_hitcount\n",
    "        \n",
    "        \n",
    "    def create_matrices(self, data):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(self.total_users, self.total_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1                 \n",
    "        return m, m_ones\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def update_alpha(self, last_loss, it_loss):\n",
    "        if(last_loss < it_loss): #bold driver\n",
    "            self.alpha = 0.5 * self.alpha\n",
    "            return\n",
    "        \n",
    "        self.alpha = (1 - self.alpha_decay) * self.alpha\n",
    "        \n",
    "    def eval(self, val_set, max_rank):\n",
    "        import eval_rank\n",
    "        val_ratings, val_ones = create_matrices(val_set, self.total_users, self.total_items)\n",
    "        result = self.model\n",
    "        users = val_set.new_user_id.unique()\n",
    "        items = val_set.new_item_id.unique()\n",
    "\n",
    "        s = time.time()\n",
    "        rank_at = max_rank\n",
    "        mp_splits = 4\n",
    "        users_split = np.array_split(users, mp_splits)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = mp.Pool(processes = mp_splits)\n",
    "            ranked = pool.map(eval_rank.eval_rank, [[result, users_split[0], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[1], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[2], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[3], items, val_ones, rank_at]])\n",
    "            pool.close()\n",
    "\n",
    "            ranked_df = pd.DataFrame()\n",
    "\n",
    "            for i in range(mp_splits):\n",
    "                ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "\n",
    "            t = time.time() - s\n",
    "            hitcount = 0\n",
    "            for u in ranked_df.index:\n",
    "                hitcount += len(set(ranked_df.loc[u]['true_id']) & set(ranked_df.loc[u]['pred_items_ranked']))\n",
    "\n",
    "            prec_at =  hitcount / (len(ranked_df) * rank_at)\n",
    "            rec_at = hitcount / (len(ranked_df) * len(ranked_df.loc[0]['true_id']))\n",
    "            \n",
    "            return prec_at, rec_at, hitcount\n",
    "#             print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_iterations\":20, #around 30 is sufficient\n",
    "\"alpha\":0.08, # Learning rate\n",
    "          \n",
    "#Regularizers, still tweaking the values\n",
    "\"reg_user\":0.1,\n",
    "\"reg_item\":0.1,\n",
    "\"reg_bias\":0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2m-ml'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0  loss: 1276927.85\n",
      "iteration: 1  loss: 1247616.07\n",
      "iteration: 2  loss: 981486.6\n",
      "iteration: 3  loss: 759244.55\n",
      "iteration: 4  loss: 686151.98\n",
      "iteration: 5  loss: 660573.04\n",
      "iteration: 6  loss: 649731.48\n",
      "iteration: 7  loss: 644348.29\n",
      "iteration: 8  loss: 641505.38\n",
      "iteration: 9  loss: 638507.19\n",
      "iteration: 10  loss: 636824.42\n",
      "iteration: 11  loss: 635322.39\n",
      "iteration: 12  loss: 634584.84\n",
      "iteration: 13  loss: 634180.61\n",
      "iteration: 14  loss: 633276.33\n",
      "iteration: 15  loss: 632570.04\n",
      "iteration: 16  loss: 632291.79\n",
      "iteration: 17  loss: 632133.82\n",
      "iteration: 18  loss: 632741.84\n",
      "iteration: 19  loss: 630836.41\n"
     ]
    }
   ],
   "source": [
    "model_BPR = BPR(total_users, total_items, params)\n",
    "model_BPR.fit(train_set, val_set, 20)\n",
    "results = model_BPR.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(results, log_path, res_name, file_name):\n",
    "        result_info = {'train_loss': results['train_loss'], 'train_speed': results['train_time'], 'lr':results['learning_rate'], 'file':file_name}\n",
    "        other_info = {'b': results['b'], 'p':results['p'], 'q':results['q']} #'train_size':train_size, 'test_size':test_size, 'val_size':val_size}\n",
    "        final_log = dict(result_info, **params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results added\n"
     ]
    }
   ],
   "source": [
    "log_path = 'Results/BPR/'\n",
    "res_name = 'all_BPR_res'\n",
    "store_results(results, log_path, res_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_pickle(log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>lr</th>\n",
       "      <th>file</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_iterations</th>\n",
       "      <th>alpha</th>\n",
       "      <th>reg_user</th>\n",
       "      <th>reg_item</th>\n",
       "      <th>reg_bias</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1041327.7181980582, 983585.2541277763, 925064...</td>\n",
       "      <td>11091.973832</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>amazon_csj_2m</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.5744556755559315, -0.12968364295707485, -0...</td>\n",
       "      <td>[[0.0029188887467819138, -0.13482579685206106,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[309265.14381085814, 292752.2765175044, 273525...</td>\n",
       "      <td>4443.041277</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>df_amazon_csj_with_styles_0.63m_u_above_5_rui</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.060173608051981076, -0.3564972054359648, 0...</td>\n",
       "      <td>[[0.11844427469006483, -0.17929419274963204, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1241375.5402842462, 633604.9694529951, 468382...</td>\n",
       "      <td>18736.577080</td>\n",
       "      <td>[0.08, 0.07978666666666666, 0.0795739022222222...</td>\n",
       "      <td>2m-ml</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.033471121024971615, -0.2902192839575998, 0...</td>\n",
       "      <td>[[-0.19170825541845965, 0.3181363957948458, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[411104.40277496673, 354006.8112705361, 268678...</td>\n",
       "      <td>4303.921962</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>ml_0.7_u_above_5</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[-0.5525214346704977, 0.21174521541499766, -0...</td>\n",
       "      <td>[[-0.05786146334049641, 0.09695000367698393, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[319326.7272305316, 283297.45000489795, 229991...</td>\n",
       "      <td>3869.142029</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>ml_0.7_u_above_5_3_r_thres</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.11574940040550882, -0.4785672237389483, -0...</td>\n",
       "      <td>[[-0.04492450875335416, -0.04727986252057235, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1021380.4201729958, 519238.8191915321, 364879...</td>\n",
       "      <td>10878.254489</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>2m-ml_3_r_thres</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[-0.0340469185918828, -0.5993586798552621, -0...</td>\n",
       "      <td>[[0.65838825165359, -0.7817035209700743, 0.213...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[169437.9191571808, 150467.70098369857, 147363...</td>\n",
       "      <td>3284.115248</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>ml_0.7_u_above_5_3_r_thres</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.3976236180340462, 0.17453690053484575, 0.3...</td>\n",
       "      <td>[[-0.08620392062787273, -0.19538987335503893, ...</td>\n",
       "      <td>[0.0, -2.805510907465008, -2.002299043886927, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[356506.5256515709, 316841.34818833385, 307975...</td>\n",
       "      <td>8956.975783</td>\n",
       "      <td>[0.1, 0.09966666666666668, 0.09933444444444446...</td>\n",
       "      <td>2m-ml_3_r_thres</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.15943060190887007, 0.07132606657232936, 0....</td>\n",
       "      <td>[[1.3327906230503868, -0.2915533556208581, -0....</td>\n",
       "      <td>[-2.2935566694138876, 0.0, -0.3828441170158684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1144295.3231575612, 603327.7988461375, 435003...</td>\n",
       "      <td>18180.674521</td>\n",
       "      <td>[0.08, 0.07978666666666666, 0.0795739022222222...</td>\n",
       "      <td>2m-ml</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.6778299230970914, 0.17604384450480873, 0.6...</td>\n",
       "      <td>[[0.1461011483956811, 0.013774337675409202, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1276927.8508763094, 1247616.0736636545, 98148...</td>\n",
       "      <td>8312.766355</td>\n",
       "      <td>[0.08, 0.07968, 0.07936128, 0.0790438348800000...</td>\n",
       "      <td>2m-ml</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[[0.21295729920007836, 0.18800521483229088, 0....</td>\n",
       "      <td>[[0.09272121236242736, 0.17227121634094736, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train_loss   train_speed  \\\n",
       "0  [1041327.7181980582, 983585.2541277763, 925064...  11091.973832   \n",
       "1  [309265.14381085814, 292752.2765175044, 273525...   4443.041277   \n",
       "2  [1241375.5402842462, 633604.9694529951, 468382...  18736.577080   \n",
       "3  [411104.40277496673, 354006.8112705361, 268678...   4303.921962   \n",
       "4  [319326.7272305316, 283297.45000489795, 229991...   3869.142029   \n",
       "5  [1021380.4201729958, 519238.8191915321, 364879...  10878.254489   \n",
       "6  [169437.9191571808, 150467.70098369857, 147363...   3284.115248   \n",
       "7  [356506.5256515709, 316841.34818833385, 307975...   8956.975783   \n",
       "8  [1144295.3231575612, 603327.7988461375, 435003...  18180.674521   \n",
       "9  [1276927.8508763094, 1247616.0736636545, 98148...   8312.766355   \n",
       "\n",
       "                                                  lr  \\\n",
       "0  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "1  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "2  [0.08, 0.07978666666666666, 0.0795739022222222...   \n",
       "3  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "4  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "5  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "6  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "7  [0.1, 0.09966666666666668, 0.09933444444444446...   \n",
       "8  [0.08, 0.07978666666666666, 0.0795739022222222...   \n",
       "9  [0.08, 0.07968, 0.07936128, 0.0790438348800000...   \n",
       "\n",
       "                                            file nolf n_iterations  alpha  \\\n",
       "0                                  amazon_csj_2m   20           30   0.10   \n",
       "1  df_amazon_csj_with_styles_0.63m_u_above_5_rui   20           30   0.10   \n",
       "2                                          2m-ml   20           30   0.08   \n",
       "3                               ml_0.7_u_above_5   20           30   0.10   \n",
       "4                     ml_0.7_u_above_5_3_r_thres   20           30   0.10   \n",
       "5                                2m-ml_3_r_thres   20           30   0.10   \n",
       "6                     ml_0.7_u_above_5_3_r_thres   20           30   0.10   \n",
       "7                                2m-ml_3_r_thres   20           30   0.10   \n",
       "8                                          2m-ml   20           30   0.08   \n",
       "9                                          2m-ml   20           20   0.08   \n",
       "\n",
       "   reg_user  reg_item  reg_bias  \\\n",
       "0      0.01      0.01      0.01   \n",
       "1      0.01      0.01      0.01   \n",
       "2      0.01      0.01      0.01   \n",
       "3      0.01      0.01      0.01   \n",
       "4      0.01      0.01      0.01   \n",
       "5      0.01      0.01      0.01   \n",
       "6      0.01      0.01      0.01   \n",
       "7      0.01      0.01      0.01   \n",
       "8      0.01      0.01      0.01   \n",
       "9      0.10      0.10      0.01   \n",
       "\n",
       "                                                   p  \\\n",
       "0  [[0.5744556755559315, -0.12968364295707485, -0...   \n",
       "1  [[0.060173608051981076, -0.3564972054359648, 0...   \n",
       "2  [[0.033471121024971615, -0.2902192839575998, 0...   \n",
       "3  [[-0.5525214346704977, 0.21174521541499766, -0...   \n",
       "4  [[0.11574940040550882, -0.4785672237389483, -0...   \n",
       "5  [[-0.0340469185918828, -0.5993586798552621, -0...   \n",
       "6  [[0.3976236180340462, 0.17453690053484575, 0.3...   \n",
       "7  [[0.15943060190887007, 0.07132606657232936, 0....   \n",
       "8  [[0.6778299230970914, 0.17604384450480873, 0.6...   \n",
       "9  [[0.21295729920007836, 0.18800521483229088, 0....   \n",
       "\n",
       "                                                   q  \\\n",
       "0  [[0.0029188887467819138, -0.13482579685206106,...   \n",
       "1  [[0.11844427469006483, -0.17929419274963204, -...   \n",
       "2  [[-0.19170825541845965, 0.3181363957948458, 0....   \n",
       "3  [[-0.05786146334049641, 0.09695000367698393, 0...   \n",
       "4  [[-0.04492450875335416, -0.04727986252057235, ...   \n",
       "5  [[0.65838825165359, -0.7817035209700743, 0.213...   \n",
       "6  [[-0.08620392062787273, -0.19538987335503893, ...   \n",
       "7  [[1.3327906230503868, -0.2915533556208581, -0....   \n",
       "8  [[0.1461011483956811, 0.013774337675409202, -0...   \n",
       "9  [[0.09272121236242736, 0.17227121634094736, -0...   \n",
       "\n",
       "                                                   b  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  [0.0, -2.805510907465008, -2.002299043886927, ...  \n",
       "7  [-2.2935566694138876, 0.0, -0.3828441170158684...  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = len(df_res['train_loss']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['train_loss'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['lr'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings, test_ones = create_matrices(test_set, total_users, total_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ratings, test_ones = create_matrices(val_set, total_users, total_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98626"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set.new_user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.029275699456532\n"
     ]
    }
   ],
   "source": [
    "import eval_rank\n",
    "result = {'b':list(df_res['b'])[last], 'p':list(df_res['p'])[last], 'q':list(df_res['q'])[last]}\n",
    "users = test_set.new_user_id.unique()\n",
    "items = test_set.new_item_id.unique()\n",
    "\n",
    "s = time.time()\n",
    "rank_at = 20\n",
    "mp_splits = 4\n",
    "users_split = np.array_split(users, mp_splits)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    pool = mp.Pool(processes = mp_splits)\n",
    "    ranked = pool.map(eval_rank.eval_rank, [[result, users_split[0], items, test_ones, rank_at], \n",
    "                                            [result, users_split[1], items, test_ones, rank_at], \n",
    "                                            [result, users_split[2], items, test_ones, rank_at], \n",
    "                                            [result, users_split[3], items, test_ones, rank_at]])\n",
    "    pool.close()\n",
    "    \n",
    "    ranked_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(mp_splits):\n",
    "        ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "        \n",
    "    t = time.time() - s\n",
    "    print(t/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 10, 15, 20]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_at: 1   Hits: 525\n",
      "rank_at: 5   Hits: 1074\n",
      "rank_at: 10   Hits: 2591\n",
      "rank_at: 15   Hits: 3048\n",
      "rank_at: 20   Hits: 3424\n"
     ]
    }
   ],
   "source": [
    "hitcounts = []\n",
    "recs_at = []\n",
    "precs_at = []\n",
    "for rank in ranks_at:\n",
    "    hitcount = 0\n",
    "    for u in ranked_df.index:\n",
    "        hitcount +=  len(set(ranked_df.loc[u]['true_id'][0]) & set(ranked_df.loc[u]['pred_items_ranked'][:rank]))\n",
    "                    \n",
    "    prec_at = hitcount / rank / len(ranked_df)\n",
    "    rec_at = hitcount / len(ranked_df.loc[0]['true_id']) / len(ranked_df)\n",
    "    \n",
    "    print('rank_at:', rank, '  Hits:', hitcount)\n",
    "    hitcounts.append(hitcount)                     \n",
    "    recs_at.append(rec_at)\n",
    "    precs_at.append(prec_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_at: 1   Hits: 1185\n",
    "# rank_at: 5   Hits: 4218\n",
    "# rank_at: 10   Hits: 7687\n",
    "# rank_at: 15   Hits: 11209\n",
    "# rank_at: 20   Hits: 14630\n",
    "\n",
    "# 2m-ml without bias\n",
    "# rank_at: 1   Hits: 120\n",
    "# rank_at: 5   Hits: 1022\n",
    "# rank_at: 10   Hits: 2101\n",
    "# rank_at: 15   Hits: 3150\n",
    "# rank_at: 20   Hits: 4152\n",
    "\n",
    "# 2m-ml with bias\n",
    "# rank_at: 1   Hits: 207\n",
    "# rank_at: 5   Hits: 1114\n",
    "# rank_at: 10   Hits: 2365\n",
    "# rank_at: 15   Hits: 3647\n",
    "# rank_at: 20   Hits: 4653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_csj_2m</th>\n",
       "      <th>df_amazon_csj_with_styles_0.63m_u_above_5_rui</th>\n",
       "      <th>2m-ml</th>\n",
       "      <th>ml_0.7_u_above_5</th>\n",
       "      <th>rank_at</th>\n",
       "      <th>ranks_at</th>\n",
       "      <th>ml_0.7_u_above_5_3_r_thres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109</td>\n",
       "      <td>438</td>\n",
       "      <td>1185</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7254</td>\n",
       "      <td>2562</td>\n",
       "      <td>4218</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12671</td>\n",
       "      <td>4976</td>\n",
       "      <td>7687</td>\n",
       "      <td>712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16373</td>\n",
       "      <td>6789</td>\n",
       "      <td>11209</td>\n",
       "      <td>1069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19430</td>\n",
       "      <td>8567</td>\n",
       "      <td>14630</td>\n",
       "      <td>1470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazon_csj_2m  df_amazon_csj_with_styles_0.63m_u_above_5_rui  2m-ml  \\\n",
       "0           1109                                            438   1185   \n",
       "1           7254                                           2562   4218   \n",
       "2          12671                                           4976   7687   \n",
       "3          16373                                           6789  11209   \n",
       "4          19430                                           8567  14630   \n",
       "\n",
       "   ml_0.7_u_above_5 rank_at  ranks_at  ml_0.7_u_above_5_3_r_thres  \n",
       "0                55     NaN         1                          77  \n",
       "1               315     NaN         5                         390  \n",
       "2               712     NaN        10                         834  \n",
       "3              1069     NaN        15                        1240  \n",
       "4              1470     NaN        20                        1700  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_results = pd.read_pickle('Results/BPR/bpr_hitcounts')\n",
    "bpr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_results[file_name] = hitcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_results.to_pickle('Results/BPR/bpr_hitcounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_at: 1   Hits: 176\n",
    "# rank_at: 5   Hits: 1103\n",
    "# rank_at: 10   Hits: 2296\n",
    "# rank_at: 15   Hits: 3453\n",
    "# rank_at: 20   Hits: 4655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_at, precs_at)\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('precision@')\n",
    "plt.title('Precision for different rank values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_at, recs_at)\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('recall@')\n",
    "plt.title('Recall for different rank values (1 item/user)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_at, precs_at)\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('precision@')\n",
    "plt.title('Precision for different rank values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks_at, recs_at)\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('recall@')\n",
    "plt.title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df.to_pickle('Results/BPR/ranked' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df = pd.read_pickle('Results/BPR/ranked_ML_0.7m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('Data/amazon_clothing_shoes_jewelry_data')\n",
    "# users = df.user.unique()\n",
    "# to_keep = users[:300000]\n",
    "\n",
    "# user_indices = df.groupby('user')['index'].apply(list)\n",
    "# to_keep_indices = []\n",
    "# for u in user_indices[to_keep]:\n",
    "#     to_keep_indices.extend(u)\n",
    "\n",
    "# new_df = df_og.loc[to_keep_indices]\n",
    "# len(to_keep_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    \"\"\"\" All functions used to run, test, plot and store the\n",
    "    Singular Value Decomposition Model\"\"\"\n",
    "\n",
    "    def __init__(self, params, total_users, total_items):\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.alpha = params['alpha']\n",
    "        self.alpha_b = params['alpha_b']\n",
    "        self.alpha_cb = params['alpha_cb']\n",
    "        self.use_bias = params['use_bias']\n",
    "        self.use_impl_fb = params['use_impl_fb']\n",
    "        self.use_color = params['use_color']\n",
    "        self.use_weight_ver = params['use_weight_ver']\n",
    "        self.bu_reg = params['bu_reg']\n",
    "        self.bi_reg = params['bi_reg']\n",
    "        self.pu_reg = params['pu_reg']\n",
    "        self.qi_reg = params['qi_reg']\n",
    "        self.x_reg = params['x_reg']\n",
    "        self.cb_reg = params['cb_reg']\n",
    "        self.ver_weight = params['ver_weight']\n",
    "        self.stop = params['stop']\n",
    "        self.random_state = params['random_state']\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.params = params\n",
    "        self.mu = 0 \n",
    "        self.N = []\n",
    "        self.N_test = []\n",
    "        self.t = pd.DataFrame()\n",
    "        self.c = pd.DataFrame()\n",
    "        self.F = pd.DataFrame()\n",
    "\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.train_time = 0\n",
    "        self.best_model = {}\n",
    "        self.model = {}\n",
    "        self.test_results = {}\n",
    "\n",
    "    def fit(self, train_data, val_data=[], verbose=1, plot=True, plot_name=''):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.SVD(train_data=train_data, val_data=val_data, verbose=verbose, plot=plot, plot_name=plot_name)\n",
    "        return self\n",
    "\n",
    "    \n",
    "###############################################################################################\n",
    "    \n",
    "    def SVD(self, train_data, val_data, verbose, plot, plot_name):\n",
    "        \"\"\"\"The SVD algorithm with sgd\n",
    "        input: rating dataset with columns:['rating', 'user_id', 'item_id']\n",
    "        output: the resulting p, q, bi, bu matrices\"\"\"\n",
    "        self.mu = self.create_mu(train_data)\n",
    "        train_matrix = self.create_matrix(train_data, self.total_users, self.total_items)\n",
    "        \n",
    "        tuples_train = [tuple(x) for x in train_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        \n",
    "        p = np.random.normal(0, .1, (total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (total_items, self.nolf))  # items\n",
    "        \n",
    "        # user and item biases\n",
    "        b_user = np.zeros(total_users)\n",
    "        b_item = np.zeros(total_items)\n",
    "        \n",
    "        # using color (pareto split (0,1,2)) attribute bias\n",
    "        if self.use_color:\n",
    "            print('Creating F and c, for incorporating color bias')\n",
    "            self.F, self.c = self.init_color(train_data)\n",
    "\n",
    "        # implicit fb rated, not rated\n",
    "        x = np.random.normal(0, .1, (total_items, self.nolf))\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        if self.use_impl_fb:\n",
    "            print('Creating N, for incorporating implicit feedback')\n",
    "            self.N = train_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        \n",
    "        # 0.5 weight on the errors of verified = False user item combinations\n",
    "        if self.use_weight_ver:\n",
    "            i_verified = train_data.set_index(['new_user_id', 'new_item_id'])['verified']\n",
    "            i_verified = i_verified.loc[~i_verified.index.duplicated(keep='first')]\n",
    "        \n",
    "        sqrt_Nu = 0\n",
    "        cb = 0\n",
    "        rmses = []\n",
    "        val_rmses = []\n",
    "        smallest_val_rmse = 10000\n",
    "        val_rmse = \"na\"\n",
    "        start = time.time()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_sq_error = 0\n",
    "            for u, i, r_ui in tuples_train:\n",
    "                u = int(u)\n",
    "                i = int(i)\n",
    "                \n",
    "                if self.use_impl_fb:\n",
    "                    impl_fb_u = np.zeros(self.nolf)\n",
    "                    sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                    for j in self.N[u]:\n",
    "                        impl_fb_u += x[j] / sqrt_Nu\n",
    "\n",
    "                if self.use_color and epoch > 5:\n",
    "                    F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                    u_mu = self.mu + b_user[u]\n",
    "                    sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        cb += (r_uf - u_mu) * self.c[u,i][index]\n",
    "                    cb /=  sqrt_F_ui\n",
    "                        \n",
    "                if self.use_bias:   \n",
    "                    error = r_ui - ((self.mu + b_user[u] + b_item[i] + cb) + np.dot(p[u] + impl_fb_u, q[i]))\n",
    "                    if self.use_weight_ver and not i_verified[u,i]:\n",
    "                        error = self.ver_weight * error\n",
    "                    \n",
    "                    b_user[u] += self.alpha_b * (error - self.bu_reg * b_user[u])\n",
    "                    b_item[i] += self.alpha_b * (error - self.bi_reg * b_item[i])\n",
    "                else:\n",
    "                    error = r_ui - np.dot(p[u], q[i])\n",
    "\n",
    "                p[u] += self.alpha * (error * q[i] - self.pu_reg * p[u])\n",
    "                q[i] += self.alpha * (error * (p[u] + impl_fb_u) - self.qi_reg * q[i])\n",
    "                total_sq_error += np.square(error)\n",
    "            \n",
    "                if self.use_impl_fb:\n",
    "                    for j in self.N[u]:\n",
    "                        x[j] += self.alpha * (error * q[i] / sqrt_Nu - self.x_reg * x[j])\n",
    "                \n",
    "                if self.use_color and epoch > 5:\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        u_mu = self.mu + b_user[u]\n",
    "                        self.c[u,i][index] += self.alpha_cb * (error * (1/sqrt_F_ui) * (r_uf - u_mu) - self.cb_reg * self.c[u,i][index])\n",
    "                \n",
    "            rmse = np.sqrt(total_sq_error / len(tuples_train))\n",
    "            rmses.append(rmse)\n",
    "            \n",
    "            self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "            \n",
    "            # Validation\n",
    "            if len(val_data) > 0:\n",
    "                new_val_rmse = self.test(val_data, val=True)\n",
    "                val_rmses.append(new_val_rmse)\n",
    "                if new_val_rmse < smallest_val_rmse:\n",
    "                    smallest_val_rmse = new_val_rmse\n",
    "                    self.best_model = copy.deepcopy(self.model)\n",
    "                val_rmse = new_val_rmse\n",
    "                \n",
    "            # Epoch Printing\n",
    "            if epoch % verbose == 0:\n",
    "                if len(val_data) > 0:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse, ' Val_RMSE:', val_rmse)\n",
    "                else:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse)\n",
    "            \n",
    "            if self.stop and val_rmses[-2:][0] < val_rmse:\n",
    "                print('BREAK: Validation set not improving anymore')\n",
    "                break\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_rmse(rmses, val_rmses, plot_name)\n",
    "\n",
    "        self.train_time = time.time() - start\n",
    "        self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "#################################################################################################\n",
    "\n",
    "    def init_color(self, data_set):\n",
    "        self.t = data_set.groupby(['new_user_id', 'par_col2'])['new_item_id'].apply(list)\n",
    "        F = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items)\n",
    "        c = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items, random=True)\n",
    "        return F, c\n",
    "\n",
    "    def sim_items(self, x, random=False):\n",
    "        u_id = x.name[0]\n",
    "        col = x.iloc[0]\n",
    "        if random:\n",
    "            return np.random.normal(0,.1,len(self.t[u_id, col]))\n",
    "        return self.t[u_id, col]\n",
    "    \n",
    "    def create_matrix(self, X_train, n_users, n_items):\n",
    "        r = X_train['new_user_id']\n",
    "        c = X_train['new_item_id']\n",
    "        d = X_train['rating']\n",
    "        train_matrix = sparse.coo_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "    \n",
    "        return train_matrix.tocsr()\n",
    "    \n",
    "    def create_mu(self, train_set):\n",
    "        # Better mean calculation according to https://sifter.org/~simon/journal/20061211.html\n",
    "        va = train_set.groupby('new_user_id')['rating'].mean().var() #variance mean ratings users\n",
    "        vb = train_set.groupby('new_item_id')['rating'].mean().var() #variance mean ratings items\n",
    "        k = va/vb #variance proportion\n",
    "        better_mu = (train_set['rating'].mean() + train_set['rating'].sum()) / (k+len(train_set))\n",
    "        return better_mu\n",
    "    \n",
    "    def plot_rmse(self, rmse, val_rmses=[], plot_name=''):\n",
    "        plt.plot(np.arange(len(rmse)), rmse)\n",
    "        if len(val_rmses) > 0:\n",
    "            plt.plot(np.arange(len(val_rmses)), val_rmses, color='red')\n",
    "        plt.title('RMSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        if len(plot_name) > 0:\n",
    "            plt.savefig('Plots/' + plot_name + '.png')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self, test_data, val=False):\n",
    "        if not val:\n",
    "            self.test_data = test_data\n",
    "        tuples_test = [tuple(x) for x in test_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        test_matrix = self.create_matrix(test_data, self.total_users, self.total_items)\n",
    "        \n",
    "        if self.use_impl_fb and val:\n",
    "            self.N_test = self.val_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        elif self.use_impl_fb:\n",
    "            self.N_test = self.test_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "            \n",
    "        total_error = 0\n",
    "        estimates = []\n",
    "        for u, i, r_ui in tuples_test:\n",
    "            u = int(u)\n",
    "            i = int(i)\n",
    "            est = self.estimate(u, i, test_matrix, test_data)\n",
    "            estimates.append(est)\n",
    "            total_error += np.square(r_ui - est)\n",
    "        \n",
    "        rmse = np.sqrt(total_error / len(tuples_test))\n",
    "        \n",
    "        if not val:\n",
    "            self.test_results = {'rmse': rmse, 'estimates':estimates}\n",
    "            print('RMSE on test set:', self.test_results['rmse'])\n",
    "        else:\n",
    "            return rmse\n",
    "\n",
    "    def estimate(self, u, i, test_matrix, test_data):\n",
    "        est = self.mu + self.model['bu'][u] + self.model['bi'][i]\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        cb = 0\n",
    "        if u in self.train_data['new_user_id'] and i in self.train_data['new_item_id']:\n",
    "            \n",
    "            if self.use_impl_fb and u in self.N.index:\n",
    "                sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                for j in self.N[u]:   \n",
    "                    impl_fb_u += self.model['x'][j] / sqrt_Nu\n",
    "            \n",
    "            if self.use_color and (u,i) in self.model['cbu']:\n",
    "                F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                u_mu = self.mu + self.model['bu'][u]\n",
    "                sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                for index, f in enumerate(F_ui):\n",
    "                    r_uf = self.train_data[(self.train_data['new_user_id']==u) & (self.train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                    cb += (r_uf - u_mu) * self.model['cbu'][u,i][index]\n",
    "                cb /=  sqrt_F_ui\n",
    "                \n",
    "            est += cb + np.dot(self.model['p'][u] + impl_fb_u, self.model['q'][i])\n",
    "\n",
    "        return est\n",
    "    \n",
    "    def store_results(self, log_path, res_name, user_thres, item_thres):\n",
    "        train_size = round((len(self.train_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        test_size = round((len(self.test_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        val_size = round((len(self.val_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        \n",
    "        result_info = {'RMSE_test': self.test_results['rmse'], 'train_speed': round(self.train_time,2)}\n",
    "        other_info = {'u_thres': user_thres,'i_thres': item_thres, 'train_size':train_size, 'test_size':test_size, 'val_size':val_size, 'train_rmse':self.model['rmse'], 'val_rmse':self.model['val_rmse']}\n",
    "        final_log = dict(result_info, **self.params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_iterations = params['n_iterations']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg_user = params['reg_user']\n",
    "        self.reg_item = params['reg_item']\n",
    "        self.reg_bias = params['reg_bias']\n",
    "        self.alpha_decay = self.alpha / self.n_iterations\n",
    "        self.model = {'loss_list':[], 'learning_rate':[]}\n",
    "        \n",
    "    def fit(self, train_set, val_set, val_rank, batch_size=1000):\n",
    "        #Init\n",
    "        s = time.time()\n",
    "        self.model['p'] = np.random.normal(0, .1, (self.total_users, self.nolf))  # users\n",
    "        self.model['q'] = np.random.normal(0, .1, (self.total_items, self.nolf))  # items\n",
    "        self.model['b'] = np.zeros(self.total_items)\n",
    "        \n",
    "#         val_prec_at = []\n",
    "#         val_rec_at = []\n",
    "#         val_hitcount = []\n",
    "        \n",
    "        # Create samples \n",
    "        n_sgd_samples = len(train_set) * self.n_iterations\n",
    "        \n",
    "        z = 0\n",
    "        self.model['train_time'] = 0\n",
    "        print('init and sampling done:', time.time() - s, 'seconds')\n",
    "        for i in range(self.n_iterations):\n",
    "            sgd_users, sgd_pos_items, sgd_neg_items = self.user_sampling(train_set, n_sgd_samples)\n",
    "        \n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            s_it = time.time()\n",
    "            it_loss = self.train(sgd_users[z*batch_size:(z+1)*batch_size], sgd_pos_items[z*batch_size:(z+1)*batch_size], sgd_neg_items[z*batch_size:(z+1)*batch_size])\n",
    "            \n",
    "            if z > 0:\n",
    "                self.update_alpha(it_loss)\n",
    "            \n",
    "            z += 1\n",
    "            self.model['loss_list'].append(it_loss) \n",
    "\n",
    "#             rec_at, prec_at, hitcount = self.eval(val_set, val_rank)\n",
    "            t_it = time.time()- s_it\n",
    "            self.model['train_time'] += t_it\n",
    "            print('batch:', z, ' loss:', round(it_loss,4), 'iteration time:', round(t_it/2,2))#, ' val prec@' + str(val_rank), ':', round(prec_at,5), ' val rec@' + str(val_rank), ':', round(rec_at,5), '  Hits:', hitcount)#'  alpha:', self.alpha)\n",
    "    \n",
    "#             val_prec_at.append(prec_at)\n",
    "#             val_rec_at.append(rec_at)\n",
    "#             val_hitcount.append(hitcount)\n",
    "            \n",
    "#         self.model['val_prec_at'] = val_prec_at\n",
    "#         self.model['val_rec_at'] = val_rec_at\n",
    "#         self.model['val_hitcount'] = val_hitcount\n",
    "        \n",
    "        \n",
    "    def create_matrices(self, data):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(self.total_users, self.total_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1                 \n",
    "        return m, m_ones\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def user_sampling(self, data, n_samples):\n",
    "        train_ratings, train_ones = self.create_matrices(train_set)\n",
    "        user_items = train_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        train_users  = train_set.new_user_id.unique()\n",
    "        train_items = train_set.new_item_id.unique()\n",
    "        \n",
    "        sgd_users, sgd_pos_items, sgd_neg_items = [], [], []\n",
    "        for sample in range(n_samples):\n",
    "            u = np.random.choice(train_users)\n",
    "            i = random.choice(user_items[u])\n",
    "\n",
    "            j = int(np.random.choice(train_items)) # neg item\n",
    "#             j_v = int(train_ones[u,j]) # Value, NEEDED?\n",
    "\n",
    "            while j in user_items[u]: # j cannot be the same item or an item with a 1\n",
    "                j = int(np.random.choice(train_items))\n",
    "#                 j_v = int(train_ones[u,j])\n",
    "            \n",
    "            sgd_users.append(u)\n",
    "            sgd_pos_items.append(i)\n",
    "            sgd_neg_items.append(j)\n",
    "            \n",
    "        return sgd_users, sgd_pos_items, sgd_neg_items\n",
    "        \n",
    "    def train(self, users, pos_items, neg_items):\n",
    "        for u, i, j in zip(users, pos_items, neg_items):\n",
    "            pos_item_pred = self.model['b'][i] + np.dot(self.model['p'][u], self.model['q'][i].T)\n",
    "            neg_item_pred = self.model['b'][j] + np.dot(self.model['p'][u], self.model['q'][j].T)\n",
    "            diff = pos_item_pred - neg_item_pred\n",
    "\n",
    "            loss_value = - np.log(self.sigmoid(diff)) #NEGATIVE?\n",
    "            regulariser = self.reg_user * np.dot(self.model['p'][u], self.model['p'][u]) + self.reg_item * np.dot(self.model['q'][i],self.model['q'][i]) + self.reg_item/10 * np.dot(self.model['q'][j], self.model['q'][j]) + self.reg_bias * (self.model['b'][i]**2 + self.model['b'][j]**2) \n",
    "            it_loss = loss_value + regulariser\n",
    "\n",
    "            diff_deriv = self.sigmoid(- diff)\n",
    "            \n",
    "            #SGD update\n",
    "            for f in range(self.nolf): # update each factor (see notes for derivatives)\n",
    "                self.model['p'][u,f] += self.alpha * (diff_deriv * (self.model['q'][i,f] - self.model['q'][j,f]) - self.reg_user * self.model['p'][u,f])\n",
    "                self.model['q'][i,f] += self.alpha * (diff_deriv * self.model['p'][u,f] - self.reg_item * self.model['q'][i,f])\n",
    "                self.model['q'][j,f] += self.alpha * (diff_deriv * (-self.model['p'][u,f]) - self.reg_item / 10 * self.model['q'][j,f])\n",
    "                self.model['b'][i] += self.alpha * (diff_deriv * self.reg_bias * self.model['b'][i])\n",
    "                self.model['b'][j] += self.alpha * (- diff_deriv * (- self.reg_bias) * self.model['b'][j])\n",
    "\n",
    "#                 it_loss += self.reg_user * self.model['p'][u,f] * self.model['p'][u,f] + self.reg_item * self.model['q'][i,f] * self.model['q'][i,f] + self.reg_item * self.model['q'][j,f] * self.model['q'][j,f]\n",
    "        return it_loss\n",
    "        \n",
    "    def update_alpha(self, it_loss):\n",
    "        last_loss = self.model['loss_list'][-1]\n",
    "        if(last_loss < it_loss): #bold driver\n",
    "            self.alpha = 0.5 * self.alpha\n",
    "            return\n",
    "        \n",
    "        self.alpha = (1 - self.alpha_decay) * self.alpha\n",
    "        self.model['learning_rate'].append(self.alpha)\n",
    "        \n",
    "    def eval(self, val_set, max_rank):\n",
    "        import eval_rank\n",
    "        val_ratings, val_ones = create_matrices(val_set, self.total_users, self.total_items)\n",
    "        result = self.model\n",
    "        users = val_set.new_user_id.unique()\n",
    "        items = val_set.new_item_id.unique()\n",
    "\n",
    "        s = time.time()\n",
    "        rank_at = max_rank\n",
    "        mp_splits = 4\n",
    "        users_split = np.array_split(users, mp_splits)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = mp.Pool(processes = mp_splits)\n",
    "            ranked = pool.map(eval_rank.eval_rank, [[result, users_split[0], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[1], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[2], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[3], items, val_ones, rank_at]])\n",
    "            pool.close()\n",
    "\n",
    "            ranked_df = pd.DataFrame()\n",
    "\n",
    "            for i in range(mp_splits):\n",
    "                ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "\n",
    "            t = time.time() - s\n",
    "            hitcount = 0\n",
    "            for u in ranked_df.index:\n",
    "                hitcount += len(set(ranked_df.loc[u]['true_id']) & set(ranked_df.loc[u]['pred_items_ranked']))\n",
    "\n",
    "            prec_at =  hitcount / (len(ranked_df) * rank_at)\n",
    "            rec_at = hitcount / (len(ranked_df) * len(ranked_df.loc[0]['true_id']))\n",
    "            \n",
    "            return prec_at, rec_at, hitcount\n",
    "#             print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
