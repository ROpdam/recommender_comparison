{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>datetime</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18590190</th>\n",
       "      <td>120461</td>\n",
       "      <td>2501</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>2410</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590032</th>\n",
       "      <td>120461</td>\n",
       "      <td>252</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>249</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590159</th>\n",
       "      <td>120461</td>\n",
       "      <td>2069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1980</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590048</th>\n",
       "      <td>120461</td>\n",
       "      <td>440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>435</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18590145</th>\n",
       "      <td>120461</td>\n",
       "      <td>1959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-04-25 02:29:35</td>\n",
       "      <td>1870</td>\n",
       "      <td>120460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  item  rating            datetime item_id user_id\n",
       "18590190  120461  2501     5.0 2000-04-25 02:29:35    2410  120460\n",
       "18590032  120461   252     4.0 2000-04-25 02:29:35     249  120460\n",
       "18590159  120461  2069     4.0 2000-04-25 02:29:35    1980  120460\n",
       "18590048  120461   440     4.0 2000-04-25 02:29:35     435  120460\n",
       "18590145  120461  1959     4.0 2000-04-25 02:29:35    1870  120460"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep ratings above 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['rating'] > 3]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 27387\n",
      "Total users: 16254\n",
      "Number of train users: 16192\n",
      "Number of test users: 1664\n",
      "Number of validation users: 1664 \n",
      "\n",
      "Users deleted: 62\n"
     ]
    }
   ],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "total_users, total_items, train_set, val_set, test_set = \\\n",
    "train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking\n",
    "- Paper: https://arxiv.org/pdf/1205.2618.pdf\n",
    "- Code:  https://github.com/valerystrizh/bpr/blob/master/BPR.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"nolf\":20, #Size of latent feature vectors\n",
    "\"n_iterations\":2, #around 20 is sufficient\n",
    "\"sample_size\":0.0001, #0.2*len(train_set),\n",
    "\"seed\":1234,\n",
    "\"alpha\":0.1, # Learning rate\n",
    "          \n",
    "#Regularizers, still tweaking the values\n",
    "# Amazon best: 0.1\n",
    "# ML best: 0\n",
    "\"reg_user\":0.005,\n",
    "\"reg_item\":0.005,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML_01_users'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 2 samples of length 0.0001\n",
      "iteration: 0  loss: 0\n",
      "iteration: 1  loss: 0\n"
     ]
    }
   ],
   "source": [
    "from Models import BPR\n",
    "BPR_model = BPR(total_users, total_items, params)\n",
    "BPR_model.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new results created\n"
     ]
    }
   ],
   "source": [
    "log_path = path + 'Results/BPR/'\n",
    "res_name = 'BPR_models_test'\n",
    "BPR_model.store_results(log_path, res_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_pickle(log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>train_speed</th>\n",
       "      <th>lr</th>\n",
       "      <th>file</th>\n",
       "      <th>nolf</th>\n",
       "      <th>n_iterations</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>alpha</th>\n",
       "      <th>reg_user</th>\n",
       "      <th>reg_item</th>\n",
       "      <th>p</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.366361</td>\n",
       "      <td>[0.1, 0.095]</td>\n",
       "      <td>ML_01_users</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[[0.04714351637324931, -0.11909756947064645, 0...</td>\n",
       "      <td>[[0.09909888026599971, 0.10829793925804916, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_loss val_auc  train_speed            lr         file nolf  \\\n",
       "0     [0, 0]      []     3.366361  [0.1, 0.095]  ML_01_users   20   \n",
       "\n",
       "  n_iterations  sample_size  seed  alpha  reg_user  reg_item  \\\n",
       "0            2       0.0001  1234    0.1     0.005     0.005   \n",
       "\n",
       "                                                   p  \\\n",
       "0  [[0.04714351637324931, -0.11909756947064645, 0...   \n",
       "\n",
       "                                                   q  \n",
       "0  [[0.09909888026599971, 0.10829793925804916, -0...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = len(df_res['train_loss']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['train_loss'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_res['lr'][last])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import rank_predictions, get_metrics\n",
    "def final_metric(model, test_set, rank_at, steps, store_path=''):\n",
    "    m =  {'p':model.model['p'], 'q': model.model['q']}\n",
    "    ranked_df = rank_predictions(m, test_set, rank_at)\n",
    "    metrics = get_metrics(ranked_df, steps, rank_at)\n",
    "    if len(store_path) > 0:\n",
    "        metrics.to_pickle(store_path)\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = '' #path + 'Results/Results_17_04/'\n",
    "rank_at = 20\n",
    "steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking time: 1.5\n",
      "Obtaining metrics time: 1.24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_at</th>\n",
       "      <th>hitcounts</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_at  hitcounts  recall  precision\n",
       "0        1          0     0.0        0.0\n",
       "1        5          0     0.0        0.0\n",
       "2       10          0     0.0        0.0\n",
       "3       15          0     0.0        0.0\n",
       "4       20          0     0.0        0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'metrics_bpr_' + file_name\n",
    "final_metric(BPR_ml_01_rate_above_3, test_set, rank_at, steps, store_path + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['rank_at'], metrics['precision'])\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('precision@')\n",
    "plt.title('Precision for different rank values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics['rank_at'], metrics['recall'])\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('recall@')\n",
    "plt.title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "- Amazon_01_users\n",
    "- ML_01_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_get_train_test(file_path, file_name):\n",
    "    # Init \n",
    "    df = pd.read_pickle(file_path + file_name)\n",
    "    df['item_id'] = df.item.astype('category').cat.codes\n",
    "    df['user_id'] = df.user.astype('category').cat.codes\n",
    "\n",
    "    # Create Train and Test sets\n",
    "    BATCH_SIZE = 64\n",
    "    val_perc = test_perc = 0.1\n",
    "    n_last_items_val = n_last_items_test = 1\n",
    "    return train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test, stats=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_run(total_users, total_items, train_set, val_set, test_set, params, sample_perc, n_full_runs=1):\n",
    "    print('Run:', str(1) ,'/', str(n_full_runs))\n",
    "    # Model Run\n",
    "    params['sample_size'] = sample_perc*len(train_set)\n",
    "    model = BPR(total_users, total_items, params)\n",
    "    model.fit(train_set,verbose=0)\n",
    "    \n",
    "    # Evaluation\n",
    "    rank_at = 20\n",
    "    steps = 5\n",
    "    ranked_df = rank_predictions(model.model, test_set, rank_at, stats=False)\n",
    "    full_metrics = get_metrics(ranked_df, steps, rank_at, stats=False)\n",
    "    \n",
    "    for i in range(n_full_runs-1):\n",
    "        print('Run:', str(i+2) ,'/', str(n_full_runs))\n",
    "        model = BPR(total_users, total_items, params)\n",
    "        model.fit(train_set, verbose=0)\n",
    "\n",
    "        # Evaluation\n",
    "        ranked_df = rank_predictions(model.model, test_set, rank_at, stats=False)\n",
    "        full_metrics += get_metrics(ranked_df, steps, rank_at, stats=False)\n",
    "    \n",
    "    full_metrics /= n_full_runs\n",
    "    return model, full_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\"nolf\":20, # Size of latent feature vectors\n",
    "\"n_iterations\":40, # Depends on number of items and users\n",
    "\"sample_size\":1, # Adjusted in loop to sample_perc*len(train_set)\n",
    "\"seed\":0, # 0 Means no seed and samples will be drawn differently every time\n",
    "\"alpha\":0.08, # Learning rate\n",
    "          \n",
    "#Regularizers\n",
    "\"reg_user\":0.03, # should be in proportion to the number of items \n",
    "\"reg_item\":0.03,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================================================ \n",
      " Run: 1 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 2 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0.0001\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 3 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0.001\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 4 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0.01\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 5 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0.1\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 6 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 0.5\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 7 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 1\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n",
      "\n",
      " ============================================================ \n",
      " Run: 8 / 8\n",
      "File:\t\t\t ML_01_users\n",
      "Iterations:\t\t 40\n",
      "Regularisation:\t\t 1.5\n",
      "NOLF:\t\t\t 20\n",
      "Sample Percentage:\t 0.1\n",
      "Run: 1 / 10\n",
      "Run: 2 / 10\n",
      "Run: 3 / 10\n",
      "Run: 4 / 10\n",
      "Run: 5 / 10\n",
      "Run: 6 / 10\n",
      "Run: 7 / 10\n",
      "Run: 8 / 10\n",
      "Run: 9 / 10\n",
      "Run: 10 / 10\n"
     ]
    }
   ],
   "source": [
    "file_names = ['ML_01_users']\n",
    "file_paths = [path + 'Data/ML/']\n",
    "ext = 'ML'\n",
    "\n",
    "n_iterations = [40]\n",
    "regs = [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1, 1.5]\n",
    "nolfs = [20]\n",
    "sample_percs = [0.1]\n",
    "\n",
    "runs = 0\n",
    "all_runs = len(n_iterations) * len(regs) * len(nolfs) * len(sample_percs)\n",
    "\n",
    "for file_name, file_path in zip(file_names, file_paths):\n",
    "    #Get data split and variables needed for BPR\n",
    "    total_users, total_items, train_set, val_set, test_set = read_get_train_test(file_path, file_name)\n",
    "    \n",
    "    for n_iters in n_iterations:\n",
    "        params['n_iterations'] = n_iters\n",
    "        for reg in regs:\n",
    "            params['reg_user'] = reg\n",
    "            params['reg_item'] = reg\n",
    "            for nolf in nolfs:\n",
    "                params['nolf'] = nolf\n",
    "                for sample_perc in sample_percs:\n",
    "                    # Track Progress\n",
    "                    runs += 1\n",
    "                    print('\\n', '='*60, '\\n', 'Run:', runs, '/', all_runs)\n",
    "                    print('File:\\t\\t\\t', file_name)\n",
    "                    print('Iterations:\\t\\t', n_iters)\n",
    "                    print('Regularisation:\\t\\t', reg)\n",
    "                    print('NOLF:\\t\\t\\t', nolf)\n",
    "                    print('Sample Percentage:\\t', sample_perc)\n",
    "                    \n",
    "                    # Result name\n",
    "                    final_name = ext + '_' + str(n_iters) + '_' + str(nolf) + '_' + str(reg) + '_' + str(sample_perc)\n",
    "                    \n",
    "                    # Run\n",
    "                    model, metrics = full_run(total_users, total_items, train_set, val_set, test_set, params, sample_perc, 10)\n",
    "                    \n",
    "                    # Store\n",
    "                    log_path = path + 'Results/BPR/Grid_Search/'\n",
    "                    res_name = 'BPR_models'\n",
    "                    store_results(model.model, log_path, res_name, final_name, params, stats=False)\n",
    "                    metrics.to_pickle(path + 'Results/BPR/Grid_Search/metrics_' + final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 005 sample_prec = 0.2\n",
    "# Results\n",
    "#    rank_at  hitcounts    recall  precision\n",
    "# 0        1         45  0.007794   0.007794\n",
    "# 1        5        265  0.045895   0.009179\n",
    "# 2       10        339  0.058711   0.005871\n",
    "# 3       15        364  0.063041   0.004203\n",
    "# 4       20        392  0.067891   0.003395\n",
    "\n",
    "\n",
    "# 001 sample_prec = 0.5\n",
    "# Results\n",
    "#    rank_at  hitcounts    recall  precision\n",
    "# 0        1         11  0.009532   0.009532\n",
    "# 1        5         53  0.045927   0.009185\n",
    "# 2       10         70  0.060659   0.006066\n",
    "# 3       15         75  0.064991   0.004333\n",
    "# 4       20         76  0.065858   0.003293"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('Data/amazon_clothing_shoes_jewelry_data')\n",
    "# users = df.user.unique()\n",
    "# to_keep = users[:300000]\n",
    "\n",
    "# user_indices = df.groupby('user')['index'].apply(list)\n",
    "# to_keep_indices = []\n",
    "# for u in user_indices[to_keep]:\n",
    "#     to_keep_indices.extend(u)\n",
    "\n",
    "# new_df = df_og.loc[to_keep_indices]\n",
    "# len(to_keep_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard SVD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    \"\"\"\" All functions used to run, test, plot and store the\n",
    "    Singular Value Decomposition Model\"\"\"\n",
    "\n",
    "    def __init__(self, params, total_users, total_items):\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_epochs = params['n_epochs']\n",
    "        self.alpha = params['alpha']\n",
    "        self.alpha_b = params['alpha_b']\n",
    "        self.alpha_cb = params['alpha_cb']\n",
    "        self.use_bias = params['use_bias']\n",
    "        self.use_impl_fb = params['use_impl_fb']\n",
    "        self.use_color = params['use_color']\n",
    "        self.use_weight_ver = params['use_weight_ver']\n",
    "        self.bu_reg = params['bu_reg']\n",
    "        self.bi_reg = params['bi_reg']\n",
    "        self.pu_reg = params['pu_reg']\n",
    "        self.qi_reg = params['qi_reg']\n",
    "        self.x_reg = params['x_reg']\n",
    "        self.cb_reg = params['cb_reg']\n",
    "        self.ver_weight = params['ver_weight']\n",
    "        self.stop = params['stop']\n",
    "        self.random_state = params['random_state']\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.params = params\n",
    "        self.mu = 0 \n",
    "        self.N = []\n",
    "        self.N_test = []\n",
    "        self.t = pd.DataFrame()\n",
    "        self.c = pd.DataFrame()\n",
    "        self.F = pd.DataFrame()\n",
    "\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.train_time = 0\n",
    "        self.best_model = {}\n",
    "        self.model = {}\n",
    "        self.test_results = {}\n",
    "\n",
    "    def fit(self, train_data, val_data=[], verbose=1, plot=True, plot_name=''):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.SVD(train_data=train_data, val_data=val_data, verbose=verbose, plot=plot, plot_name=plot_name)\n",
    "        return self\n",
    "\n",
    "    \n",
    "###############################################################################################\n",
    "    \n",
    "    def SVD(self, train_data, val_data, verbose, plot, plot_name):\n",
    "        \"\"\"\"The SVD algorithm with sgd\n",
    "        input: rating dataset with columns:['rating', 'user_id', 'item_id']\n",
    "        output: the resulting p, q, bi, bu matrices\"\"\"\n",
    "        self.mu = self.create_mu(train_data)\n",
    "        train_matrix = self.create_matrix(train_data, self.total_users, self.total_items)\n",
    "        \n",
    "        tuples_train = [tuple(x) for x in train_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        \n",
    "        p = np.random.normal(0, .1, (total_users, self.nolf))  # users\n",
    "        q = np.random.normal(0, .1, (total_items, self.nolf))  # items\n",
    "        \n",
    "        # user and item biases\n",
    "        b_user = np.zeros(total_users)\n",
    "        b_item = np.zeros(total_items)\n",
    "        \n",
    "        # using color (pareto split (0,1,2)) attribute bias\n",
    "        if self.use_color:\n",
    "            print('Creating F and c, for incorporating color bias')\n",
    "            self.F, self.c = self.init_color(train_data)\n",
    "\n",
    "        # implicit fb rated, not rated\n",
    "        x = np.random.normal(0, .1, (total_items, self.nolf))\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        if self.use_impl_fb:\n",
    "            print('Creating N, for incorporating implicit feedback')\n",
    "            self.N = train_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        \n",
    "        # 0.5 weight on the errors of verified = False user item combinations\n",
    "        if self.use_weight_ver:\n",
    "            i_verified = train_data.set_index(['new_user_id', 'new_item_id'])['verified']\n",
    "            i_verified = i_verified.loc[~i_verified.index.duplicated(keep='first')]\n",
    "        \n",
    "        sqrt_Nu = 0\n",
    "        cb = 0\n",
    "        rmses = []\n",
    "        val_rmses = []\n",
    "        smallest_val_rmse = 10000\n",
    "        val_rmse = \"na\"\n",
    "        start = time.time()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            total_sq_error = 0\n",
    "            for u, i, r_ui in tuples_train:\n",
    "                u = int(u)\n",
    "                i = int(i)\n",
    "                \n",
    "                if self.use_impl_fb:\n",
    "                    impl_fb_u = np.zeros(self.nolf)\n",
    "                    sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                    for j in self.N[u]:\n",
    "                        impl_fb_u += x[j] / sqrt_Nu\n",
    "\n",
    "                if self.use_color and epoch > 5:\n",
    "                    F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                    u_mu = self.mu + b_user[u]\n",
    "                    sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        cb += (r_uf - u_mu) * self.c[u,i][index]\n",
    "                    cb /=  sqrt_F_ui\n",
    "                        \n",
    "                if self.use_bias:   \n",
    "                    error = r_ui - ((self.mu + b_user[u] + b_item[i] + cb) + np.dot(p[u] + impl_fb_u, q[i]))\n",
    "                    if self.use_weight_ver and not i_verified[u,i]:\n",
    "                        error = self.ver_weight * error\n",
    "                    \n",
    "                    b_user[u] += self.alpha_b * (error - self.bu_reg * b_user[u])\n",
    "                    b_item[i] += self.alpha_b * (error - self.bi_reg * b_item[i])\n",
    "                else:\n",
    "                    error = r_ui - np.dot(p[u], q[i])\n",
    "\n",
    "                p[u] += self.alpha * (error * q[i] - self.pu_reg * p[u])\n",
    "                q[i] += self.alpha * (error * (p[u] + impl_fb_u) - self.qi_reg * q[i])\n",
    "                total_sq_error += np.square(error)\n",
    "            \n",
    "                if self.use_impl_fb:\n",
    "                    for j in self.N[u]:\n",
    "                        x[j] += self.alpha * (error * q[i] / sqrt_Nu - self.x_reg * x[j])\n",
    "                \n",
    "                if self.use_color and epoch > 5:\n",
    "                    for index, f in enumerate(F_ui):\n",
    "                        r_uf = train_data[(train_data['new_user_id']==u) & (train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                        u_mu = self.mu + b_user[u]\n",
    "                        self.c[u,i][index] += self.alpha_cb * (error * (1/sqrt_F_ui) * (r_uf - u_mu) - self.cb_reg * self.c[u,i][index])\n",
    "                \n",
    "            rmse = np.sqrt(total_sq_error / len(tuples_train))\n",
    "            rmses.append(rmse)\n",
    "            \n",
    "            self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "            \n",
    "            # Validation\n",
    "            if len(val_data) > 0:\n",
    "                new_val_rmse = self.test(val_data, val=True)\n",
    "                val_rmses.append(new_val_rmse)\n",
    "                if new_val_rmse < smallest_val_rmse:\n",
    "                    smallest_val_rmse = new_val_rmse\n",
    "                    self.best_model = copy.deepcopy(self.model)\n",
    "                val_rmse = new_val_rmse\n",
    "                \n",
    "            # Epoch Printing\n",
    "            if epoch % verbose == 0:\n",
    "                if len(val_data) > 0:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse, ' Val_RMSE:', val_rmse)\n",
    "                else:\n",
    "                    print('Epoch:', epoch, '  RMSE:', rmse)\n",
    "            \n",
    "            if self.stop and val_rmses[-2:][0] < val_rmse:\n",
    "                print('BREAK: Validation set not improving anymore')\n",
    "                break\n",
    "                \n",
    "        if plot:\n",
    "            self.plot_rmse(rmses, val_rmses, plot_name)\n",
    "\n",
    "        self.train_time = time.time() - start\n",
    "        self.model = {'p': p, 'q': q, 'bu':b_user, 'bi':b_item, 'cbu': self.c, 'x':x, 'rmse':rmses, 'val_rmse':val_rmses}\n",
    "#################################################################################################\n",
    "\n",
    "    def init_color(self, data_set):\n",
    "        self.t = data_set.groupby(['new_user_id', 'par_col2'])['new_item_id'].apply(list)\n",
    "        F = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items)\n",
    "        c = data_set.groupby(['new_user_id', 'new_item_id'])['par_col2'].apply(self.sim_items, random=True)\n",
    "        return F, c\n",
    "\n",
    "    def sim_items(self, x, random=False):\n",
    "        u_id = x.name[0]\n",
    "        col = x.iloc[0]\n",
    "        if random:\n",
    "            return np.random.normal(0,.1,len(self.t[u_id, col]))\n",
    "        return self.t[u_id, col]\n",
    "    \n",
    "    def create_matrix(self, X_train, n_users, n_items):\n",
    "        r = X_train['new_user_id']\n",
    "        c = X_train['new_item_id']\n",
    "        d = X_train['rating']\n",
    "        train_matrix = sparse.coo_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "    \n",
    "        return train_matrix.tocsr()\n",
    "    \n",
    "    def create_mu(self, train_set):\n",
    "        # Better mean calculation according to https://sifter.org/~simon/journal/20061211.html\n",
    "        va = train_set.groupby('new_user_id')['rating'].mean().var() #variance mean ratings users\n",
    "        vb = train_set.groupby('new_item_id')['rating'].mean().var() #variance mean ratings items\n",
    "        k = va/vb #variance proportion\n",
    "        better_mu = (train_set['rating'].mean() + train_set['rating'].sum()) / (k+len(train_set))\n",
    "        return better_mu\n",
    "    \n",
    "    def plot_rmse(self, rmse, val_rmses=[], plot_name=''):\n",
    "        plt.plot(np.arange(len(rmse)), rmse)\n",
    "        if len(val_rmses) > 0:\n",
    "            plt.plot(np.arange(len(val_rmses)), val_rmses, color='red')\n",
    "        plt.title('RMSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        if len(plot_name) > 0:\n",
    "            plt.savefig('Plots/' + plot_name + '.png')\n",
    "        plt.show()\n",
    "\n",
    "    def test(self, test_data, val=False):\n",
    "        if not val:\n",
    "            self.test_data = test_data\n",
    "        tuples_test = [tuple(x) for x in test_data[['new_user_id', 'new_item_id', 'rating']].to_numpy()]\n",
    "        test_matrix = self.create_matrix(test_data, self.total_users, self.total_items)\n",
    "        \n",
    "        if self.use_impl_fb and val:\n",
    "            self.N_test = self.val_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        elif self.use_impl_fb:\n",
    "            self.N_test = self.test_data.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "            \n",
    "        total_error = 0\n",
    "        estimates = []\n",
    "        for u, i, r_ui in tuples_test:\n",
    "            u = int(u)\n",
    "            i = int(i)\n",
    "            est = self.estimate(u, i, test_matrix, test_data)\n",
    "            estimates.append(est)\n",
    "            total_error += np.square(r_ui - est)\n",
    "        \n",
    "        rmse = np.sqrt(total_error / len(tuples_test))\n",
    "        \n",
    "        if not val:\n",
    "            self.test_results = {'rmse': rmse, 'estimates':estimates}\n",
    "            print('RMSE on test set:', self.test_results['rmse'])\n",
    "        else:\n",
    "            return rmse\n",
    "\n",
    "    def estimate(self, u, i, test_matrix, test_data):\n",
    "        est = self.mu + self.model['bu'][u] + self.model['bi'][i]\n",
    "        impl_fb_u = np.zeros(self.nolf)\n",
    "        cb = 0\n",
    "        if u in self.train_data['new_user_id'] and i in self.train_data['new_item_id']:\n",
    "            \n",
    "            if self.use_impl_fb and u in self.N.index:\n",
    "                sqrt_Nu = np.sqrt(len(self.N[u]))\n",
    "                for j in self.N[u]:   \n",
    "                    impl_fb_u += self.model['x'][j] / sqrt_Nu\n",
    "            \n",
    "            if self.use_color and (u,i) in self.model['cbu']:\n",
    "                F_ui =  self.F[u,i] #Set of items associated with i and rated by u\n",
    "                u_mu = self.mu + self.model['bu'][u]\n",
    "                sqrt_F_ui = np.sqrt(len(F_ui))\n",
    "                for index, f in enumerate(F_ui):\n",
    "                    r_uf = self.train_data[(self.train_data['new_user_id']==u) & (self.train_data['new_item_id']==f)]['rating'].iloc[0]\n",
    "                    cb += (r_uf - u_mu) * self.model['cbu'][u,i][index]\n",
    "                cb /=  sqrt_F_ui\n",
    "                \n",
    "            est += cb + np.dot(self.model['p'][u] + impl_fb_u, self.model['q'][i])\n",
    "\n",
    "        return est\n",
    "    \n",
    "    def store_results(self, log_path, res_name, user_thres, item_thres):\n",
    "        train_size = round((len(self.train_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        test_size = round((len(self.test_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        val_size = round((len(self.val_data) / (len(self.train_data) + len(self.test_data) + len(self.val_data))),1)\n",
    "        \n",
    "        result_info = {'RMSE_test': self.test_results['rmse'], 'train_speed': round(self.train_time,2)}\n",
    "        other_info = {'u_thres': user_thres,'i_thres': item_thres, 'train_size':train_size, 'test_size':test_size, 'val_size':val_size, 'train_rmse':self.model['rmse'], 'val_rmse':self.model['val_rmse']}\n",
    "        final_log = dict(result_info, **self.params, **other_info)\n",
    "\n",
    "        if not os.path.exists(log_path + res_name):\n",
    "            df_results = pd.DataFrame(columns=final_log.keys())\n",
    "            print('new results created')\n",
    "\n",
    "        else:\n",
    "            df_results = pd.read_pickle(log_path + res_name)\n",
    "            print('results added')\n",
    "\n",
    "        df_results = df_results.append(final_log, ignore_index=True)\n",
    "        pd.to_pickle(df_results, log_path + res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR():\n",
    "    def __init__(self, total_users, total_items, params):\n",
    "        self.total_users = total_users\n",
    "        self.total_items = total_items\n",
    "        self.nolf = params['nolf']\n",
    "        self.n_iterations = params['n_iterations']\n",
    "        self.alpha = params['alpha']\n",
    "        self.reg_user = params['reg_user']\n",
    "        self.reg_item = params['reg_item']\n",
    "        self.reg_bias = params['reg_bias']\n",
    "        self.alpha_decay = self.alpha / self.n_iterations\n",
    "        self.model = {'loss_list':[], 'learning_rate':[]}\n",
    "        \n",
    "    def fit(self, train_set, val_set, val_rank, batch_size=1000):\n",
    "        #Init\n",
    "        s = time.time()\n",
    "        self.model['p'] = np.random.normal(0, .1, (self.total_users, self.nolf))  # users\n",
    "        self.model['q'] = np.random.normal(0, .1, (self.total_items, self.nolf))  # items\n",
    "        self.model['b'] = np.zeros(self.total_items)\n",
    "        \n",
    "#         val_prec_at = []\n",
    "#         val_rec_at = []\n",
    "#         val_hitcount = []\n",
    "        \n",
    "        # Create samples \n",
    "        n_sgd_samples = len(train_set) * self.n_iterations\n",
    "        \n",
    "        z = 0\n",
    "        self.model['train_time'] = 0\n",
    "        print('init and sampling done:', time.time() - s, 'seconds')\n",
    "        for i in range(self.n_iterations):\n",
    "            sgd_users, sgd_pos_items, sgd_neg_items = self.user_sampling(train_set, n_sgd_samples)\n",
    "        \n",
    "        while (z+1)*batch_size < n_sgd_samples:\n",
    "            s_it = time.time()\n",
    "            it_loss = self.train(sgd_users[z*batch_size:(z+1)*batch_size], sgd_pos_items[z*batch_size:(z+1)*batch_size], sgd_neg_items[z*batch_size:(z+1)*batch_size])\n",
    "            \n",
    "            if z > 0:\n",
    "                self.update_alpha(it_loss)\n",
    "            \n",
    "            z += 1\n",
    "            self.model['loss_list'].append(it_loss) \n",
    "\n",
    "#             rec_at, prec_at, hitcount = self.eval(val_set, val_rank)\n",
    "            t_it = time.time()- s_it\n",
    "            self.model['train_time'] += t_it\n",
    "            print('batch:', z, ' loss:', round(it_loss,4), 'iteration time:', round(t_it/2,2))#, ' val prec@' + str(val_rank), ':', round(prec_at,5), ' val rec@' + str(val_rank), ':', round(rec_at,5), '  Hits:', hitcount)#'  alpha:', self.alpha)\n",
    "    \n",
    "#             val_prec_at.append(prec_at)\n",
    "#             val_rec_at.append(rec_at)\n",
    "#             val_hitcount.append(hitcount)\n",
    "            \n",
    "#         self.model['val_prec_at'] = val_prec_at\n",
    "#         self.model['val_rec_at'] = val_rec_at\n",
    "#         self.model['val_hitcount'] = val_hitcount\n",
    "        \n",
    "        \n",
    "    def create_matrices(self, data):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(self.total_users, self.total_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1                 \n",
    "        return m, m_ones\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    \n",
    "    def user_sampling(self, data, n_samples):\n",
    "        train_ratings, train_ones = self.create_matrices(train_set)\n",
    "        user_items = train_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "        train_users  = train_set.new_user_id.unique()\n",
    "        train_items = train_set.new_item_id.unique()\n",
    "        \n",
    "        sgd_users, sgd_pos_items, sgd_neg_items = [], [], []\n",
    "        for sample in range(n_samples):\n",
    "            u = np.random.choice(train_users)\n",
    "            i = random.choice(user_items[u])\n",
    "\n",
    "            j = int(np.random.choice(train_items)) # neg item\n",
    "#             j_v = int(train_ones[u,j]) # Value, NEEDED?\n",
    "\n",
    "            while j in user_items[u]: # j cannot be the same item or an item with a 1\n",
    "                j = int(np.random.choice(train_items))\n",
    "#                 j_v = int(train_ones[u,j])\n",
    "            \n",
    "            sgd_users.append(u)\n",
    "            sgd_pos_items.append(i)\n",
    "            sgd_neg_items.append(j)\n",
    "            \n",
    "        return sgd_users, sgd_pos_items, sgd_neg_items\n",
    "        \n",
    "    def train(self, users, pos_items, neg_items):\n",
    "        for u, i, j in zip(users, pos_items, neg_items):\n",
    "            pos_item_pred = self.model['b'][i] + np.dot(self.model['p'][u], self.model['q'][i].T)\n",
    "            neg_item_pred = self.model['b'][j] + np.dot(self.model['p'][u], self.model['q'][j].T)\n",
    "            diff = pos_item_pred - neg_item_pred\n",
    "\n",
    "            loss_value = - np.log(self.sigmoid(diff)) #NEGATIVE?\n",
    "            regulariser = self.reg_user * np.dot(self.model['p'][u], self.model['p'][u]) + self.reg_item * np.dot(self.model['q'][i],self.model['q'][i]) + self.reg_item/10 * np.dot(self.model['q'][j], self.model['q'][j]) + self.reg_bias * (self.model['b'][i]**2 + self.model['b'][j]**2) \n",
    "            it_loss = loss_value + regulariser\n",
    "\n",
    "            diff_deriv = self.sigmoid(- diff)\n",
    "            \n",
    "            #SGD update\n",
    "            for f in range(self.nolf): # update each factor (see notes for derivatives)\n",
    "                self.model['p'][u,f] += self.alpha * (diff_deriv * (self.model['q'][i,f] - self.model['q'][j,f]) - self.reg_user * self.model['p'][u,f])\n",
    "                self.model['q'][i,f] += self.alpha * (diff_deriv * self.model['p'][u,f] - self.reg_item * self.model['q'][i,f])\n",
    "                self.model['q'][j,f] += self.alpha * (diff_deriv * (-self.model['p'][u,f]) - self.reg_item / 10 * self.model['q'][j,f])\n",
    "                self.model['b'][i] += self.alpha * (diff_deriv * self.reg_bias * self.model['b'][i])\n",
    "                self.model['b'][j] += self.alpha * (- diff_deriv * (- self.reg_bias) * self.model['b'][j])\n",
    "\n",
    "#                 it_loss += self.reg_user * self.model['p'][u,f] * self.model['p'][u,f] + self.reg_item * self.model['q'][i,f] * self.model['q'][i,f] + self.reg_item * self.model['q'][j,f] * self.model['q'][j,f]\n",
    "        return it_loss\n",
    "        \n",
    "    def update_alpha(self, it_loss):\n",
    "        last_loss = self.model['loss_list'][-1]\n",
    "        if(last_loss < it_loss): #bold driver\n",
    "            self.alpha = 0.5 * self.alpha\n",
    "            return\n",
    "        \n",
    "        self.alpha = (1 - self.alpha_decay) * self.alpha\n",
    "        self.model['learning_rate'].append(self.alpha)\n",
    "        \n",
    "    def eval(self, val_set, max_rank):\n",
    "        import eval_rank\n",
    "        val_ratings, val_ones = create_matrices(val_set, self.total_users, self.total_items)\n",
    "        result = self.model\n",
    "        users = val_set.new_user_id.unique()\n",
    "        items = val_set.new_item_id.unique()\n",
    "\n",
    "        s = time.time()\n",
    "        rank_at = max_rank\n",
    "        mp_splits = 4\n",
    "        users_split = np.array_split(users, mp_splits)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = mp.Pool(processes = mp_splits)\n",
    "            ranked = pool.map(eval_rank.eval_rank, [[result, users_split[0], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[1], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[2], items, val_ones, rank_at], \n",
    "                                                    [result, users_split[3], items, val_ones, rank_at]])\n",
    "            pool.close()\n",
    "\n",
    "            ranked_df = pd.DataFrame()\n",
    "\n",
    "            for i in range(mp_splits):\n",
    "                ranked_df = pd.concat([ranked_df, ranked[i]])\n",
    "\n",
    "            t = time.time() - s\n",
    "            hitcount = 0\n",
    "            for u in ranked_df.index:\n",
    "                hitcount += len(set(ranked_df.loc[u]['true_id']) & set(ranked_df.loc[u]['pred_items_ranked']))\n",
    "\n",
    "            prec_at =  hitcount / (len(ranked_df) * rank_at)\n",
    "            rec_at = hitcount / (len(ranked_df) * len(ranked_df.loc[0]['true_id']))\n",
    "            \n",
    "            return prec_at, rec_at, hitcount\n",
    "#             print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.292px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
