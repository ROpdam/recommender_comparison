{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import calc_vector\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983863</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00FXSELCM</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>155390</td>\n",
       "      <td>730619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294092</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00VDPQ884</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264632</td>\n",
       "      <td>730619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809981</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B00EWC0W3W</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>147315</td>\n",
       "      <td>730619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337932</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01EZKMD64</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>362038</td>\n",
       "      <td>730619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832820</th>\n",
       "      <td>A39ZLL8ILVT2J8</td>\n",
       "      <td>B01ABS4646</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>335911</td>\n",
       "      <td>730619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user        item   datetime  rating item_id user_id\n",
       "4983863  A39ZLL8ILVT2J8  B00FXSELCM 2014-03-24     3.0  155390  730619\n",
       "7294092  A39ZLL8ILVT2J8  B00VDPQ884 2016-06-29     5.0  264632  730619\n",
       "4809981  A39ZLL8ILVT2J8  B00EWC0W3W 2016-08-14     5.0  147315  730619\n",
       "9337932  A39ZLL8ILVT2J8  B01EZKMD64 2016-10-03     5.0  362038  730619\n",
       "8832820  A39ZLL8ILVT2J8  B01ABS4646 2016-12-22     5.0  335911  730619"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "### Leave last item out of subset of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_users_out(full_data, leave_out, seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    full_data['index'] = full_data.index\n",
    "    user_index_df = full_data.groupby('user')['index'].apply(list)\n",
    "    users = np.random.choice(list(user_index_df.index), leave_out, replace=False)\n",
    "    users_indices = []\n",
    "    \n",
    "    for user in users:\n",
    "        users_indices.extend(user_index_df.loc[user])\n",
    "    \n",
    "    sub_set = full_data.loc[users_indices]\n",
    "    remaining = full_data.drop(users_indices)\n",
    "    \n",
    "    return remaining.drop(columns=['index']), sub_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_x_out(full_data, n_users, leave_out=1, seed=1234):\n",
    "    # Input: data must contain user_id\n",
    "    # Output: full_data = without all last (time order) entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('user_id')['index'].apply(list)\n",
    "    users = full_data.user_id.unique()\n",
    "    leave_out_indices = []\n",
    "    users_picked = []\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        random_user = np.random.choice(users)\n",
    "        item_indices = user_items_ind[random_user] # random user's items indices\n",
    "        while random_user not in users_picked and len(item_indices) <= leave_out: # needs to have more items than to leave out, or deleting users\n",
    "            random_user = np.random.choice(users)\n",
    "            item_indices = user_items_ind[random_user]\n",
    "            \n",
    "        users_picked.append(random_user)\n",
    "        leave_out_indices.extend(item_indices[-leave_out:])\n",
    "    \n",
    "    leave_out_set = full_data.loc[leave_out_indices] # the last items of n_users users with n_item > leave_out\n",
    "    full_data_leave_one_out = full_data.drop(leave_out_indices) # drops last items for n_users users\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, batch_size, val_perc, test_perc, n_items_val, n_items_test, stats=True):\n",
    "    # Input: df with user and item id, batch size for CFRNN data, val and test perc of users\n",
    "    #        number of last items to leave out for val and test set\n",
    "    # Output:full_data = total users and items of the original df, \n",
    "    #        Train, validation and test sets\n",
    "    \n",
    "    total_users = len(df.user_id.unique()) # Need all users for BPR\n",
    "    total_items = len(df.item_id.unique()) # Need all items for CFRNN\n",
    "    \n",
    "    users_to_remove = len(df.user_id.unique())%batch_size #Batch size compatible for CFRNN\n",
    "    df_new, deleted_users = leave_users_out(df, users_to_remove)\n",
    "\n",
    "    test_users = int(test_perc*total_users) # Number of users to be used for testing\n",
    "    test_last_items = n_items_test # Items to be removed from test users in train set and used in test set\n",
    "\n",
    "    val_users = int(val_perc*total_users)\n",
    "    val_last_items = n_items_val\n",
    "    \n",
    "    train_set, test_set = leave_last_x_out(df_new, test_users, test_last_items)\n",
    "    train_set, val_set = leave_last_x_out(train_set, val_users, val_last_items)\n",
    "    \n",
    "    if stats:\n",
    "        print('Total number of items:', total_items)\n",
    "        print('Total users:', total_users)\n",
    "        print('Number of train users:', len(train_set.user_id.unique()))\n",
    "        print('Number of test users:', test_users)\n",
    "        print('Number of validation users:', val_users, '\\n')\n",
    "        print('Users deleted:', len(deleted_users.user_id.unique()))\n",
    "    \n",
    "    return total_users, total_items, train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 247465\n",
      "Total users: 121372\n",
      "Number of train users: 121344\n",
      "Number of test users: 12137\n",
      "Number of validation users: 12137 \n",
      "\n",
      "Users deleted: 28\n"
     ]
    }
   ],
   "source": [
    "total_users, total_items, train_set, val_set, test_set = train_val_test_split(df, BATCH_SIZE, val_perc, test_perc, n_last_items_val, n_last_items_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: BPR MF in TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paper: https://arxiv.org/pdf/1205.2618.pdf\n",
    "- Code:  https://github.com/valerystrizh/bpr/blob/master/BPR.java\n",
    "- TF example: https://medium.com/radix-ai-blog/unifying-word-embeddings-and-matrix-factorization-part-3-4269d9a07470"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Model (with bias), Loss, Train Step and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR_MF(tf.keras.Model):\n",
    "    def __init__(self, init_func, total_users, total_items, latent_dim): #b_init_func\n",
    "        super(BPR_MF, self).__init__()\n",
    "        self.p = tf.Variable(init_func(total_users, latent_dim), name=\"p\")\n",
    "        self.q = tf.Variable(init_func(total_items, latent_dim), name=\"q\")\n",
    "    \n",
    "    def call(self, uij):\n",
    "        return tf.math.multiply(self.p[uij[0]], (self.q[uij[1]] - self.q[uij[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __call__(self, x):\n",
    "        return - tf.math.log_sigmoid(tf.math.reduce_sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(uij):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        x = model(uij) \n",
    "        loss = loss_obj(x)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(n_samples, sample_size, user_items, train_users, train_items):\n",
    "#         print('Creating', str(n_samples), 'samples of length', str(sample_size))\n",
    "        all_uij_samples = []\n",
    "        from progressbar import ProgressBar\n",
    "        pbar = ProgressBar()\n",
    "        for n in pbar(range(n_samples)):\n",
    "            uij_samples = []\n",
    "            for s in range(sample_size):\n",
    "                u = int(np.random.choice(train_users))\n",
    "                u_items = user_items[u]\n",
    "                i = random.choice(u_items)\n",
    "                j = int(np.random.choice(train_items)) \n",
    "                while j in u_items: #neg item j cannot be in the set of pos items of user u\n",
    "                    j = int(np.random.choice(train_items))\n",
    "                \n",
    "                uij_samples.append([u,i,j])\n",
    "                \n",
    "            all_uij_samples.append(uij_samples)\n",
    "            \n",
    "        return all_uij_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Init: Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = train_set.groupby('user_id')['item_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 121372 \n",
      "Total Items: 247465\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "n_iterations = tf.constant(10)\n",
    "sample_size = tf.constant(int(0.0001*len(train_set)) - 1)\n",
    "\n",
    "train_users = train_set.user_id.unique()\n",
    "train_items = train_set.item_id.unique()\n",
    "\n",
    "print('Total Users:', total_users,\n",
    "      '\\nTotal Items:', total_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_init = lambda v, d: tf.random.normal((v, d), 0.0, 1.0/d)\n",
    "zero_init = lambda v: tf.zeros(v,1)\n",
    "\n",
    "model = BPR_MF(normal_init, total_users, total_items, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = Loss()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "all_uij_samples = tf.concat([create_samples(n_iterations, sample_size, user_items, train_users, train_items)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% |##############                                                          |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-36aaa09bff29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muij_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0muij_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muij_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muij_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mit_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/re_research_m/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "train_time_s = time.time()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "total_losses = []\n",
    "\n",
    "# train(n_iterations, sample_size, all_uij_samples)\n",
    "for iteration in pbar(tf.range(n_iterations)):\n",
    "    it_losses = []\n",
    "    uij_samples = all_uij_samples[iteration]\n",
    "    for s in tf.range(uij_samples.shape[0]):\n",
    "        uij_sample = uij_samples[s]\n",
    "        loss = train_step(uij_sample)\n",
    "        it_losses.append(loss)\n",
    "        \n",
    "    avg_it_losses = np.average(it_losses)\n",
    "    total_losses.append(avg_it_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick np save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('Results/BPR_TF/p.txt', model.p.numpy(), fmt='%f')\n",
    "# np.savetxt('Results/BPR_TF/q.txt', model.q.numpy(), fmt='%f')\n",
    "\n",
    "\n",
    "p = np.loadtxt(path + 'Results/BPR_TF/p.txt', dtype=float)\n",
    "q = np.loadtxt(path + 'Results/BPR_TF/q.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Rank items per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_predictions(model, test_set, rank_at):\n",
    "    import eval_rank_bpr\n",
    "    \n",
    "    s = time.time()\n",
    "    users = test_set.user_id.unique()\n",
    "    items = test_set.item_id.unique()\n",
    "    test_user_items = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "    ranked_df = pd.DataFrame(columns=['pred_items_ranked', 'true_id'], index=users)\n",
    "    \n",
    "    pred_items_ranked = []\n",
    "    true_items_list = []\n",
    "\n",
    "    for u in users:\n",
    "        user_item_pred_score = []\n",
    "        true_items = []\n",
    "        for true_item in test_user_items.loc[u]:\n",
    "            true_items.append(true_item)\n",
    "\n",
    "        predictions = np.dot(model['p'][u], model['q'].T)\n",
    "        ids = np.argpartition(predictions, -rank_at)[-rank_at:]\n",
    "        best_ids = np.argsort(predictions[ids])[::-1]\n",
    "        best = ids[best_ids]\n",
    "\n",
    "        pred_items_ranked.append(best)\n",
    "        true_items_list.append(true_items)\n",
    "\n",
    "    ranked_df['pred_items_ranked'] = pred_items_ranked\n",
    "    ranked_df['true_id'] = true_items_list\n",
    "\n",
    "    print('Ranking time:', round(time.time() - s,2))\n",
    "    \n",
    "    return ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ranked_df, steps, max_rank):\n",
    "    s = time.time()\n",
    "    ranks_at = [1] + [i for i in range(steps, max_rank + steps, steps)]\n",
    "    hitcounts = []\n",
    "    recs_at = []\n",
    "    precs_at = []\n",
    "    metrics = pd.DataFrame(columns=['rank_at', 'hitcounts', 'recall', 'precision'])\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for i, row in ranked_df.iterrows():\n",
    "            hitcount +=  len(set(row['true_id']) & set(row['pred_items_ranked'][:rank]))\n",
    "\n",
    "        prec_at = hitcount / rank / len(ranked_df)\n",
    "        rec_at = hitcount / len(ranked_df.iloc[0]['true_id']) / len(ranked_df)\n",
    "\n",
    "        hitcounts.append(hitcount)                     \n",
    "        recs_at.append(rec_at)\n",
    "        precs_at.append(prec_at)\n",
    "\n",
    "    metrics['rank_at'] = ranks_at\n",
    "    metrics['hitcounts'] = hitcounts\n",
    "    metrics['recall'] = recs_at\n",
    "    metrics['precision'] = precs_at\n",
    "    print('Obtaining metrics time:', round(time.time() - s,2))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'p':model.p.numpy(), 'q':model.q.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_at = 20\n",
    "ranked_df = rank_predictions(result, test_set, rank_at)\n",
    "\n",
    "steps = 5\n",
    "metrics = get_metrics(ranked_df, steps, rank_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]\n",
    "ranks_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calc Hits@, Rec@ and Prec@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitcounts = []\n",
    "recs_at = []\n",
    "precs_at = []\n",
    "bpr_tf = pd.DataFrame(columns=['rank_at', 'hitcounts', 'recall', 'precision'])\n",
    "for rank in ranks_at:\n",
    "    hitcount = 0\n",
    "    for u in ranked_df.index:\n",
    "        hitcount +=  len(set(ranked_df.loc[u]['true_id']) & set(ranked_df.loc[u]['pred_items_ranked'][:rank]))\n",
    "                    \n",
    "    prec_at = hitcount / rank / len(ranked_df)\n",
    "    rec_at = hitcount / len(ranked_df.iloc[0]['true_id']) / len(ranked_df)\n",
    "    \n",
    "    print('rank_at:', rank, '  Hits:', hitcount)\n",
    "    hitcounts.append(hitcount)                     \n",
    "    recs_at.append(rec_at)\n",
    "    precs_at.append(prec_at)\n",
    "\n",
    "bpr_tf['rank_at'] = ranks_at\n",
    "bpr_tf['hitcounts'] = hitcounts\n",
    "bpr_tf['recall'] = recs_at\n",
    "bpr_tf['precision'] = precs_at\n",
    "bpr_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'Results/BPR_TF/'\n",
    "bpr_tf.to_pickle(path + result_path + file_name + '_bpr_tf_res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(path + result_path + 'ml_07m' + '_bpr_tf_res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "375.742px",
    "left": "1048.75px",
    "top": "110.57px",
    "width": "200.295px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
