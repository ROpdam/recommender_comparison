{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/Amazon/'\n",
    "# file_name = 'Amazon_full' \n",
    "# file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'Amazon_005_users'\n",
    "# file_name = 'Amazon_001_users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/ML/'\n",
    "# file_name = 'ML_full' \n",
    "# file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'\n",
    "# file_name = 'ML_005_users'\n",
    "# file_name = 'ML_001_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>datetime</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21225350</th>\n",
       "      <td>137924</td>\n",
       "      <td>318</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-09-20 19:20:13</td>\n",
       "      <td>314</td>\n",
       "      <td>137923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225354</th>\n",
       "      <td>137924</td>\n",
       "      <td>527</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-09-20 19:20:17</td>\n",
       "      <td>522</td>\n",
       "      <td>137923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225351</th>\n",
       "      <td>137924</td>\n",
       "      <td>356</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-09-20 19:20:20</td>\n",
       "      <td>351</td>\n",
       "      <td>137923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225362</th>\n",
       "      <td>137924</td>\n",
       "      <td>1704</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-20 19:20:22</td>\n",
       "      <td>1640</td>\n",
       "      <td>137923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225367</th>\n",
       "      <td>137924</td>\n",
       "      <td>3147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-09-20 19:20:25</td>\n",
       "      <td>3054</td>\n",
       "      <td>137923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user  item  rating            datetime item_id user_id\n",
       "21225350  137924   318     4.5 2017-09-20 19:20:13     314  137923\n",
       "21225354  137924   527     3.5 2017-09-20 19:20:17     522  137923\n",
       "21225351  137924   356     5.0 2017-09-20 19:20:20     351  137923\n",
       "21225362  137924  1704     4.0 2017-09-20 19:20:22    1640  137923\n",
       "21225367  137924  3147     4.0 2017-09-20 19:20:25    3054  137923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_am = ['Amazon_05_users', 'Amazon_01_users', 'Amazon_005_users', 'Amazon_001_users']\n",
    "names_ml = ['ML_05_users', 'ML_01_users', 'ML_005_users', 'ML_001_users']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = df.item.astype('category').cat.codes\n",
    "df['user_id'] = df.user.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave item train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_x_out(full_data, leave_out):\n",
    "    # Input: data must be formatted by func: tranfsorm\n",
    "    # Output: full_data = without all entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('user_id')['index'].apply(list)\n",
    "    index_to_drop = []\n",
    "    \n",
    "    for indices in user_items_ind:\n",
    "        if len(indices) > leave_out:\n",
    "            for to_leave_out in range(leave_out):\n",
    "                index = indices[- to_leave_out]\n",
    "                index_to_drop.append(index)\n",
    "    \n",
    "    leave_one_out_set = full_data.loc[index_to_drop]\n",
    "    full_data_leave_one_out = full_data.drop(index_to_drop)\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_one_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrices(data, n_users, n_items):\n",
    "        r = data['user_id']\n",
    "        c = data['item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1\n",
    "                               \n",
    "        return m, m_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random user item dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_ui_dict(test_set, rank_at=20):\n",
    "    users = test_set.user_id.unique()\n",
    "    items = test_set.item_id.unique()\n",
    "\n",
    "    user_item_dict = {}\n",
    "\n",
    "    random.shuffle(items)\n",
    "    for u in users:\n",
    "        item_index = random.randint(rank_at, len(items))\n",
    "        user_item_dict[u] = items[item_index-rank_at:item_index]        \n",
    "\n",
    "    return user_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bench(file_names, path, steps, ranks_at, results):\n",
    "    for name in file_names:\n",
    "        print(name)\n",
    "        df = pd.read_pickle(path + name)\n",
    "        df['item_id'] = df.item.astype('category').cat.codes\n",
    "        df['user_id'] = df.user.astype('category').cat.codes\n",
    "        # Uses leave items out, but need leave users out?\n",
    "        train_set, test_set = leave_x_out(df, 2)\n",
    "        val_set, test_set = leave_x_out(test_set, 1)\n",
    "\n",
    "        user_items = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "        hits = np.zeros((1,5))\n",
    "        iterations = 10\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            ui_rand_dict = create_random_ui_dict(test_set)\n",
    "            hitcounts = []\n",
    "            recs_at = []\n",
    "            precs_at = []\n",
    "            for rank in ranks_at:\n",
    "                hitcount = 0\n",
    "                for u in test_set.user_id.unique():\n",
    "                    for item in user_items[u]:\n",
    "                        if item in ui_rand_dict[u][:rank]: #for 1 item test sets only\n",
    "                            hitcount += 1\n",
    "\n",
    "                hitcounts.append(hitcount)                     \n",
    "            hits += np.array(hitcounts).T\n",
    "\n",
    "        avg_hits = hits / iterations\n",
    "        random_results[name] = avg_hits[0]\n",
    "        print(avg_hits)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon_05_users\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5dfe217777f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/Amazon/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrandom_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_bench\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_am\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranks_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-52b9e5f9aa41>\u001b[0m in \u001b[0;36mrandom_bench\u001b[0;34m(file_names, path, steps, ranks_at, results)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mui_rand_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for 1 item test sets only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                             \u001b[0mhitcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = 5\n",
    "rank_at = 20\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]\n",
    "random_results = pd.DataFrame(columns=names_am)\n",
    "file_path = path + 'data/Amazon/'\n",
    "\n",
    "random_results = random_bench(names_am, file_path, steps, ranks_at, random_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('Results/BPR/rand_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results['rank_at'] = ranks_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results.to_pickle('Results/BPR/rand_rank_hits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Benchmark SHOULD BE COUNTS OF TRAIN SET\n",
    "Popularity decides rank of item for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon_csj_2m',\n",
       " 'df_amazon_csj_with_styles_0.63m_u_above_5_rui',\n",
       " '2m-ml',\n",
       " 'ml_0.7_u_above_5',\n",
       " 'ml_0.7_u_above_5_3_r_thres',\n",
       " '2m-ml_3_r_thres']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " amazon_csj_2m\n",
      "Full data #row:  2059552\n",
      "rank_at 1  hitcount: 15\n",
      "rank_at 5  hitcount: 1390\n",
      "rank_at 10  hitcount: 5840\n",
      "rank_at 15  hitcount: 6460\n",
      "rank_at 20  hitcount: 10185\n",
      "\n",
      " df_amazon_csj_with_styles_0.63m_u_above_5_rui\n",
      "Full data #row:  629889\n",
      "rank_at 1  hitcount: 23\n",
      "rank_at 5  hitcount: 256\n",
      "rank_at 10  hitcount: 1314\n",
      "rank_at 15  hitcount: 3843\n",
      "rank_at 20  hitcount: 6959\n",
      "\n",
      " 2m-ml\n",
      "Full data #row:  1974692\n",
      "rank_at 1  hitcount: 184\n",
      "rank_at 5  hitcount: 1900\n",
      "rank_at 10  hitcount: 6933\n",
      "rank_at 15  hitcount: 9426\n",
      "rank_at 20  hitcount: 17776\n",
      "\n",
      " ml_0.7_u_above_5\n",
      "Full data #row:  707447\n",
      "rank_at 1  hitcount: 14\n",
      "rank_at 5  hitcount: 1777\n",
      "rank_at 10  hitcount: 3853\n",
      "rank_at 15  hitcount: 5296\n",
      "rank_at 20  hitcount: 7063\n",
      "\n",
      " ml_0.7_u_above_5_3_r_thres\n",
      "Full data #row:  574132\n",
      "rank_at 1  hitcount: 275\n",
      "rank_at 5  hitcount: 2690\n",
      "rank_at 10  hitcount: 4016\n",
      "rank_at 15  hitcount: 5979\n",
      "rank_at 20  hitcount: 8040\n",
      "\n",
      " 2m-ml_3_r_thres\n",
      "Full data #row:  1614609\n",
      "rank_at 1  hitcount: 3483\n",
      "rank_at 5  hitcount: 5015\n",
      "rank_at 10  hitcount: 8950\n",
      "rank_at 15  hitcount: 13821\n",
      "rank_at 20  hitcount: 22936\n"
     ]
    }
   ],
   "source": [
    "max_rank_at = 20\n",
    "steps = 5\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]\n",
    "items_in_test_set = 1\n",
    "pop_results = pd.DataFrame(columns=file_names)\n",
    "\n",
    "for name in file_names:\n",
    "    print('\\n', name)\n",
    "    df = pd.read_pickle('Data/' + name)\n",
    "    df_new_ids = transform(df)\n",
    "    df_new_ids['item_counts'] = df_new_ids.groupby('item_id')['user_id'].transform('count') #for populairty\n",
    "    train_set, test_set = leave_x_out(df_new_ids, items_in_test_set*2)\n",
    "    val_set, test_set = leave_x_out(test_set, items_in_test_set)\n",
    "    \n",
    "    most_pop_items = test_set.sort_values('item_counts')['item_id'].unique()[-max_rank_at:]\n",
    "    user_items = test_set.groupby('user_id')['item_id'].apply(list)\n",
    "    \n",
    "    hitcounts = []\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for u in test_set.user_id.unique():\n",
    "            for item in user_items[u]:\n",
    "                if item in most_pop_items[:rank]:\n",
    "                    hitcount += 1\n",
    "        print('rank_at', rank, ' hitcount:', hitcount)\n",
    "        hitcounts.append(hitcount)\n",
    "    \n",
    "    pop_results[name] = hitcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Results/BPR/pop_rank_hits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-34effa0490ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpop_results_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Results/BPR/pop_rank_hits'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# 1) try standard library Pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Results/BPR/pop_rank_hits'"
     ]
    }
   ],
   "source": [
    "pop_results_old = pd.read_pickle('Results/BPR/pop_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_old['ml_0.7_u_above_5_3_r_thres'] = pop_results['ml_0.7_u_above_5_3_r_thres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results.to_pickle('Results/BPR/pop_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
