{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data\n",
    "# file_name = 'amazon_clothing_shoes_jewelry_data' \n",
    "\n",
    "#2m user above 5 ratings\n",
    "# file_name = 'amazon_csj_2m'\n",
    "\n",
    "#0.63m user above 5 ratings\n",
    "# file_name = 'df_amazon_csj_with_styles_0.63m_u_above_5_rui' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data\n",
    "# file_name = '25m_ml'\n",
    "\n",
    "# 2m subset\n",
    "# file_name = '2m-ml', \n",
    "\n",
    "# 0.7m subset\n",
    "file_name = 'ml_0.7_u_above_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['amazon_csj_2m', 'df_amazon_csj_with_styles_0.63m_u_above_5_rui', '2m-ml', 'ml_0.7_u_above_5', 'ml_0.7_u_above_5_3_r_thres', '2m-ml_3_r_thres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19412305</th>\n",
       "      <td>126018</td>\n",
       "      <td>1247</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19670428</th>\n",
       "      <td>127741</td>\n",
       "      <td>27706</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23908501</th>\n",
       "      <td>155314</td>\n",
       "      <td>1203</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673811</th>\n",
       "      <td>30576</td>\n",
       "      <td>541</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299153</th>\n",
       "      <td>99133</td>\n",
       "      <td>1220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user   item  rating  verified\n",
       "19412305  126018   1247     5.0         1\n",
       "19670428  127741  27706     3.5         1\n",
       "23908501  155314   1203     3.5         1\n",
       "4673811    30576    541     5.0         1\n",
       "15299153   99133   1220     4.0         1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Data/'\n",
    "df = pd.read_pickle(path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "Create new ids for users and items that match the row and column indices of the user-item interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    items = df['item'].unique()\n",
    "    itemsDF = pd.DataFrame(data=items, columns=['original_item_id'])\n",
    "    itemsDF['new_item_id'] = itemsDF.index\n",
    "\n",
    "    users = df['user'].unique()\n",
    "    usersDF = pd.DataFrame(data=users, columns=['original_user_id'])\n",
    "    usersDF['new_user_id'] = usersDF.index\n",
    "\n",
    "    ratingDF = df.merge(itemsDF, left_on='item', right_on='original_item_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_item_id'])\n",
    "\n",
    "    ratingDF = ratingDF.merge(usersDF, left_on='user', right_on='original_user_id')\n",
    "    ratingDF = ratingDF.drop(columns=['original_user_id'])\n",
    "\n",
    "    df_new_ids = ratingDF\n",
    "    print('Full data #row: ', df_new_ids.shape[0])\n",
    "    \n",
    "    return df_new_ids\n",
    "\n",
    "# df_new_ids = transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave item train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_x_out(full_data, leave_out):\n",
    "    # Input: data must be formatted by func: tranfsorm\n",
    "    # Output: full_data = without all entries in leave one out set\n",
    "    #         leave_one_out_set = data with one user and one item from full_data\n",
    "    \n",
    "    full_data['index'] = full_data.index\n",
    "    user_items_ind = full_data.groupby('new_user_id')['index'].apply(list)\n",
    "    index_to_drop = []\n",
    "    \n",
    "    for indices in user_items_ind:\n",
    "        if len(indices) > leave_out:\n",
    "            for to_leave_out in range(leave_out):\n",
    "                index = indices[- to_leave_out]\n",
    "                index_to_drop.append(index)\n",
    "    \n",
    "    leave_one_out_set = full_data.loc[index_to_drop]\n",
    "    full_data_leave_one_out = full_data.drop(index_to_drop)\n",
    "    \n",
    "    return full_data_leave_one_out.drop(columns=['index']), leave_one_out_set.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrices(data, n_users, n_items):\n",
    "        r = data['new_user_id']\n",
    "        c = data['new_item_id']\n",
    "        d = data['rating']\n",
    "        m = sparse.csr_matrix((d, (r, c)), shape=(n_users, n_items))\n",
    "        m_ones = m.copy()\n",
    "        m_ones[m_ones > 0] = 1\n",
    "                               \n",
    "        return m, m_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random user item dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_ui_dict(test_set, rank_at=20):\n",
    "    users = test_set.new_user_id.unique()\n",
    "    items = test_set.new_item_id.unique()\n",
    "\n",
    "    user_item_dict = {}\n",
    "\n",
    "    random.shuffle(items)\n",
    "    for u in users:\n",
    "        item_index = random.randint(rank_at, len(items))\n",
    "        user_item_dict[u] = items[item_index-rank_at:item_index]        \n",
    "\n",
    "    return user_item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_csj_2m\n",
      "Full data #row:  2059552\n",
      "[[  6.3  37.2  75.  113.7 150.4]]\n",
      "df_amazon_csj_with_styles_0.63m_u_above_5_rui\n",
      "Full data #row:  629889\n",
      "[[  5.5  27.2  51.9  74.4 103.4]]\n",
      "2m-ml\n",
      "Full data #row:  1974692\n",
      "[[  74.3  371.2  740.2 1107.5 1478.5]]\n",
      "ml_0.7_u_above_5\n",
      "Full data #row:  707447\n",
      "[[ 43.1 200.  414.2 626.1 841.2]]\n",
      "ml_0.7_u_above_5_3_r_thres\n",
      "Full data #row:  574132\n",
      "[[ 38.8 182.9 365.9 544.7 732.5]]\n",
      "2m-ml_3_r_thres\n",
      "Full data #row:  1614609\n",
      "[[  67.3  330.8  666.8  979.9 1310.2]]\n"
     ]
    }
   ],
   "source": [
    "steps = 5\n",
    "rank_at = 20\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]\n",
    "random_results = pd.DataFrame(columns=file_names)\n",
    "\n",
    "for name in file_names:\n",
    "    print(name)\n",
    "    df = pd.read_pickle('Data/' + name)\n",
    "    df_new_ids = transform(df)\n",
    "    train_set, test_set = leave_x_out(df_new_ids, 2)\n",
    "    val_set, test_set = leave_x_out(test_set, 1)\n",
    "    \n",
    "    user_items = test_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "    hits = np.zeros((1,5))\n",
    "    iterations = 10\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        ui_rand_dict = create_random_ui_dict(test_set)\n",
    "        hitcounts = []\n",
    "        recs_at = []\n",
    "        precs_at = []\n",
    "        for rank in ranks_at:\n",
    "            hitcount = 0\n",
    "            for u in test_set.new_user_id.unique():\n",
    "                for item in user_items[u]:\n",
    "                    if item in ui_rand_dict[u][:rank]: #for 1 item test sets only\n",
    "                        hitcount += 1\n",
    "\n",
    "            hitcounts.append(hitcount)                     \n",
    "        hits += np.array(hitcounts).T\n",
    "\n",
    "    avg_hits = hits / iterations\n",
    "    random_results[name] = avg_hits[0]\n",
    "    print(avg_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('Results/BPR/rand_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results['rank_at'] = ranks_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results.to_pickle('Results/BPR/rand_rank_hits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Benchmark\n",
    "Popularity decides rank of item for everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon_csj_2m',\n",
       " 'df_amazon_csj_with_styles_0.63m_u_above_5_rui',\n",
       " '2m-ml',\n",
       " 'ml_0.7_u_above_5',\n",
       " 'ml_0.7_u_above_5_3_r_thres',\n",
       " '2m-ml_3_r_thres']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " amazon_csj_2m\n",
      "Full data #row:  2059552\n",
      "rank_at 1  hitcount: 15\n",
      "rank_at 5  hitcount: 1390\n",
      "rank_at 10  hitcount: 5840\n",
      "rank_at 15  hitcount: 6460\n",
      "rank_at 20  hitcount: 10185\n",
      "\n",
      " df_amazon_csj_with_styles_0.63m_u_above_5_rui\n",
      "Full data #row:  629889\n",
      "rank_at 1  hitcount: 23\n",
      "rank_at 5  hitcount: 256\n",
      "rank_at 10  hitcount: 1314\n",
      "rank_at 15  hitcount: 3843\n",
      "rank_at 20  hitcount: 6959\n",
      "\n",
      " 2m-ml\n",
      "Full data #row:  1974692\n",
      "rank_at 1  hitcount: 184\n",
      "rank_at 5  hitcount: 1900\n",
      "rank_at 10  hitcount: 6933\n",
      "rank_at 15  hitcount: 9426\n",
      "rank_at 20  hitcount: 17776\n",
      "\n",
      " ml_0.7_u_above_5\n",
      "Full data #row:  707447\n",
      "rank_at 1  hitcount: 14\n",
      "rank_at 5  hitcount: 1777\n",
      "rank_at 10  hitcount: 3853\n",
      "rank_at 15  hitcount: 5296\n",
      "rank_at 20  hitcount: 7063\n",
      "\n",
      " ml_0.7_u_above_5_3_r_thres\n",
      "Full data #row:  574132\n",
      "rank_at 1  hitcount: 275\n",
      "rank_at 5  hitcount: 2690\n",
      "rank_at 10  hitcount: 4016\n",
      "rank_at 15  hitcount: 5979\n",
      "rank_at 20  hitcount: 8040\n",
      "\n",
      " 2m-ml_3_r_thres\n",
      "Full data #row:  1614609\n",
      "rank_at 1  hitcount: 3483\n",
      "rank_at 5  hitcount: 5015\n",
      "rank_at 10  hitcount: 8950\n",
      "rank_at 15  hitcount: 13821\n",
      "rank_at 20  hitcount: 22936\n"
     ]
    }
   ],
   "source": [
    "max_rank_at = 20\n",
    "steps = 5\n",
    "ranks_at = [1] + [i for i in range(steps, rank_at + steps, steps)]\n",
    "items_in_test_set = 1\n",
    "pop_results = pd.DataFrame(columns=file_names)\n",
    "\n",
    "for name in file_names:\n",
    "    print('\\n', name)\n",
    "    df = pd.read_pickle('Data/' + name)\n",
    "    df_new_ids = transform(df)\n",
    "    df_new_ids['item_counts'] = df_new_ids.groupby('new_item_id')['new_user_id'].transform('count') #for populairty\n",
    "    train_set, test_set = leave_x_out(df_new_ids, items_in_test_set*2)\n",
    "    val_set, test_set = leave_x_out(test_set, items_in_test_set)\n",
    "    \n",
    "    most_pop_items = test_set.sort_values('item_counts')['new_item_id'].unique()[-max_rank_at:]\n",
    "    user_items = test_set.groupby('new_user_id')['new_item_id'].apply(list)\n",
    "    \n",
    "    hitcounts = []\n",
    "    for rank in ranks_at:\n",
    "        hitcount = 0\n",
    "        for u in test_set.new_user_id.unique():\n",
    "            for item in user_items[u]:\n",
    "                if item in most_pop_items[:rank]:\n",
    "                    hitcount += 1\n",
    "        print('rank_at', rank, ' hitcount:', hitcount)\n",
    "        hitcounts.append(hitcount)\n",
    "    \n",
    "    pop_results[name] = hitcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Results/BPR/pop_rank_hits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-34effa0490ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpop_results_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Results/BPR/pop_rank_hits'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# 1) try standard library Pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\re_research\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Results/BPR/pop_rank_hits'"
     ]
    }
   ],
   "source": [
    "pop_results_old = pd.read_pickle('Results/BPR/pop_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_old['ml_0.7_u_above_5_3_r_thres'] = pop_results['ml_0.7_u_above_5_3_r_thres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results.to_pickle('Results/BPR/pop_rank_hits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_results_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
