{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import progressbar as progressbar\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'TF version: {tf.__version__}')\n",
    "# print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/Amazon/'\n",
    "# file_name = 'Amazon_full' # file_name = 'Amazon_05_users' \n",
    "# file_name = 'Amazon_01_users'\n",
    "# file_name = 'am_80k_users'\n",
    "file_name = 'am_40k_users'\n",
    "# file_name = 'am_like_ml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = 'data/ML/'\n",
    "file_name = 'ml_1m'\n",
    "# file_name = 'ML_full' # file_name = 'ML_05_users'\n",
    "# file_name = 'ML_01_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1845392</th>\n",
       "      <td>AGYA6NBNU1VUH</td>\n",
       "      <td>B0020B4EYU</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34371</td>\n",
       "      <td>11002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919114</th>\n",
       "      <td>AGYA6NBNU1VUH</td>\n",
       "      <td>B0000ZFDD4</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34371</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872323</th>\n",
       "      <td>AGYA6NBNU1VUH</td>\n",
       "      <td>B00KR6I6IK</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34371</td>\n",
       "      <td>75683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237107</th>\n",
       "      <td>AGYA6NBNU1VUH</td>\n",
       "      <td>B0000ZFDD4</td>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34371</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971633</th>\n",
       "      <td>AGYA6NBNU1VUH</td>\n",
       "      <td>B008GXBRNM</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34371</td>\n",
       "      <td>35964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user        item   datetime  rating  user_id  item_id\n",
       "1845392  AGYA6NBNU1VUH  B0020B4EYU 2015-04-14     3.0    34371    11002\n",
       "919114   AGYA6NBNU1VUH  B0000ZFDD4 2015-04-14     3.0    34371      179\n",
       "5872323  AGYA6NBNU1VUH  B00KR6I6IK 2015-04-14     5.0    34371    75683\n",
       "1237107  AGYA6NBNU1VUH  B0000ZFDD4 2015-04-14     3.0    34371      179\n",
       "9971633  AGYA6NBNU1VUH  B008GXBRNM 2015-12-20     5.0    34371    35964"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import leave_last_x_out_2\n",
    "\n",
    "test_set_cfrnn = pd.read_pickle(path + 'test_set_ml_cfrnn')\n",
    "val_set_cfrnn = pd.read_pickle(path  + 'val_set_ml_cfrnn')\n",
    "train_set_cfrnn = pd.read_pickle(path + 'train_set_ml_cfrnn')\n",
    "\n",
    "add_to_train, val_set = leave_last_x_out_2(val_set_cfrnn)\n",
    "add_to_train_2, test_set = leave_last_x_out_2(test_set_cfrnn)\n",
    "\n",
    "train_set = pd.concat([train_set_cfrnn, add_to_train, add_to_train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_mf = pd.read_pickle(path + data_path + file_name + '_test_mf')\n",
    "val_set_mf = pd.read_pickle(path + data_path + file_name + '_val_mf')\n",
    "train_set_mf = pd.read_pickle(path + data_path + file_name + '_train_mf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.DataFrame()\n",
    "train_set_og = pd.DataFrame()\n",
    "pbar = progressbar.ProgressBar()\n",
    "for u in pbar(df.user_id.unique()):\n",
    "    last_item = df[df.user_id==u].iloc[-1:]\n",
    "    test_set = test_set.append(last_item)\n",
    "    remaining = df[df.user_id==u].iloc[:-1]\n",
    "    train_set_og = pd.concat([train_set_og, remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B001MWSW8W</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B00KS6N9BI</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B007MM9VSG</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B00KS6NJCW</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B000X25EF6</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371497</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B00RL6T3FE</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371498</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B008UG5970</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371499</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B00S0VTSYA</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371500</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B00DVH1TP4</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371501</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B01HFKNX2E</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>145766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365463 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                  user        item   datetime  rating  item_id\n",
       "0             0  A0435554Z2P98AIGLNCS  B001MWSW8W 2015-03-17     5.0     8768\n",
       "1             0  A0435554Z2P98AIGLNCS  B00KS6N9BI 2015-03-17     5.0    76377\n",
       "2             0  A0435554Z2P98AIGLNCS  B007MM9VSG 2015-03-17     5.0    31002\n",
       "3             0  A0435554Z2P98AIGLNCS  B00KS6NJCW 2015-03-17     1.0    76380\n",
       "4             0  A0435554Z2P98AIGLNCS  B000X25EF6 2015-03-17     5.0     4730\n",
       "...         ...                   ...         ...        ...     ...      ...\n",
       "371497     6039         AZZXCFBNEWIBQ  B00RL6T3FE 2017-06-22     5.0    95419\n",
       "371498     6039         AZZXCFBNEWIBQ  B008UG5970 2017-08-27     4.0    34999\n",
       "371499     6039         AZZXCFBNEWIBQ  B00S0VTSYA 2017-09-07     5.0    96119\n",
       "371500     6039         AZZXCFBNEWIBQ  B00DVH1TP4 2017-09-07     5.0    52179\n",
       "371501     6039         AZZXCFBNEWIBQ  B01HFKNX2E 2017-10-13     5.0   145766\n",
       "\n",
       "[365463 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "val_set = pd.DataFrame()\n",
    "train_set = pd.DataFrame()\n",
    "pbar = progressbar.ProgressBar()\n",
    "for u in pbar(df.user_id.unique()):\n",
    "    last_item = train_set_og[train_set_og.user_id==u].iloc[-1:]\n",
    "    val_set = val_set.append(last_item)\n",
    "    remaining = train_set_og[train_set_og.user_id==u].iloc[:-1]\n",
    "    train_set = pd.concat([train_set, remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>datetime</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>A0435554Z2P98AIGLNCS</td>\n",
       "      <td>B000YXC2LI</td>\n",
       "      <td>2016-07-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>A0464351OZXPUPKGI6HO</td>\n",
       "      <td>B01DKTA3N6</td>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>A0488385844WNV2OWO9X</td>\n",
       "      <td>B01075YZY4</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>111762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3</td>\n",
       "      <td>A1005AVG5ETV5F</td>\n",
       "      <td>B002UD8JHQ</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4</td>\n",
       "      <td>A101GG7X49PK0A</td>\n",
       "      <td>B00KMW2AZO</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371122</th>\n",
       "      <td>6035</td>\n",
       "      <td>AZV1BS40E75V5</td>\n",
       "      <td>B00PUDMEOW</td>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>91663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371190</th>\n",
       "      <td>6036</td>\n",
       "      <td>AZX2RDN9YXZAE</td>\n",
       "      <td>B0009GGUO0</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371239</th>\n",
       "      <td>6037</td>\n",
       "      <td>AZXX5N2AH6WPN</td>\n",
       "      <td>B00N9SFSO8</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371303</th>\n",
       "      <td>6038</td>\n",
       "      <td>AZZT1ERHBSNQ8</td>\n",
       "      <td>B01CQVZ46A</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>136397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371501</th>\n",
       "      <td>6039</td>\n",
       "      <td>AZZXCFBNEWIBQ</td>\n",
       "      <td>B01HFKNX2E</td>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>145766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                  user        item   datetime  rating  item_id\n",
       "60            0  A0435554Z2P98AIGLNCS  B000YXC2LI 2016-07-18     5.0     4986\n",
       "108           1  A0464351OZXPUPKGI6HO  B01DKTA3N6 2016-12-21     5.0   138307\n",
       "175           2  A0488385844WNV2OWO9X  B01075YZY4 2017-03-06     5.0   111762\n",
       "234           3        A1005AVG5ETV5F  B002UD8JHQ 2018-04-30     5.0    12106\n",
       "304           4        A101GG7X49PK0A  B00KMW2AZO 2017-08-07     5.0    75773\n",
       "...         ...                   ...         ...        ...     ...      ...\n",
       "371122     6035         AZV1BS40E75V5  B00PUDMEOW 2018-05-02     5.0    91663\n",
       "371190     6036         AZX2RDN9YXZAE  B0009GGUO0 2018-02-02     3.0      936\n",
       "371239     6037         AZXX5N2AH6WPN  B00N9SFSO8 2018-03-12     5.0    84947\n",
       "371303     6038         AZZT1ERHBSNQ8  B01CQVZ46A 2017-07-31     5.0   136397\n",
       "371501     6039         AZZXCFBNEWIBQ  B01HFKNX2E 2017-10-13     5.0   145766\n",
       "\n",
       "[6040 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_pickle('../datasets/train_set_am_like_ml')\n",
    "val_set.to_pickle('../datasets/val_set_am_like_ml')\n",
    "test_set.to_pickle('../datasets/test_set_am_like_ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_pickle(path + 'ml_1m_test')\n",
    "train_set = pd.read_pickle(path + 'ml_1m_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_prep import leave_users_out\n",
    "remaining, subset = leave_users_out(df, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351771"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = subset\n",
    "df.user_id = df.user_id.astype('category').cat.codes\n",
    "df.item_id = df.item_id.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_items: 139230\n",
      "total_users: 40000\n"
     ]
    }
   ],
   "source": [
    "val_perc = test_perc = 0.1\n",
    "n_last_items_val = n_last_items_test = 1\n",
    "\n",
    "total_items = len(df.item_id.unique())\n",
    "total_users = len(df.user_id.unique())\n",
    "print(f'total_items: {total_items}')\n",
    "print(f'total_users: {total_users}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot pick 6040 users with 1 items\nTry a smaller test and/or validation percentage of the data or less items to leave out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-36dbc99dff8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mData_prep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_val_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_last_items_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_last_items_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/Data_prep.py\u001b[0m in \u001b[0;36mtrain_val_test_split\u001b[0;34m(df, val_perc, test_perc, n_items_val, n_items_test, seqs, stats)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mval_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_perc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mtrain_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_last_x_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_items_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mtest_users_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mtrain_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_last_x_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_items_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malready_picked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_users_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/Data_prep.py\u001b[0m in \u001b[0;36mleave_last_x_out\u001b[0;34m(full_data, n_users, leave_out, seqs, already_picked, seed)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot pick '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' users with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleave_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' items'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\nTry a smaller test and/or validation percentage of the data or less items to leave out'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot pick 6040 users with 1 items\nTry a smaller test and/or validation percentage of the data or less items to leave out"
     ]
    }
   ],
   "source": [
    "from Data_prep import train_val_test_split\n",
    "datasets = train_val_test_split(df, val_perc, test_perc, n_last_items_val, n_last_items_test)\n",
    "train_set, val_set, test_set = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sampes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = 'am_40k_nolf_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMF_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'nolf': 8,\n",
    "    'regs': [0,0],\n",
    "    'epochs': 20,\n",
    "    'sample_size': len(train_set_mf),#int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 2,\n",
    "    'ckpt_dir': f'../NeuMF_storage/GMF_ckpts_{run_num}/ckpts',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'layers': [64,32,16,8],\n",
    "    'reg_layers': [0,0,0,0],\n",
    "    'epochs': 20,\n",
    "    'sample_size': len(train_set_mf),#int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 4,\n",
    "    'ckpt_dir': f'../NeuMF_storage/MLP_ckpts_{run_num}/ckpts',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuMF_params = {\n",
    "    'learning_rate': 0.0005,\n",
    "    'batch_size': 256,\n",
    "    'layers': [64,32,16,8],\n",
    "    'reg_layers': [0,0,0,0],\n",
    "    'reg_mf': [0, 0],\n",
    "    'nolf': 8,\n",
    "    'epochs': 20,\n",
    "    'sample_size': len(train_set_mf),#int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 4,\n",
    "    'ckpt_dir': f'../NeuMF_storage/NeuMF_ckpts_{run_num}/ckpts',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NCF import NCF\n",
    "NCF = NCF(total_users, total_items, GMF_params, MLP_params, NeuMF_params)\n",
    "\n",
    "NCF.build_GMF_model()\n",
    "NCF.build_MLP_model()\n",
    "NCF.build_NeuMF_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Samples (MP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random User sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp        \n",
    "def create_sample(user_items, train_users, train_items, params, num_processes):\n",
    "    samples_sizes_split = np.array_split(np.array(range(params['sample_size'])),num_processes)\n",
    "    args = []\n",
    "    for samples_size in samples_sizes_split:\n",
    "        args.append((user_items, train_users, train_items, len(samples_size), params['num_neg']))\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(create_sample_worker, args)\n",
    "\n",
    "    user_inputs, item_inputs, labels = [], [], []\n",
    "    for res_epochs in results: \n",
    "        user_inputs.extend(res_epochs['u'])\n",
    "        item_inputs.extend(res_epochs['i'])\n",
    "        labels.extend(res_epochs['l'])\n",
    "\n",
    "    return user_inputs, item_inputs, labels\n",
    "\n",
    "\n",
    "def create_sample_worker(user_items, train_users, train_items, sample_size, num_neg):\n",
    "    user_inputs, item_inputs, labels = [], [], []\n",
    "    for s in range(sample_size):\n",
    "        # Add positive item\n",
    "        u = np.random.choice(train_users)\n",
    "        u_items = user_items[u]\n",
    "        i = np.random.choice(u_items)\n",
    "\n",
    "        user_inputs.append(u)\n",
    "        item_inputs.append(i)\n",
    "        labels.append(1)\n",
    "\n",
    "        # Add negative item\n",
    "        for i in range(num_neg):\n",
    "            j = np.random.choice(train_items)\n",
    "            while j in u_items:  # neg item j cannot be in the set of pos items of user u\n",
    "                j = np.random.choice(train_items)\n",
    "\n",
    "            user_inputs.append(u)\n",
    "            item_inputs.append(j)\n",
    "            labels.append(0)\n",
    "\n",
    "    return {'u':user_inputs, 'i':item_inputs, 'l':labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single user sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp        \n",
    "def create_user_sample(user_items, train_users, train_items, params, num_processes):\n",
    "    users_splits = np.array_split(np.array(train_users),num_processes)\n",
    "    args = []\n",
    "    for user_split in users_splits:\n",
    "        args.append((user_items, user_split, train_items, params['num_neg']))\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(create_user_sample_worker, args)\n",
    "\n",
    "    user_inputs, item_inputs, labels = [], [], []\n",
    "    for res_epochs in results: \n",
    "        user_inputs.extend(res_epochs['u'])\n",
    "        item_inputs.extend(res_epochs['i'])\n",
    "        labels.extend(res_epochs['l'])\n",
    "\n",
    "    return user_inputs, item_inputs, labels\n",
    "\n",
    "\n",
    "def create_user_sample_worker(user_items, train_users, train_items, num_neg):\n",
    "    user_inputs, item_inputs, labels = [], [], []\n",
    "    for user in train_users:\n",
    "        # All positive items for this user\n",
    "        u_items = user_items[user]\n",
    "        \n",
    "        # Per positive item, sample num_neg negative items\n",
    "        for u_item in u_items:\n",
    "            pos_item = np.random.choice(u_items)\n",
    "\n",
    "            user_inputs.append(user)\n",
    "            item_inputs.append(pos_item)\n",
    "            labels.append(1)\n",
    "\n",
    "            # Add negative item\n",
    "            for i in range(num_neg):\n",
    "                neg_item = np.random.choice(train_items)\n",
    "                while neg_item in u_items:  # neg item j cannot be in the set of pos items of user u\n",
    "                    neg_item = np.random.choice(train_items)\n",
    "\n",
    "                user_inputs.append(user)\n",
    "                item_inputs.append(neg_item)\n",
    "                labels.append(0)\n",
    "\n",
    "    return {'u':user_inputs, 'i':item_inputs, 'l':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = train_set_mf.groupby('user_id')['item_id'].apply(list)\n",
    "train_users = train_set_mf.user_id.unique()\n",
    "train_items = train_set_mf.item_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = path + data_path + 'Samples/' + file_name + '_samples_' + GMF_params['num_neg'] + '_neg'\n",
    "sample_name = file_name + '_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "CPU times: user 1min 51s, sys: 11 s, total: 2min 2s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "num_processes = mp.cpu_count()\n",
    "val_metrics = []\n",
    "for epoch in range(30):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    user_inputs, item_inputs, labels = create_user_sample(user_items, train_users, train_items, NCF.GMF_params, num_processes)\n",
    "    samples = [user_inputs, item_inputs, labels]\n",
    "    file = open(f'{store_path}/{sample_name}_{epoch}.csv', 'w+', newline='')\n",
    "    with file:\n",
    "        write = csv.writer(file)\n",
    "        write.writerows(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml_1m'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4993545"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_split = np.array_split(np.array(train_users),num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3334,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file = open(f'../NeuMF_storage/samples/ml_1m_sample_test.csv', 'w+', newline='')\n",
    "\n",
    "with file:\n",
    "    write = csv.writer(file)\n",
    "    write.writerows(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 965 ms, sys: 290 ms, total: 1.26 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('samples.csv', 'r') as read_obj:\n",
    "    csv_reader = csv.reader(read_obj)\n",
    "    samples = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
