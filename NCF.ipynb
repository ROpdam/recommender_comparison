{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Evaluation import get_metrics\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/robin.opdam/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "# path = '/Users/Robin/Google Drive/Thesis (Msc)/Thesis_shared_files/'\n",
    "path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params based on top 3 GS results\n",
    "- ML: Final run for GS iloc 52\n",
    "- Am_like_ML: Final run for GS iloc 50\n",
    "- Am_20k_users: Final run for GS iloc 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['am_like_ml']#['ml_1m', 'am_like_ml', 'am_20k_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_val_rec@10</th>\n",
       "      <th>total_val_rec</th>\n",
       "      <th>val_rec@10</th>\n",
       "      <th>train_time</th>\n",
       "      <th>GMF</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NeuMF</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layers</th>\n",
       "      <th>reg_layers</th>\n",
       "      <th>reg_mf</th>\n",
       "      <th>nolf</th>\n",
       "      <th>epochs</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>weights_dir</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.054</td>\n",
       "      <td>158.569508</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.57862, 0.47443, 0.41558, 0.37725, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[1e-05, 1e-05, 1e-05, 1e-05]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.046</td>\n",
       "      <td>151.870936</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.49594, 0.32659, 0.28297, 0.2654, 0...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-05, 1e-05]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.046</td>\n",
       "      <td>168.121778</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.43756, 0.29277, 0.26578, 0.26185, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>256</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-06, 1e-06]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    all_val_rec@10  total_val_rec  val_rec@10  train_time           GMF  \\\n",
       "50              []          0.254       0.054  158.569508  {'loss': []}   \n",
       "155             []          0.212       0.046  151.870936  {'loss': []}   \n",
       "103             []          0.214       0.046  168.121778  {'loss': []}   \n",
       "\n",
       "              MLP                                              NeuMF  \\\n",
       "50   {'loss': []}  {'loss': [0.57862, 0.47443, 0.41558, 0.37725, ...   \n",
       "155  {'loss': []}  {'loss': [0.49594, 0.32659, 0.28297, 0.2654, 0...   \n",
       "103  {'loss': []}  {'loss': [0.43756, 0.29277, 0.26578, 0.26185, ...   \n",
       "\n",
       "     learning_rate batch_size           layers  \\\n",
       "50         0.00005        512  [16, 32, 16, 8]   \n",
       "155        0.00005        512  [16, 32, 16, 8]   \n",
       "103        0.00005        256  [16, 32, 16, 8]   \n",
       "\n",
       "                           reg_layers          reg_mf nolf epochs num_neg  \\\n",
       "50       [1e-05, 1e-05, 1e-05, 1e-05]          [0, 0]    8     20       4   \n",
       "155  [0.0001, 0.0001, 0.0001, 0.0001]  [1e-05, 1e-05]    8     20       8   \n",
       "103  [0.0001, 0.0001, 0.0001, 0.0001]  [1e-06, 1e-06]    8     20       8   \n",
       "\n",
       "                                       weights_dir optimizer  \n",
       "50   ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "155  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "103  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(path + 'Logs/GS/' + file_names[0] + '_neumf_gs_log').sort_values('val_rec@10', ascending=False).iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuMF_ml_1m_params = {\n",
    "    'learning_rate': 0.0001,\n",
    "    'batch_size': 512,\n",
    "    'layers': [16,32,16,8],\n",
    "    'reg_layers': [0,0,0,0],\n",
    "    'reg_mf': [0,0],\n",
    "    'nolf': 8,\n",
    "    'epochs': 20,\n",
    "    'sample_size': 0,\n",
    "    'num_neg': 4,\n",
    "    'weights_dir': '', #f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_val_rec@10</th>\n",
       "      <th>total_val_rec</th>\n",
       "      <th>val_rec@10</th>\n",
       "      <th>train_time</th>\n",
       "      <th>GMF</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NeuMF</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layers</th>\n",
       "      <th>reg_layers</th>\n",
       "      <th>reg_mf</th>\n",
       "      <th>nolf</th>\n",
       "      <th>epochs</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>weights_dir</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.054</td>\n",
       "      <td>158.569508</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.57862, 0.47443, 0.41558, 0.37725, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[1e-05, 1e-05, 1e-05, 1e-05]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.046</td>\n",
       "      <td>151.870936</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.49594, 0.32659, 0.28297, 0.2654, 0...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-05, 1e-05]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.046</td>\n",
       "      <td>168.121778</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.43756, 0.29277, 0.26578, 0.26185, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>256</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-06, 1e-06]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.044</td>\n",
       "      <td>540.383654</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.36203, 0.28288, 0.27778, 0.27679, ...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.044</td>\n",
       "      <td>170.349026</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.42634, 0.28736, 0.26632, 0.26279, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>256</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-05, 1e-05]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    all_val_rec@10  total_val_rec  val_rec@10  train_time           GMF  \\\n",
       "50              []          0.254       0.054  158.569508  {'loss': []}   \n",
       "155             []          0.212       0.046  151.870936  {'loss': []}   \n",
       "103             []          0.214       0.046  168.121778  {'loss': []}   \n",
       "111             []          0.194       0.044  540.383654  {'loss': []}   \n",
       "107             []          0.198       0.044  170.349026  {'loss': []}   \n",
       "\n",
       "              MLP                                              NeuMF  \\\n",
       "50   {'loss': []}  {'loss': [0.57862, 0.47443, 0.41558, 0.37725, ...   \n",
       "155  {'loss': []}  {'loss': [0.49594, 0.32659, 0.28297, 0.2654, 0...   \n",
       "103  {'loss': []}  {'loss': [0.43756, 0.29277, 0.26578, 0.26185, ...   \n",
       "111  {'loss': []}  {'loss': [0.36203, 0.28288, 0.27778, 0.27679, ...   \n",
       "107  {'loss': []}  {'loss': [0.42634, 0.28736, 0.26632, 0.26279, ...   \n",
       "\n",
       "     learning_rate batch_size           layers  \\\n",
       "50         0.00005        512  [16, 32, 16, 8]   \n",
       "155        0.00005        512  [16, 32, 16, 8]   \n",
       "103        0.00005        256  [16, 32, 16, 8]   \n",
       "111        0.00010        256  [16, 32, 16, 8]   \n",
       "107        0.00005        256  [16, 32, 16, 8]   \n",
       "\n",
       "                           reg_layers          reg_mf nolf epochs num_neg  \\\n",
       "50       [1e-05, 1e-05, 1e-05, 1e-05]          [0, 0]    8     20       4   \n",
       "155  [0.0001, 0.0001, 0.0001, 0.0001]  [1e-05, 1e-05]    8     20       8   \n",
       "103  [0.0001, 0.0001, 0.0001, 0.0001]  [1e-06, 1e-06]    8     20       8   \n",
       "111  [0.0001, 0.0001, 0.0001, 0.0001]          [0, 0]    8     20       8   \n",
       "107  [0.0001, 0.0001, 0.0001, 0.0001]  [1e-05, 1e-05]    8     20       8   \n",
       "\n",
       "                                       weights_dir optimizer  \n",
       "50   ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "155  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "103  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "111  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "107  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(path + 'Logs/GS/' + file_names[1] + '_neumf_gs_log').sort_values('val_rec@10', ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuMF_am_like_ml_params = {\n",
    "    'learning_rate': 0.00005,\n",
    "    'batch_size': 512,\n",
    "    'layers': [16,32,16,8],\n",
    "    'reg_layers': [0.0001, 0.0001, 0.0001, 0.0001],#[0.00001,0.00001,0.00001,0.00001],\n",
    "    'reg_mf': [0.000001,0.000001],#[0,0],\n",
    "    'nolf': 8,\n",
    "    'epochs': 20,\n",
    "    'sample_size': 0,\n",
    "    'num_neg': 8,\n",
    "    'weights_dir': '',#f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_val_rec@10</th>\n",
       "      <th>total_val_rec</th>\n",
       "      <th>val_rec@10</th>\n",
       "      <th>train_time</th>\n",
       "      <th>GMF</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NeuMF</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>layers</th>\n",
       "      <th>reg_layers</th>\n",
       "      <th>reg_mf</th>\n",
       "      <th>nolf</th>\n",
       "      <th>epochs</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>weights_dir</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.017</td>\n",
       "      <td>293.028208</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.60951, 0.46641, 0.37973, 0.35444, ...</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>256</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-06, 1e-06]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.016</td>\n",
       "      <td>155.476554</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.59191, 0.42532, 0.36874, 0.35261, ...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[0.0001, 0.0001, 0.0001, 0.0001]</td>\n",
       "      <td>[1e-06, 1e-06]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.014</td>\n",
       "      <td>306.694566</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': []}</td>\n",
       "      <td>{'loss': [0.38299, 0.28976, 0.26635, 0.25525, ...</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>512</td>\n",
       "      <td>[16, 32, 16, 8]</td>\n",
       "      <td>[1e-06, 1e-06, 1e-06, 1e-06]</td>\n",
       "      <td>[1e-06, 1e-06]</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>../Logs/weights/NeuMF_weights_0/NeuMF_weights</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    all_val_rec@10  total_val_rec  val_rec@10  train_time           GMF  \\\n",
       "7               []          0.075       0.017  293.028208  {'loss': []}   \n",
       "67              []          0.073       0.016  155.476554  {'loss': []}   \n",
       "161             []          0.058       0.014  306.694566  {'loss': []}   \n",
       "\n",
       "              MLP                                              NeuMF  \\\n",
       "7    {'loss': []}  {'loss': [0.60951, 0.46641, 0.37973, 0.35444, ...   \n",
       "67   {'loss': []}  {'loss': [0.59191, 0.42532, 0.36874, 0.35261, ...   \n",
       "161  {'loss': []}  {'loss': [0.38299, 0.28976, 0.26635, 0.25525, ...   \n",
       "\n",
       "     learning_rate batch_size           layers  \\\n",
       "7          0.00005        256  [16, 32, 16, 8]   \n",
       "67         0.00010        512  [16, 32, 16, 8]   \n",
       "161        0.00010        512  [16, 32, 16, 8]   \n",
       "\n",
       "                           reg_layers          reg_mf nolf epochs num_neg  \\\n",
       "7    [0.0001, 0.0001, 0.0001, 0.0001]  [1e-06, 1e-06]    8     20       4   \n",
       "67   [0.0001, 0.0001, 0.0001, 0.0001]  [1e-06, 1e-06]    8     20       4   \n",
       "161      [1e-06, 1e-06, 1e-06, 1e-06]  [1e-06, 1e-06]    8     20       8   \n",
       "\n",
       "                                       weights_dir optimizer  \n",
       "7    ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "67   ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  \n",
       "161  ../Logs/weights/NeuMF_weights_0/NeuMF_weights      Adam  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(path + 'Logs/GS/' + file_names[2] + '_neumf_gs_log').sort_values('val_rec@10', ascending=False).iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuMF_am_20k_users_params = {\n",
    "    'learning_rate': 0.00005,\n",
    "    'batch_size': 256,\n",
    "    'layers': [16,32,16,8],\n",
    "    'reg_layers': [0.0001, 0.0001, 0.0001, 0.0001],\n",
    "    'reg_mf': [0.000001,0.000001],\n",
    "    'nolf': 8,\n",
    "    'epochs': 20,\n",
    "    'sample_size': 0,#len(train_set_mf),#int(0.5*len(train_set.user_id.unique())),\n",
    "    'num_neg': 4,\n",
    "    'weights_dir': '',#f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights',\n",
    "    'optimizer':'Adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NeuMF Final Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(679596)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = ['Data/Amazon/'] #['Data/ML/', 'Data/Amazon/', 'Data/Amazon/']\n",
    "params = [NeuMF_am_like_ml_params] #[NeuMF_ml_1m_params, NeuMF_am_like_ml_params, NeuMF_am_20k_users_params]\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "steps = 5\n",
    "rank_at = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "\n",
      "Fitting NeuMF with parameters:\n",
      "learning_rate                                                5e-05\n",
      "batch_size                                                     512\n",
      "layers                                             [16, 32, 16, 8]\n",
      "reg_layers                        [0.0001, 0.0001, 0.0001, 0.0001]\n",
      "reg_mf                                              [1e-06, 1e-06]\n",
      "nolf                                                             8\n",
      "epochs                                                          20\n",
      "sample_size                                                 176012\n",
      "num_neg                                                          8\n",
      "weights_dir      ../Logs/weights/NeuMF_weights_am_like_ml/NeuMF...\n",
      "optimizer                                                     Adam\n",
      "Name: 0, dtype: object\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094/3094 [==============================] - 15s 5ms/step - loss: 0.4832\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f0e9fa822ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mNeuMF_val_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NeuMF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_set_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, name, num, samples, train_set, val_set, verbose)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No samples available, create samples first using: create_samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, params, samples, train_set, val_set, verbose, num)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;31m#             val_metrics.append(sample_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;31m#             print(sample_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mranked_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mval_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(self, name, train_set, test_set, rank_at, exclude_already_seen)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0muser_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mtotal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexclude_already_seen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malready_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from NCF import NCF\n",
    "for data_path, file_name, neumf_params in zip(data_paths, file_names, params):\n",
    "    df = pd.read_pickle(path + data_path + file_name)\n",
    "    total_items = df.item_id.nunique()\n",
    "    total_users = df.user_id.nunique()\n",
    "    \n",
    "    # Load Train Test Val Split\n",
    "    train_set_mf = pd.read_pickle(path + data_path + file_name + '_train_mf')\n",
    "    val_set_mf = pd.read_pickle(path + data_path + file_name + '_val_mf')\n",
    "    test_set_mf = pd.read_pickle(path + data_path + file_name + '_test_mf')\n",
    "    \n",
    "    # Load Samples\n",
    "    ncf = NCF(total_users, total_items, neumf_params)\n",
    "    sample_path = path + data_path + 'Samples/' + file_name + '_samples_' + str(neumf_params['num_neg']) + '_neg/'\n",
    "    samples = ncf.load_samples(sample_path, file_name + '_sample', neumf_params['epochs'])\n",
    "    \n",
    "    neumf_params['sample_size'] = len(train_set_mf)\n",
    "    neumf_params['weights_dir'] = f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights'\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        print(f'run: {i}')\n",
    "        ncf = NCF(total_users, total_items, NeuMF_params=neumf_params)\n",
    "        ncf.build_NeuMF_model()\n",
    "                                \n",
    "        s = time.time()\n",
    "        NeuMF_val_metrics = ncf.train_model(name='NeuMF', samples=samples, train_set=train_set_mf, val_set=val_set_mf, verbose=1, num=0)\n",
    "        t = time.time() - s\n",
    "        \n",
    "        ncf.NeuMF = tf.keras.models.load_model('../Logs/weights/NeuMF_0_best_model.h5')\n",
    "        ranked_df_neumf = ncf.get_predictions('NeuMF', train_set=train_set_mf, test_set=test_set_mf)\n",
    "        neumf_test_metrics = get_metrics(ranked_df_neumf, stats=False)\n",
    "        \n",
    "        additional_info = {}\n",
    "        additional_info['all_val_rec@10'] = [val_m['recall'].iloc[2] for val_m in NeuMF_val_metrics]\n",
    "        additional_info['all_val_ndcg@10'] = [val_m['ndcg'].iloc[2] for val_m in NeuMF_val_metrics]\n",
    "        additional_info['val_metrics'] = NeuMF_val_metrics\n",
    "        \n",
    "        additional_info['metrics'] = neumf_test_metrics\n",
    "        additional_info['train_time'] = t\n",
    "\n",
    "        store_path = path + '/Logs/final/' + file_name +  '_neumf_log'\n",
    "        ncf.store_model('NeuMF', store_path, additional_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = path + '/Logs/final/' + file_names[0] + '_neumf_log'\n",
    "pd.read_pickle(res_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single runs for clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_paths[0]\n",
    "file_name = file_names[0]\n",
    "neumf_params = params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_params['epochs'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path + data_path + file_name)\n",
    "total_items = df.item_id.nunique()\n",
    "total_users = df.user_id.nunique()\n",
    "\n",
    "# Load Train Test Val Split\n",
    "train_set_mf = pd.read_pickle(path + data_path + file_name + '_train_mf')\n",
    "val_set_mf = pd.read_pickle(path + data_path + file_name + '_val_mf')\n",
    "test_set_mf = pd.read_pickle(path + data_path + file_name + '_test_mf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NCF import NCF\n",
    "ncf = NCF(total_users, total_items, NeuMF_params=neumf_params)\n",
    "ncf.build_NeuMF_model()\n",
    "\n",
    "# Load Samples\n",
    "# sample_path = path + data_path + 'Samples/' + file_name + '_samples_' + str(neumf_params['num_neg']) + '_neg/'\n",
    "# samples = ncf.load_samples(sample_path, file_name + '_sample', neumf_params['epochs'])\n",
    "    \n",
    "# neumf_params['sample_size'] = len(train_set_mf)\n",
    "# neumf_params['weights_dir'] = f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting NeuMF with parameters:\n",
      "learning_rate                                                5e-05\n",
      "batch_size                                                     512\n",
      "layers                                             [16, 32, 16, 8]\n",
      "reg_layers                        [0.0001, 0.0001, 0.0001, 0.0001]\n",
      "reg_mf                                              [1e-06, 1e-06]\n",
      "nolf                                                             8\n",
      "epochs                                                          20\n",
      "sample_size                                                 176012\n",
      "num_neg                                                          8\n",
      "weights_dir      ../Logs/weights/NeuMF_weights_am_like_ml/NeuMF...\n",
      "optimizer                                                     Adam\n",
      "Name: 0, dtype: object\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094/3094 [==============================] - 16s 5ms/step - loss: 0.5214\n",
      "Epoch: 1\n",
      "3094/3094 [==============================] - 16s 5ms/step - loss: 0.3223\n",
      "save\n",
      "Epoch: 2\n",
      "3094/3094 [==============================] - 16s 5ms/step - loss: 0.2750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0f2a2718afaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNeuMF_val_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NeuMF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_set_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, name, num, samples, train_set, val_set, verbose)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No samples available, create samples first using: create_samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weights_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, params, samples, train_set, val_set, verbose, num)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;31m#             val_metrics.append(sample_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;31m#             print(sample_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mranked_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mval_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Robin/recommender_systems/NCF.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(self, name, train_set, test_set, rank_at, exclude_already_seen)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0muser_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mtotal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexclude_already_seen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malready_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4069\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 4071\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   4072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         if x is not None)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, op, message)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;34m\"\"\"Creates an `InvalidArgumentError`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     super(InvalidArgumentError, self).__init__(node_def, op, message,\n\u001b[0;32m--> 267\u001b[0;31m                                                INVALID_ARGUMENT)\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, op, message, error_code)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0merror_code\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0merror_codes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCode\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdescribing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NeuMF_val_metrics = ncf.train_model(name='NeuMF', samples=samples, train_set=train_set_mf, val_set=val_set_mf, verbose=1, num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.046, 0.042, 0.046]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncf.val_rec_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ncf.get_predictions('NeuMF', train_set_mf, test_set_mf)\n",
    "metrics = get_metrics(preds)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncf2 = NCF(total_users, total_items, NeuMF_params=neumf_params)\n",
    "ncf2.NeuMF = tf.keras.model.load('../Logs/weights/NeuMF_1_best_model.h5)\n",
    "best_preds = ncf.get_predictions('NeuMF', train_set_mf, test_set_mf)\n",
    "best_metrics = get_metrics(best_preds)\n",
    "best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting NeuMF with parameters:\n",
      "learning_rate                               5e-05\n",
      "batch_size                                    512\n",
      "layers                            [16, 32, 16, 8]\n",
      "reg_layers       [0.0001, 0.0001, 0.0001, 0.0001]\n",
      "reg_mf                             [1e-06, 1e-06]\n",
      "nolf                                            8\n",
      "epochs                                         20\n",
      "sample_size                                     0\n",
      "num_neg                                         8\n",
      "weights_dir                                      \n",
      "optimizer                                    Adam\n",
      "Name: 0, dtype: object\n",
      "Epoch: 0\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.5234\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         10   0.020   0.020000  0.020000\n",
      "1        5         21   0.042   0.008400  0.032032\n",
      "2       10         22   0.044   0.004400  0.032699\n",
      "3       15         23   0.046   0.003067  0.033211\n",
      "4       20         23   0.046   0.002300  0.033211]\n",
      "Epoch: 1\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.3280\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         10   0.020   0.020000  0.020000\n",
      "1        5         21   0.042   0.008400  0.032032\n",
      "2       10         23   0.046   0.004600  0.033236\n",
      "3       15         23   0.046   0.003067  0.033236\n",
      "4       20         23   0.046   0.002300  0.033236]\n",
      "Epoch: 2\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2813\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         13   0.026   0.026000  0.026000\n",
      "1        5         22   0.044   0.008800  0.035909\n",
      "2       10         23   0.046   0.004600  0.036621\n",
      "3       15         23   0.046   0.003067  0.036621\n",
      "4       20         23   0.046   0.002300  0.036621]\n",
      "Epoch: 3\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2623\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         14   0.028   0.028000  0.028000\n",
      "1        5         23   0.046   0.009200  0.037893\n",
      "2       10         23   0.046   0.004600  0.037893\n",
      "3       15         23   0.046   0.003067  0.037893\n",
      "4       20         23   0.046   0.002300  0.037893]\n",
      "Epoch: 4\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2557\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         14   0.028   0.028000  0.028000\n",
      "1        5         23   0.046   0.009200  0.037806\n",
      "2       10         23   0.046   0.004600  0.037806\n",
      "3       15         23   0.046   0.003067  0.037806\n",
      "4       20         23   0.046   0.002300  0.037806]\n",
      "Epoch: 5\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2528\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         15   0.030   0.030000  0.030000\n",
      "1        5         23   0.046   0.009200  0.038544\n",
      "2       10         23   0.046   0.004600  0.038544\n",
      "3       15         23   0.046   0.003067  0.038544\n",
      "4       20         23   0.046   0.002300  0.038544]\n",
      "Epoch: 6\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2514\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         16   0.032   0.032000  0.032000\n",
      "1        5         23   0.046   0.009200  0.039282\n",
      "2       10         23   0.046   0.004600  0.039282\n",
      "3       15         23   0.046   0.003067  0.039282\n",
      "4       20         23   0.046   0.002300  0.039282]\n",
      "Epoch: 7\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2506\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         15   0.030   0.030000  0.030000\n",
      "1        5         22   0.044   0.008800  0.037770\n",
      "2       10         23   0.046   0.004600  0.038483\n",
      "3       15         23   0.046   0.003067  0.038483\n",
      "4       20         23   0.046   0.002300  0.038483]\n",
      "Epoch: 9\n",
      "3094/3094 [==============================] - 14s 4ms/step - loss: 0.2506\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         13   0.026   0.026000  0.026000\n",
      "1        5         22   0.044   0.008800  0.035770\n",
      "2       10         23   0.046   0.004600  0.036483\n",
      "3       15         23   0.046   0.003067  0.036483\n",
      "4       20         23   0.046   0.002300  0.036483]\n",
      "Epoch: 10\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2507\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         13   0.026   0.026000  0.026000\n",
      "1        5         21   0.042   0.008400  0.034909\n",
      "2       10         23   0.046   0.004600  0.036206\n",
      "3       15         23   0.046   0.003067  0.036206\n",
      "4       20         23   0.046   0.002300  0.036206]\n",
      "Epoch: 11\n",
      "3094/3094 [==============================] - 14s 4ms/step - loss: 0.2508\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         11   0.022   0.022000  0.022000\n",
      "1        5         21   0.042   0.008400  0.032893\n",
      "2       10         23   0.046   0.004600  0.034138\n",
      "3       15         23   0.046   0.003067  0.034138\n",
      "4       20         23   0.046   0.002300  0.034138]\n",
      "Epoch: 12\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2508\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1         10   0.020   0.020000  0.020000\n",
      "1        5         21   0.042   0.008400  0.031929\n",
      "2       10         23   0.046   0.004600  0.033138\n",
      "3       15         23   0.046   0.003067  0.033138\n",
      "4       20         23   0.046   0.002300  0.033138]\n",
      "Epoch: 13\n",
      "3094/3094 [==============================] - 14s 4ms/step - loss: 0.2509\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         19   0.038   0.007600  0.028493\n",
      "2       10         22   0.044   0.004400  0.030496\n",
      "3       15         23   0.046   0.003067  0.031036\n",
      "4       20         23   0.046   0.002300  0.031036]\n",
      "Epoch: 14\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2508\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         20   0.040   0.008000  0.029267\n",
      "2       10         22   0.044   0.004400  0.030511\n",
      "3       15         23   0.046   0.003067  0.031023\n",
      "4       20         23   0.046   0.002300  0.031023]\n",
      "Epoch: 15\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2506\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         20   0.040   0.008000  0.029267\n",
      "2       10         22   0.044   0.004400  0.030476\n",
      "3       15         23   0.046   0.003067  0.030988\n",
      "4       20         23   0.046   0.002300  0.030988]\n",
      "Epoch: 16\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2503\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         20   0.040   0.008000  0.029267\n",
      "2       10         22   0.044   0.004400  0.030476\n",
      "3       15         23   0.046   0.003067  0.030988\n",
      "4       20         23   0.046   0.002300  0.030988]\n",
      "Epoch: 17\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2497\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         20   0.040   0.008000  0.029128\n",
      "2       10         22   0.044   0.004400  0.030361\n",
      "3       15         23   0.046   0.003067  0.030873\n",
      "4       20         23   0.046   0.002300  0.030873]\n",
      "Epoch: 18\n",
      "3094/3094 [==============================] - 14s 5ms/step - loss: 0.2489\n",
      "[   rank_at  hitcounts  recall  precision      ndcg\n",
      "0        1          9   0.018   0.018000  0.018000\n",
      "1        5         20   0.040   0.008000  0.029128\n",
      "2       10         22   0.044   0.004400  0.030361\n",
      "3       15         23   0.046   0.003067  0.030873\n",
      "4       20         23   0.046   0.002300  0.030873]\n",
      "Epoch: 19\n",
      "2355/3094 [=====================>........] - ETA: 3s - loss: 0.2480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NeuMF_val_metrics = ncf.train_model(name='NeuMF', samples=samples, train_set=train_set_mf, val_set=val_set_mf, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbb8a713208>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncf.NeuMF.load_weights(f'../Logs/weights/NeuMF_weights_{file_name}/NeuMF_weights').expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_preds = ncf.sample_prediction('NeuMF', train_set_mf, test_set_mf, exclude_already_seen=False)\n",
    "get_metrics(sample_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
